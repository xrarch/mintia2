//
// Implementation of pool caches for the MINTIA Executive.
//
// A "slabs and magazines" type cache is implemented, inspired by Solaris.
// Magazines provide a per-cpu caching mechanism.
//
// It is recommended that for best performance on NUMA systems, pool caches
// be duplicated per NUMA node, because the slab caches and depots are not
// automatically duplicated on that basis.
//

#INCLUDE "Mmp.hjk"

#DEFINE MMP_HEADER_FITS_IN_ALIGNMENT [
    (SIZEOF MmpSlabHeader <= (RTL_ALIGN_BYTES - SIZEOF ^VOID))
]

#DEFINE MMP_MAX_SMALL_BLOCKS_PER_SLAB 16
#DEFINE MMP_MAX_BIG_BLOCKS_PER_SLAB 8

#DEFINE MMP_SMALL_POOL_BLOCK [(MMP_BLOCK_MAX_REQUEST_SIZE / 5)]

STRUCT MmpSlabHeader
    References : ULONG,
END

#MACRO MmpLockSlabCache ( scache ) [
    KeAcquireApcLockExclusive ( &(scache)^.Lock )
]

#MACRO MmpUnlockSlabCache ( scache, ipl ) [
    KeReleaseApcLock ( &(scache)^.Lock, ipl )
]

STRUCT MmpPoolCachePerCpu
    MagLock : KeLock,

    Loaded : ^^VOID,
    Previous : ^^VOID,

    Rounds : BYTE,
    PreviousRounds : BYTE,

    MagazineSize : UBYTE,
END

STRUCT MmpDepotList
    Head : ^^VOID,

    Total : ULONG,
    Min : ULONG,
    ReapLimit : ULONG,
END

STRUCT MmpSlabBackedPoolCacheContext
    Slabs : MmpSlabCache,
END

STRUCT MmpPoolCache
    Name : ^UBYTE,

    DepotLock : KeLock,

    FullMagazineList : MmpDepotList,
    EmptyMagazineList : MmpDepotList,

    MasterListEntry : RtlListEntry,

    MagazineType : ^MmpMagazineType,

    Allocate : MmPoolCacheAllocateF,
    Free : MmPoolCacheFreeF,
    Delete : MmPoolCacheDeleteF,

    Context : ^VOID,

    Node : ^MmpNode,

    Pageable : UBYTE,
END

#DEFINE MMP_PCPCPU_SIZE [((SIZEOF MmpPoolCachePerCpu + KE_CACHE_ALIGN - 1) &
    ~(KE_CACHE_ALIGN - 1))]

#DEFINE MMP_PC_SIZE [((SIZEOF MmpPoolCache + KE_CACHE_ALIGN - 1) &
    ~(KE_CACHE_ALIGN - 1))]

#MACRO MmpPoolCachePerCpuById ( cache, id ) [
    (CAST cache + MMP_PC_SIZE + (id * MMP_PCPCPU_SIZE) TO ^MmpPoolCachePerCpu)
]

#MACRO MmpLockPoolCacheList ( list ) [
    KeAcquireLockExclusive ( &(list)^.MasterListLock )
]

#MACRO MmpUnlockPoolCacheList ( list ) [
    KeReleaseLock ( &(list)^.MasterListLock )
]

#MACRO MmpLockPoolCacheDepot ( cache ) [
    KeAcquireApcLockExclusive ( &(cache)^.DepotLock )
]

#MACRO MmpUnlockPoolCacheDepot ( cache, ipl ) [
    KeReleaseApcLock ( &(cache)^.DepotLock, ipl )
]

#MACRO MmpLockMagazineCache ( pcpcpu ) [
    KeAcquireApcLockExclusive ( &(pcpcpu)^.MagLock )
]

#MACRO MmpUnlockMagazineCache ( pcpcpu, ipl ) [
    KeReleaseApcLock ( &(pcpcpu)^.MagLock, ipl )
]

#MACRO MmpInitializeDepotList ( list ) [
    NOTHING (list)^.Head = NULLPTR
    NOTHING (list)^.Total = 0
    NOTHING (list)^.Min = 0
    NOTHING (list)^.ReapLimit = 0
]

#DEFINE MMP_LARGE_MAGAZINE_SIZE 4
#DEFINE MMP_SMALL_MAGAZINE_SIZE 8

#SECTION "PAGEtext"
FN MmpInitializeSlabCache (
    IN node : ^MmpNode,
    IN scache : ^MmpSlabCache,
    IN size : UWORD,
    IN poolindex : UWORD,
    IN tag : UWORD,
)

    // Initialize a slab cache.

    // Add a pointer to the block size which will be used as the back-pointer to
    // the slab header, and round it up.

    IF size < SIZEOF RtlListEntry THEN
        size = SIZEOF RtlListEntry
    END

    size = (size + SIZEOF ^VOID + RTL_ALIGN_BYTES - 1) & ~(RTL_ALIGN_BYTES - 1)

    scache^.Size = size
    scache^.PoolIndex = poolindex
    scache^.Tag = tag
    scache^.ActiveSlabCount = 0
    scache^.Node = node
    
    RtlInitializeList ( &scache^.FreeListHead )

    KeInitializeLock ( &scache^.Lock )

    blocksperslab : UWORD
    slabsize : UWORD

    // Calculate the maximum size of a slab that we're willing to allocate.
    // This is configured to try to minimize fragmentation.

    IF size < MMP_SMALL_POOL_BLOCK THEN
        // Size of one block is less than a fifth of the maximum pool request
        // size. Note that this divisor *must* be smaller than the value of
        // MMP_MAX_BIG_BLOCKS_PER_SLAB or this attempt to minimize fragmentation
        // will actually worsen it.
        //
        // Pack as many as can fit in a maximum request.

        slabsize = size * MMP_MAX_SMALL_BLOCKS_PER_SLAB

        IF slabsize >= MMP_BLOCK_MAX_REQUEST_SIZE THEN
            slabsize = MMP_BLOCK_MAX_REQUEST_SIZE - 1
        END

        // RtlPrint ( "small slabsize %d\n", slabsize )

    ELSE
        // Each slab allocation will trigger a page-aligned pool allocation.
        // To minimize fragmentation we anticipate this and try to fill each
        // page to the top.

        slabsize = (size * MMP_MAX_BIG_BLOCKS_PER_SLAB + (RTL_PAGE_SIZE - 1))
            & ~(RTL_PAGE_SIZE - 1)

        // RtlPrint ( "big slabsize %d\n", slabsize )
    END

    // Calculate how many blocks can fit in the slab.
    //
    // First assume 1 block because we do special packing for the header of the
    // first block to pack both the slab header and back-pointer into the
    // pre-alignment space.

    blocksperslab = 1

    // First align down.

    blockbytes := slabsize & ~(RTL_ALIGN_BYTES - 1)

    // Now calculate how many bytes are available for blocks.
    // Remove the bytes for the first block which we optimistically assume can
    // also contain the slab header within its pre-alignment.

    blockbytes -= size

    IF NOT MMP_HEADER_FITS_IN_ALIGNMENT THEN
        // The slab header doesn't fit in the alignment, so it needs to be
        // accounted for after all.

        blockbytes -= (SIZEOF MmpSlabHeader + (RTL_ALIGN_BYTES - 1))
            & ~(RTL_ALIGN_BYTES - 1)
    END

    // Calculate how many blocks can fit in the remaining space.

    blocksperslab += blockbytes / size

    // Calculate the final slab size.

    slabsize = blocksperslab * size

    IF NOT MMP_HEADER_FITS_IN_ALIGNMENT THEN
        // The slab header doesn't fit in the alignment, so it needs to be
        // accounted for after all.

        slabsize =
            (slabsize + SIZEOF MmpSlabHeader + (RTL_ALIGN_BYTES - 1))
            & ~(RTL_ALIGN_BYTES - 1)
    END

    // RtlPrint ( "real slabsize %d blocksperslab %d blocksize %d\n", slabsize, blocksperslab, size )

    scache^.BlocksPerSlab = blocksperslab
    scache^.SlabSize = slabsize
END

FN MmpExtendSlabCache (
    IN scache : ^MmpSlabCache,
    IN ipl : UWORD,
    IN wait : UWORD,
) : ^VOID

    // Extend the slab cache. Its lock is held.
    // Returns TRUE if extended, FALSE otherwise.

@Retry

    slab := MmAllocatePoolEx (
        scache^.Node, // node
        scache^.PoolIndex, // poolindex
        scache^.SlabSize, // bytes
        scache^.Tag, // tag
        FALSE, // wait
    )

    // RtlPrint ( "extend %p\n", slab )

    IF NOT slab THEN
        // Failure.

        IF NOT wait THEN
            // Caller specified not to wait, so break out.

            RETURN FALSE
        END

        // We can't wait for pages with a slab cache lock held or we'll deadlock
        // memory management so instead we first try with wait=FALSE, and failing
        // that we wait for free pages outside of the lock.

        MmpUnlockSlabCache ( scache, ipl )

        MmpWaitForPages (
            &scache^.Node^.Partition, // partition
            PsuCurrentThread()^.VmPrivileged, // low
        )

        MmpLockSlabCache ( scache )

        GOTO Retry
    END

    scache^.ActiveSlabCount += 1

    // Initialize the slab header.

    slabheader : ^MmpSlabHeader = slab
    slabheader^.References = 0

    // Initialize each block in the slab.

    block := (slab + SIZEOF MmpSlabHeader + SIZEOF ^VOID + (RTL_ALIGN_BYTES - 1))
        & ~(RTL_ALIGN_BYTES - 1)

    firstblock := block

    blocksize := scache^.Size

    i := 0
    count := scache^.BlocksPerSlab

    WHILE i < count DO
        // Set back pointer to header.

        (CAST (block - SIZEOF ^VOID) TO ^^MmpSlabHeader)^ = slabheader

        // Add to free list.

        RtlInsertAtTailList (
            &scache^.FreeListHead, // head
            CAST block TO ^RtlListEntry, // entry
        )

        i += 1
        block += blocksize
    END

    // Return the first block.

    RETURN firstblock
END

FN MmpFreeSlab (
    IN scache : ^MmpSlabCache,
    IN slab : ^MmpSlabHeader,
)

    // Free a slab.

    // RtlPrint ( "free %p\n", slab )

    scache^.ActiveSlabCount -= 1

    KeAssert ( slab^.References == 0 )

    // First unlink all of the free blocks.

    block := (slab + SIZEOF MmpSlabHeader + SIZEOF ^VOID + (RTL_ALIGN_BYTES - 1))
        & ~(RTL_ALIGN_BYTES - 1)

    i := 0
    count := scache^.BlocksPerSlab
    blocksize := scache^.Size

    WHILE i < count DO
        RtlRemoveEntryList ( CAST block TO ^RtlListEntry )

        i += 1
        block += blocksize
    END

    // Now free the actual pool allocation.

    MmFreePool (
        slab, // ptr
        scache^.Tag, // tag
    )
END

FN (MmPoolCacheAllocateF) MmpAllocateFromSlabCache (
    IN context : ^VOID,
    IN wait : UWORD,
) : ^VOID

    // Allocate a single entry from a slab cache.
    // Return NULLPTR upon failure.

    scache := CAST context TO ^MmpSlabCache

    ipl := MmpLockSlabCache ( scache )

    block := scache^.FreeListHead.Next

    IF block == &scache^.FreeListHead THEN
        // There are no entries so we need to make more.

        block = MmpExtendSlabCache (
            scache, // scache
            ipl, // ipl
            wait, // wait
        )

        IF NOT block THEN
            GOTO Exit
        END
    END

    // Increment the reference count on the slab header.

    (CAST (block - SIZEOF ^VOID) TO ^^MmpSlabHeader)^^.References += 1

    // Pop the block from the free list.

    RtlRemoveEntryList ( CAST block TO ^RtlListEntry )

@Exit

    MmpUnlockSlabCache ( scache, ipl )

    RETURN block
END

FN (MmPoolCacheFreeF) MmpFreeToSlabCache (
    IN context : ^VOID,
    IN ptr : ^VOID,
)

    // Free a block to the given slab cache.

    scache := CAST context TO ^MmpSlabCache

    ipl := MmpLockSlabCache ( scache )

    slabheader := (CAST (ptr - SIZEOF ^VOID) TO ^^MmpSlabHeader)^

    oldcount := slabheader^.References

    slabheader^.References = oldcount - 1

    // Add to free list.

    RtlInsertAtHeadList (
        &scache^.FreeListHead, // head
        CAST ptr TO ^RtlListEntry, // entry
    )

    IF oldcount == 1 THEN
        // Free the whole slab.

        MmpFreeSlab (
            scache, // scache
            slabheader, // slabheader
        )
    END

    MmpUnlockSlabCache ( scache, ipl )
END

#SECTION "PAGEtext"
EXPORT FN MmCreatePoolCacheEx (
    IN node : ^MmpNode,
    IN name : ^UBYTE,
    IN size : UWORD,
    IN pageable : UWORD,
    IN allocfunc : MmPoolCacheAllocateF,
    IN freefunc : MmPoolCacheFreeF,
    IN deletefunc : MmPoolCacheDeleteF,
    IN context : ^VOID,
) : ^MmpPoolCache

    // Allocate and return a new pool cache structure.

    cache : ^MmpPoolCache = MmpAllocateFromSlabCache (
        &node^.PoolCacheSlabs, // scache
        TRUE, // wait
    )

    IF NOT cache THEN
        RETURN NULLPTR
    END

    // Determine the magazine size based on whether the size of each cached
    // block is smaller or larger than what the slab layer considers a small
    // pool block.

    IF size < MMP_SMALL_POOL_BLOCK THEN
        cache^.MagazineType = &node^.MagazineTypeTable[MMP_MAGAZINE_SMALL]
    ELSE
        cache^.MagazineType = &node^.MagazineTypeTable[MMP_MAGAZINE_LARGE]
    END

    // Save the name of the cache.

    cache^.Name = name

    cache^.Allocate = allocfunc
    cache^.Free = freefunc
    cache^.Delete = deletefunc
    cache^.Context = context

    cache^.Node = node

    KeInitializeLock ( &cache^.DepotLock )

    // Set the depot lists to empty.

    MmpInitializeDepotList ( &cache^.FullMagazineList )
    MmpInitializeDepotList ( &cache^.EmptyMagazineList )

    // Insert on global list.

    list : ^MmpPoolCacheList

    IF NOT pageable THEN
        list = &node^.NpPoolCacheList
    ELSE
        list = &node^.PgPoolCacheList
    END

    MmpLockPoolCacheList ( list )

    RtlInsertAtTailList (
        &list^.Head, // head
        &cache^.MasterListEntry, // entry
    )

    // Initialize the per-CPU caches with the global list lock still held to
    // synchronize against changes to the magazine type size.

    cpus := KeQueryProcessorCount ()

    i := 0

    percpu := MmpPoolCachePerCpuById (
        cache, // cache
        0, // id
    )

    WHILE i < cpus DO
        KeInitializeLock ( &percpu^.MagLock )

        percpu^.Loaded = NULLPTR
        percpu^.Previous = NULLPTR
        percpu^.Rounds = -1
        percpu^.PreviousRounds = -1
        percpu^.MagazineSize = cache^.MagazineType^.Size

        i += 1
        percpu += MMP_PCPCPU_SIZE
    END

    MmpUnlockPoolCacheList ( list )

    RETURN cache
END

FN (MmPoolCacheDeleteF) MmpDeleteSlabBackedCache (
    IN context : ^VOID,
)

    // A slab-backed pool cache is being deleted.
    // First, make sure all of the slabs are gone.

    scache := CAST context TO ^MmpSlabCache

    KeAssert ( scache^.ActiveSlabCount == 0 )

    // Now release the slab cache.

    MmpFreeToSlabCache (
        &scache^.Node^.SlabCacheSlabs, // scache
        scache, // ptr
    )
END

EXPORT FN MmCreatePoolCache (
    IN node : ^MmpNode,
    IN name : ^UBYTE,
    IN size : UWORD,
    IN poolindex : UWORD,
    IN tag : UWORD,
) : ^MmpPoolCache

    // Create a slab-backed pool cache.

    scache : ^MmpSlabCache = MmpAllocateFromSlabCache (
        &node^.SlabCacheSlabs, // scache
        TRUE, // wait
    )

    IF NOT scache THEN
        RETURN NULLPTR
    END

    // Initialize the slab cache used for allocating cached blocks.

    MmpInitializeSlabCache (
        node, // node
        scache, // scache
        size, // size
        poolindex, // poolindex
        tag, // tag
    )

    // Create the pool cache with the appropriate slab callbacks.

    cache := MmCreatePoolCacheEx (
        node, // node
        name, // name
        size, // size
        poolindex != MM_NONPAGED_POOL, // pageable
        &MmpAllocateFromSlabCache, // allocfunc
        &MmpFreeToSlabCache, // freefunc
        &MmpDeleteSlabBackedCache, // deletefunc
        scache, // context
    )

    IF NOT cache THEN
        // Failed to allocate the pool cache, so release the slab cache.

        MmpFreeToSlabCache (
            &node^.SlabCacheSlabs, // scache
            scache, // ptr
        )
    END

    RETURN cache
END

FN MmpDestroyAndFreeMagazine (
    IN cache : ^MmpPoolCache,
    IN magazine : ^^VOID,
    IN rounds : UWORD,
)

    // Destroy the magazine.

    // Skip over the depot list link.

    magazine += SIZEOF ^VOID

    // Destroy and free each block contained in the magazine.

    i := 0

    WHILE i < rounds DO
        cache^.Free (
            cache^.Context, // context
            magazine[i], // ptr
        )

        i += 1
    END

    // Un-skip depot list link and free magazine.

    MmFreeToPoolCache (
        cache^.MagazineType^.PoolCache, // cache
        magazine - SIZEOF ^VOID, // ptr
    )
END

FN MmpAllocateMagazineFromDepot (
    IN cache : ^MmpPoolCache,
    IN list : ^MmpDepotList,
) : ^^VOID

    // Allocate a magazine from the depot.

    ipl := MmpLockPoolCacheDepot ( cache )

    magazine := list^.Head

    IF magazine THEN
        list^.Head = magazine^

        list^.Total -= 1

        IF list^.Total < list^.Min THEN
            // Increase the working set size by decreasing the number of
            // magazines that can be reaped.

            list^.Min = list^.Total
        END
    END

    MmpUnlockPoolCacheDepot ( cache, ipl )

    RETURN magazine
END

FN MmpFreeMagazineToDepot (
    IN cache : ^MmpPoolCache,
    IN list : ^MmpDepotList,
    IN magazine : ^^VOID,
)

    // Free a magazine to the depot.

    ipl := MmpLockPoolCacheDepot ( cache )

    magazine^ = list^.Head
    list^.Head = magazine

    list^.Total += 1

    MmpUnlockPoolCacheDepot ( cache, ipl )
END

FN MmpReapDepotList (
    IN cache : ^MmpPoolCache,
    IN list : ^MmpDepotList,
    IN rounds : UWORD,
)

    // Reap magazines from the depot list until it is shrunk to its working set
    // size. Each magazine has the number of rounds specified.

    reap := list^.ReapLimit

    IF reap > list^.Min THEN
        // Don't reap more than was actually used since the last reaping.

        reap = list^.Min
    END

    // rept := 0

    WHILE reap DO
        magazine := MmpAllocateMagazineFromDepot (
            cache, // cache
            list, // list
        )

        IF NOT magazine THEN
            BREAK
        END

        MmpDestroyAndFreeMagazine (
            cache, // cache
            magazine, // magazine
            rounds, // rounds
        )

        // rept += 1
        reap -= 1
    END

    // IF rept THEN
    //     RtlPrint ( "[%s %d] ", cache^.Name, rept )
    // END
END

FN MmpReapPoolCacheDepot (
    IN cache : ^MmpPoolCache,
)

    // Reap magazines from the pool cache depot until all unused entries are
    // gone.

    MmpReapDepotList (
        cache, // cache
        &cache^.FullMagazineList, // list
        cache^.MagazineType^.Size, // rounds
    )

    MmpReapDepotList (
        cache, // cache
        &cache^.EmptyMagazineList, // list
        0, // rounds
    )
END

FN MmpSetPoolCacheWsToZero (
    IN cache : ^MmpPoolCache,
)

    // Set pool cache working set size to zero by making all entries reapable.

    ipl := MmpLockPoolCacheDepot ( cache )

    cache^.FullMagazineList.Min = cache^.FullMagazineList.Total
    cache^.FullMagazineList.ReapLimit = cache^.FullMagazineList.Total

    cache^.EmptyMagazineList.Min = cache^.EmptyMagazineList.Total
    cache^.EmptyMagazineList.ReapLimit = cache^.EmptyMagazineList.Total

    MmpUnlockPoolCacheDepot ( cache, ipl )
END

FN MmpUpdatePoolCacheWs (
    IN cache : ^MmpPoolCache,
)

    // Update the pool cache working set size before a round of reaping.

    ipl := MmpLockPoolCacheDepot ( cache )

    cache^.FullMagazineList.ReapLimit = cache^.FullMagazineList.Min
    cache^.FullMagazineList.Min = cache^.FullMagazineList.Total

    cache^.EmptyMagazineList.ReapLimit = cache^.EmptyMagazineList.Min
    cache^.EmptyMagazineList.Min = cache^.EmptyMagazineList.Total

    MmpUnlockPoolCacheDepot ( cache, ipl )
END

FN MmpPurgeCpuMagazinesPoolCache (
    IN cache : ^MmpPoolCache,
)

    // Purge the per-CPU magazine caches.

    percpu := MmpPoolCachePerCpuById (
        cache, // cache
        0, // id
    )

    cpus := KeQueryProcessorCount ()
    i := 0

    WHILE i < cpus DO
        ipl := MmpLockMagazineCache ( percpu )

        currentmag := percpu^.Loaded
        prevmag := percpu^.Previous
        rounds := CAST percpu^.Rounds TO UWORD
        prevrounds := CAST percpu^.PreviousRounds TO UWORD

        percpu^.Loaded = NULLPTR
        percpu^.Previous = NULLPTR
        percpu^.Rounds = -1
        percpu^.PreviousRounds = -1

        MmpUnlockMagazineCache ( percpu, ipl )

        IF currentmag THEN
            MmpDestroyAndFreeMagazine (
                cache, // cache
                currentmag, // magazine
                rounds, // rounds
            )
        END

        IF prevmag THEN
            MmpDestroyAndFreeMagazine (
                cache, // cache
                prevmag, // magazine
                prevrounds, // rounds
            )
        END

        i += 1
        percpu += MMP_PCPCPU_SIZE
    END
END

FN MmpPurgeMagazinesPoolCache (
    IN cache : ^MmpPoolCache,
)

    // Purge the magazines of the given pool cache.
    // If this is a result of a resize operation then the global cache list
    // lock is held. If it's the result of an MmDeletePoolCache then no lock is
    // needed.

    MmpPurgeCpuMagazinesPoolCache ( cache )

    // Set the working set size of the pool cache to zero.

    MmpSetPoolCacheWsToZero ( cache )

    // Reap down to the new working set size, which is zero.

    MmpReapPoolCacheDepot ( cache )
END

#SECTION "PAGEtext"
EXPORT FN MmDeletePoolCache (
    IN cache : ^MmpPoolCache,
)

    // Delete a pool cache.

    node := cache^.Node

    // Remove from global list.

    list : ^MmpPoolCacheList

    IF NOT cache^.Pageable THEN
        list = &node^.NpPoolCacheList
    ELSE
        list = &node^.PgPoolCacheList
    END

    MmpLockPoolCacheList ( list )

    RtlRemoveEntryList ( &cache^.MasterListEntry )

    MmpUnlockPoolCacheList ( list )

    // Empty out the magazine depot.

    MmpPurgeMagazinesPoolCache ( cache )

    // Call the destructor.

    IF cache^.Delete THEN
        cache^.Delete ( cache^.Context )
    END

    // Free pool cache to pool cache slab cache.
    // Say that ten times fast.

    MmpFreeToSlabCache (
        &node^.PoolCacheSlabs, // scache
        cache, // ptr
    )
END

FN MmpReloadMagazines (
    IN percpu : ^MmpPoolCachePerCpu,
    IN newloaded : ^^VOID,
    IN rounds : WORD,
)

    // Swap the previous and loaded magazines.

    percpu^.Previous = percpu^.Loaded
    percpu^.PreviousRounds = percpu^.Rounds

    percpu^.Loaded = newloaded
    percpu^.Rounds = rounds
END

EXPORT FN MmAllocateFromPoolCache (
    IN cache : ^MmpPoolCache,
    IN wait : UWORD,
) : ^VOID

    // Allocate a block from the pool cache.

    block : ^VOID
    rounds : WORD

    // Acquire a pointer to the pool cache's per-cpu magazine cache.

    percpu := MmpPoolCachePerCpuById (
        cache, // cache
        KeCurrentProcessorId (), // id
    )

    ipl := MmpLockMagazineCache ( percpu )

@Retry

    // Try to grab a block from the loaded magazine.

    rounds = percpu^.Rounds

    IF rounds > 0 THEN
        // NOTE: The cache link pointer in the zeroth element of the magazine is
        //       skipped in a subtle way here that shouldn't be confused with an
        //       off-by-one bug.

        block = percpu^.Loaded[rounds]
        percpu^.Rounds = rounds - 1

        MmpUnlockMagazineCache ( percpu, ipl )

        RETURN block
    END

    // Loaded magazine was empty, try to reload.

    rounds = percpu^.PreviousRounds

    IF rounds > 0 THEN
        MmpReloadMagazines (
            percpu, // percpu
            percpu^.Previous, // newloaded
            rounds, // rounds
        )

        GOTO Retry
    END

    // Can't reload the previous magazine, allocate from the depot.

    magazine := MmpAllocateMagazineFromDepot (
        cache, // cache
        &cache^.FullMagazineList, // list
    )

    IF magazine THEN
        // Got a full magazine.

        IF percpu^.Previous THEN
            // First free the previous magazine to the empty magazine list.

            KeAssert ( percpu^.PreviousRounds == 0 )

            MmpFreeMagazineToDepot (
                cache, // cache
                &cache^.EmptyMagazineList, // list
                percpu^.Previous, // magazine
            )
        END

        MmpReloadMagazines (
            percpu, // percpu
            magazine, // newloaded
            CAST percpu^.MagazineSize TO WORD, // rounds
        )

        GOTO Retry
    END

    MmpUnlockMagazineCache ( percpu, ipl )

    // Magazine layer wasn't of any help so we need to drop through to the slab
    // layer of this cache.

    RETURN cache^.Allocate (
        cache^.Context, // context
        wait, // wait
    )
END

EXPORT FN MmFreeToPoolCache (
    IN cache : ^MmpPoolCache,
    IN ptr : ^VOID,
)

    // Free a block to the pool cache.

    rounds : WORD

    // Acquire a pointer to the pool cache's per-cpu magazine cache.

    percpu := MmpPoolCachePerCpuById (
        cache, // cache
        KeCurrentProcessorId (), // id
    )

    ipl := MmpLockMagazineCache ( percpu )

@Retry

    rounds = percpu^.Rounds

    IF (CAST rounds TO UWORD) < percpu^.MagazineSize THEN
        // There's room in the loaded magazine.
        // Make sure to skip over the depot list link, which occupies the zeroth
        // element of the magazine.

        percpu^.Loaded[rounds + 1] = ptr
        percpu^.Rounds = rounds + 1

        MmpUnlockMagazineCache ( percpu, ipl )

        LEAVE
    END

    // Loaded magazine is full. Swap with previous if empty.

    IF percpu^.PreviousRounds == 0 THEN
        MmpReloadMagazines (
            percpu, // percpu
            percpu^.Previous, // newloaded
            0, // rounds
        )

        GOTO Retry
    END

    IF PsuCurrentNode () != cache^.Node THEN
        // This is a CPU foreign to the preferred NUMA node of the pool cache.
        // Bypass the magazine layer since it won't do any good to have some
        // foreign CPU take up magazines in another NUMA node's pool cache.

        GOTO BypassMagazines
    END

    // Allocate a new magazine into the CPU layer.

    magazine := MmpAllocateMagazineFromDepot (
        cache, // cache
        &cache^.EmptyMagazineList, // list
    )

    IF magazine THEN
        // Got an empty magazine to load.

        IF percpu^.Previous THEN
            // First free the previous magazine to the full magazine list.

            KeAssert ( percpu^.PreviousRounds == percpu^.MagazineSize )

            MmpFreeMagazineToDepot (
                cache, // cache
                &cache^.FullMagazineList, // list
                percpu^.Previous, // magazine
            )
        END

        // Load it and free the block into it.

        MmpReloadMagazines (
            percpu, // percpu
            magazine, // newloaded
            0, // rounds
        )

        GOTO Retry
    END

    // The depot is out of empty magazines.
    // Unlock the magazine cache and allocate a new one.

    magtype := cache^.MagazineType

    MmpUnlockMagazineCache ( percpu, ipl )

    magazine = MmAllocateFromPoolCache (
        magtype^.PoolCache, // cache
        FALSE, // wait
    )

    ipl = MmpLockMagazineCache ( percpu )

    IF magazine THEN
        // Got a magazine.

        IF percpu^.MagazineSize != magtype^.Size THEN
            // The magazine type size was changed.
            // Retry.

            MmpUnlockMagazineCache ( percpu, ipl )

            MmFreeToPoolCache (
                magtype^.PoolCache, // cache
                magazine, // ptr
            )

            ipl = MmpLockMagazineCache ( percpu )

            GOTO Retry
        END

        // Add to the depot and retry.

        MmpFreeMagazineToDepot (
            cache, // cache
            &cache^.EmptyMagazineList, // list
            magazine, // magazine
        )

        GOTO Retry
    END

@BypassMagazines

    MmpUnlockMagazineCache ( percpu, ipl )

    // Failed to get a magazine, our last resort is to just free the block
    // directly to the slab layer.

    cache^.Free (
        cache^.Context, // context
        ptr, // ptr
    )
END

#SECTION "INITtext"
FN MmpInitializeMagazineType (
    IN node : ^MmpNode,
    IN magtype : ^MmpMagazineType,
    IN name : ^UBYTE,
    IN size : UWORD,
)

    // Initialize a magazine type.

    magtype^.Size = size

    magtype^.PoolCache = MmCreatePoolCache (
        node, // node
        name, // name
        (size + 1) * SIZEOF ^VOID, // size
        MM_NONPAGED_POOL, // poolindex
        'Magz', // tag
    )

#ENTERSECTION "INITtext"
    IF NOT magtype^.PoolCache THEN
        KeCrash ( "MmpInitializeMagazineType: failed to create pool cache\n" )
    END
#LEAVESECTION

END

FN MmpAdjustPoolCache (
    IN cache : ^MmpPoolCache,
)

    // Adjust a pool cache.
    // This involves reaping the working set.

    MmpUpdatePoolCacheWs ( cache )

    MmpReapPoolCacheDepot ( cache )
END

FN MmpAdjustPoolCaches (
    IN list : ^MmpPoolCacheList,
    IN purgepercpu : UWORD,
    IN empty : UWORD,
)

    // Adjust all of the pool caches on the given node.

    MmpLockPoolCacheList ( list )

    listhead := &list^.Head
    listentry := listhead^.Next

    WHILE listentry != listhead DO
        cache := CONTAINEROF listentry TO MmpPoolCache.MasterListEntry

        IF empty THEN
            MmpPurgeMagazinesPoolCache ( cache )

        ELSE
            IF purgepercpu THEN
                MmpPurgeCpuMagazinesPoolCache ( cache )
            END

            MmpAdjustPoolCache ( cache )
        END

        listentry = listentry^.Next
    END

    MmpUnlockPoolCacheList ( list )
END

#MACRO MmpInitializePoolCacheList ( list ) [
    KeInitializeLock ( &(list)^.MasterListLock )
    RtlInitializeList ( &(list)^.Head )
]

#SECTION "INITtext"
FN MmpInitializePoolCache (
    IN node : ^MmpNode,
)

    // Initialize the pool cache.

    MmpInitializePoolCacheList ( &node^.PgPoolCacheList )
    MmpInitializePoolCacheList ( &node^.NpPoolCacheList )

    // Initialize a slab cache to allocate pool caches from.

    MmpInitializeSlabCache (
        node, // node
        &node^.PoolCacheSlabs, // scache
        MMP_PC_SIZE + KeQueryProcessorCount () * MMP_PCPCPU_SIZE, // size
        MM_NONPAGED_POOL, // poolindex
        'PoCa', // tag
    )

    // Initialize a slab cache to allocate slab caches from.

    MmpInitializeSlabCache (
        node, // node
        &node^.SlabCacheSlabs, // scache
        SIZEOF MmpSlabCache, // size
        MM_NONPAGED_POOL, // poolindex
        'PoSl', // tag
    )

    // Initialize the magazine types.

    MmpInitializeMagazineType (
        node, // node
        &node^.MagazineTypeTable[MMP_MAGAZINE_SMALL], // magtype
        "Small Block Magazines", // name
        MMP_SMALL_MAGAZINE_SIZE, // size
    )

    MmpInitializeMagazineType (
        node, // node
        &node^.MagazineTypeTable[MMP_MAGAZINE_LARGE], // magtype
        "Large Block Magazines", // name
        MMP_LARGE_MAGAZINE_SIZE, // size
    )
END