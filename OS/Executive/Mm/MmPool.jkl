//
// Implements system memory pool management.
//

#INCLUDE "Mi.hjk"

// This is the shift for the minimum block size (i.e. 1 << 5 = 32).

#DEFINE MI_BLOCK_SIZE_SHIFT 5
#DEFINE MI_BLOCK_MIN_SIZE [(1 << MI_BLOCK_SIZE_SHIFT)]
#DEFINE MI_BLOCK_SIZE_MASK [(MI_BLOCK_MIN_SIZE - 1)]

// We track block sizes in units of minimum block sizes. Since we store this in
// a byte, the maximum block size is the minimum block size times 256 (or,
// shifted left by 8). Actually, here we use 6 (1 << 6 = 64 units max) to keep
// the size of the pool structures, and time spent scanning list heads down.

#DEFINE MI_BLOCK_MAX_UNITS_SHIFT 6
#DEFINE MI_BLOCK_MAX_SIZE_SHIFT [(MI_BLOCK_SIZE_SHIFT + MI_BLOCK_MAX_UNITS_SHIFT)]
#DEFINE MI_BLOCK_MAX_SIZE [(1 << MI_BLOCK_MAX_SIZE_SHIFT)]
#DEFINE MI_BLOCK_MAX_SIZE_MASK [(MI_BLOCK_MAX_SIZE - 1)]

// The maximum request size is four units less than the maximum size.
// This avoids some weird edge cases. It's also more time-efficient to use the
// page-aligned allocator for larger requests.

#DEFINE MI_BLOCK_MAX_REQUEST_UNITS [((1 << MI_BLOCK_MAX_UNITS_SHIFT) - 4)]

#DEFINE MI_FULL_BLOCKS_PER_EXTENSION [(RTL_PAGE_SIZE / MI_BLOCK_MAX_SIZE - 1)]

#DEFINE MI_BLOCK_LOG_BUCKETS [(MI_BLOCK_MAX_UNITS_SHIFT + 1)]
#DEFINE MI_BLOCK_SIZE_BUCKETS [(1 << MI_BLOCK_MAX_UNITS_SHIFT) + 1]

#DEFINE MI_BLOCK_SWIFT_MAGIC 0xC0
#DEFINE MI_BLOCK_FREE_MAGIC 0xE4
#DEFINE MI_BLOCK_INVALID_MAGIC 0xA5

STRUCT MiBlock
    BucketIndex : UBYTE,
    LastSize : UBYTE,
    Magic : UBYTE,
    Size : UBYTE,

    Tag : ULONG,
END

STRUCT MiFreeBlock
    Block : MiBlock,

    LogEntry : RtlListEntry,
    SizeEntry : RtlListEntry,
END

STRUCT MiPoolExtension
    Pool : ^MiPool,
    References : ULONG,
END

FNPTR MiPoolGetMemoryF (
    IN pool : ^MiPool,
) : ^MiPoolExtension

FNPTR MiPoolReturnMemoryF (
    IN ptr : ^VOID,
)

STRUCT MiPool
    Pushlock : KePushlock,

    GetMemory : MiPoolGetMemoryF,
    ReturnMemory : MiPoolReturnMemoryF,

    BytesUsedInternally : UWORD,
    BytesUsedExternally : UWORD,
    BytesUsedPeak : UWORD,

    LogListHeads : RtlListEntry[MI_BLOCK_LOG_BUCKETS],
    SizeListHeads : RtlListEntry[MI_BLOCK_SIZE_BUCKETS],
END

PUBLIC MiNonpagedPool : MiPool
MiPagedPool : MiPool
MiPageTrackingPool : MiPool

MiNonpagedPoolColor : ULONG = 0

FN (MiPoolGetMemoryF) MiGetNonpagedExtension (
    IN pool : ^MiPool,
) : ^MiPoolExtension
    
    // Allocate an extension for nonpaged pool. If the required page frame can't
    // be immediately allocated, return NULLPTR. Caller will decide whether to
    // wait for free memory and retry the allocation, or give up.

    printed := FALSE

@Retry

    ext := CAST MiAllocateChunkSpace (
        &MiPoolSpace, // chunkspace
    ) TO ^MiPoolExtension

    IF NOT ext THEN
        // Uh-oh! If we're out of pool space there isn't much good to be done.
        // Sleep for 500ms and retry.

        IF NOT printed THEN
            RtlPrint ( "Out of pool space!\n" )

            printed = TRUE
        END

        interval : RtlUquad
        
        RtlSetUquadToUlong ( &interval, 500 )

        KeSleep (
            &interval, // interval
            KE_KERNEL_MODE, // waitmode
            FALSE, // alertable
        )

        GOTO Retry
    END

    color := KeIncrementUlong (
        &MiNonpagedPoolColor, // ptr
        1, // inc
    )

    // Allocate a page frame to place here.

    pfe := MiAllocatePage (
        &MiSystemPartition, // partition
        FALSE, // zeroed
        FALSE, // low
        color, // color
    )

    IF NOT pfe THEN
        // Free the pool space chunk.
        // No need to flush TB since we didn't access it.

        MiFreeChunkSpace (
            &MiPoolSpace, // chunkspace
            ext, // ptr
            FALSE, // flush
        )

        RETURN NULLPTR
    END

    // Map the page frame.
    // Note that no TB entry exists for this page in any CPU if we've been
    // given it by the pool space allocator.

    pte := MI_PTE_ADDRESS ( ext )

    pte[0] = MI_BUILD_POOL_PTE ( MI_PFE_TO_PFN ( pfe ) )

    RETURN ext
END

FN (MiPoolReturnMemoryF) MiReturnNonpagedExtension (
    IN ptr : ^VOID,
)

    // Free the page frames within this extension and return it to nonpaged
    // space. The space allocator will deal with flushing the TB.

    pte := MI_PTE_ADDRESS ( ptr )
    ptecontents := pte[0]

    // Clear the PTE, makes it more likely we'll see it if a bad pointer within
    // this chunk is used later. Due to the TB it's not 100% though.

    pte[0] = MI_INVALID_KERNEL_PTE

#IF BLD_CHK
    // Make it even more likely by at least flushing this page on the current
    // processor.

    KeFlushMyTbAddress ( ptr )
#END

    MiFreePage (
        &MiSystemPartition, // partition
        MI_PFN_TO_PFE ( MI_PFN_FROM_PTE ( ptecontents ) ), // pfe
    )

    MiFreeChunkSpace (
        &MiPoolSpace, // chunkspace
        ptr, // ptr
        TRUE, // flush
    )
END

FN (MiPoolGetMemoryF) MiGetPagedExtension (
    IN pool : ^MiPool,
) : ^MiPoolExtension
    
    // Allocate an extension for paged pool.

    KeCrash ( "NYI MiGetPagedExtension\n" )
END

FN (MiPoolReturnMemoryF) MiReturnPagedExtension (
    IN ptr : ^VOID,
)

    // Free an extension for paged pool.

    KeCrash ( "NYI MiReturnPagedExtension\n" )
END

#MACRO MiFindPoolExtension ( ptr ) [
    (CAST (ptr) & RTL_PAGE_NUMBER_MASK TO ^MiPoolExtension)
]

#SECTION "INITtext"
FN MiInitializePool (
    IN pool : ^MiPool,
)

    // Initialize a pool.

    KeInitializePushlock ( &pool^.Pushlock )

    pool^.BytesUsedInternally = 0
    pool^.BytesUsedExternally = 0
    pool^.BytesUsedPeak = 0

    i := 0

    WHILE i < MI_BLOCK_LOG_BUCKETS DO
        RtlInitializeList ( &pool^.LogListHeads[i] )

        i += 1
    END

    i = 0

    WHILE i < MI_BLOCK_SIZE_BUCKETS DO
        RtlInitializeList ( &pool^.SizeListHeads[i] )

        i += 1
    END
END

#SECTION "INITtext"
FN MiInitializeNonpagedPool (
    IN pool : ^MiPool,
)

    // Initialize a nonpaged pool.

    MiInitializePool ( pool )

    pool^.GetMemory = &MiGetNonpagedExtension
    pool^.ReturnMemory = &MiReturnNonpagedExtension
END

#SECTION "INITtext"
FN MiInitializePagedPool (
    IN pool : ^MiPool,
)

    // Initialize a paged pool.

    MiInitializePool ( pool )

    pool^.GetMemory = &MiGetPagedExtension
    pool^.ReturnMemory = &MiReturnPagedExtension
END

#SECTION "INITtext"
FN MiInitializePools ()

    // Initialize the system pools.

    MiInitializeNonpagedPool ( &MiNonpagedPool )

    MiInitializePagedPool ( &MiPagedPool )

    MiInitializePagedPool ( &MiPageTrackingPool )
END

MiEightBitLog : UBYTE[256] = {
    0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
}

#MACRO MiAcquirePool ( pool ) [
    KeAcquireApcSafePushlockExclusive ( &pool^.Pushlock )
]

#MACRO MiReleasePool ( pool, ipl ) [
    KeReleaseApcSafePushlock ( &pool^.Pushlock, ipl )
]

FN MiAllocateFromPool (
    IN pool : ^MiPool,
    IN bytes : UWORD,
    IN tag : ULONG,
    IN wait : UWORD,
) : ^VOID

    // Allocate a block of memory of at least the given number of bytes from the
    // specified pool.

    bytes += SIZEOF MiBlock

    bytes += MI_BLOCK_SIZE_MASK
    bytes >>= MI_BLOCK_SIZE_SHIFT

#IF BLD_CHK
    IF bytes > MI_BLOCK_MAX_REQUEST_UNITS THEN
        KeCrash ( "MiAllocateFromPool: too large %u\n", bytes )
    END
#END

    // Bytes now stores size units rather than real bytes.

    // We want to start searching in the bucket ceil(log_2(units)).
    // We place blocks in bucket floor(log_2(units)).

    insertindex := MiEightBitLog[bytes]

    bucketindex := insertindex

    IF 1 << insertindex != bytes THEN
        // Not a power of two number of units, so ceil log is floor log + 1.

        bucketindex += 1
    END

@Retry

    // Do some work outside the pool lock.

    listhead := &pool^.SizeListHeads[bytes]
    i := bytes
    max := 1 << bucketindex

    block : ^MiFreeBlock

    // Lock the pool.

    ipl := MiAcquirePool ( pool )

    // Search the inbetween lists up to the next power of two.

    WHILE i < max DO
        IF NOT RtlEmptyList ( listhead ) THEN
            // Found a block.

            block = CONTAINEROF listhead^.Next TO MiFreeBlock.SizeEntry

#IF BLD_CHK
            IF block^.Block.Size != i THEN
                KeCrash ( "MiAllocateFromPool: bad 2 %p %u\n", block, i )
            END
#END

            GOTO FoundBlock
        END

        i += 1
        listhead += SIZEOF RtlListEntry
    END

    // Search the log lists.

    listhead = &pool^.LogListHeads[bucketindex]
    i = bucketindex

    WHILE i < MI_BLOCK_LOG_BUCKETS DO
        IF NOT RtlEmptyList ( listhead ) THEN
            // Found a block.

            block = CONTAINEROF listhead^.Next TO MiFreeBlock.LogEntry

#IF BLD_CHK
            IF block^.Block.BucketIndex != i THEN
                KeCrash ( "MiAllocateFromPool: bad 3 %p %u\n", block, i )
            END
#END

            GOTO FoundBlock
        END

        i += 1
        listhead += SIZEOF RtlListEntry
    END

    // No sufficient block. We need to allocate a new pool extension.

    ext := pool^.GetMemory ( pool )

    IF NOT ext THEN
        // Failed to allocate a pool extension.

        MiReleasePool ( pool, ipl )

        IF NOT wait THEN
            // Caller requested that we don't wait upon failure.

            RETURN NULLPTR
        END

        // Wait for free memory and retry.

        MiWaitForPages (
            &MiSystemPartition, // partition
            FALSE, // low
        )

        GOTO Retry
    END

    // Increment external usage. Note that a pool chunk is one page frame.

    pool^.BytesUsedExternally += RTL_PAGE_SIZE

    // Increment pool statistics.

    pool^.BytesUsedInternally += bytes << MI_BLOCK_SIZE_SHIFT

    IF pool^.BytesUsedInternally > pool^.BytesUsedPeak THEN
        pool^.BytesUsedPeak = pool^.BytesUsedInternally
    END

    // Initialize the extension header.

    ext^.Pool = pool
    ext^.References = 1

    // We need to initialize the extension as a single block of the maximum size
    // minus whatever is used by the extension header, minus whatever we need
    // for our allocation.

    // Here we assume that a maximum size block is <= the chunk size, i.e.,
    // there's always room for at least one within a new extension.

    // We also assume that the extension header fits within a single block unit
    // (currently 32 bytes).

    block = CAST ext + MI_BLOCK_MIN_SIZE TO ^MiFreeBlock

    // Initialize the block we'll be returning to the caller.

    block^.Block.Magic = MI_BLOCK_SWIFT_MAGIC
    block^.Block.Size = bytes
    block^.Block.BucketIndex = insertindex
    block^.Block.LastSize = 0
    block^.Block.Tag = tag

    // Initialize the new block.

    newblock := block + (bytes << MI_BLOCK_SIZE_SHIFT)

    newblocksize := (1 << MI_BLOCK_MAX_UNITS_SHIFT) - 1

#IF BLD_CHK
    IF bytes > newblocksize THEN
        // If the allocation request was this large, it should have been
        // dispatched to the page aligned allocator.

        KeCrash ( "MiAllocateFromPool: large allocation %u\n", bytes )
    END
#END

    newblocksize -= bytes

    newbucketindex := MiEightBitLog[newblocksize]

    newblock^.Block.Magic = MI_BLOCK_FREE_MAGIC
    newblock^.Block.Size = newblocksize
    newblock^.Block.BucketIndex = newbucketindex
    newblock^.Block.LastSize = bytes

    // Insert the new block in the free list.

    RtlInsertAtHeadList (
        &pool^.LogListHeads[newbucketindex], // head
        &newblock^.LogEntry, // entry
    )

    RtlInsertAtHeadList (
        &pool^.SizeListHeads[newblocksize], // head
        &newblock^.SizeEntry, // entry
    )

    newblock += newblocksize << MI_BLOCK_SIZE_SHIFT

    i = 0

    WHILE i < MI_FULL_BLOCKS_PER_EXTENSION DO
        // Initialize this full block.

        newblock^.Block.Magic = MI_BLOCK_FREE_MAGIC
        newblock^.Block.Size = 1 << MI_BLOCK_MAX_UNITS_SHIFT
        newblock^.Block.BucketIndex = MI_BLOCK_MAX_UNITS_SHIFT
        newblock^.Block.LastSize = 0

        // Insert the new block into the buckets indexed by floor-log and size.

        RtlInsertAtHeadList (
            &pool^.LogListHeads[MI_BLOCK_MAX_UNITS_SHIFT], // head
            &newblock^.LogEntry, // entry
        )

        RtlInsertAtHeadList (
            &pool^.SizeListHeads[1 << MI_BLOCK_MAX_UNITS_SHIFT], // head
            &newblock^.SizeEntry,
        )

        newblock += MI_BLOCK_MAX_SIZE
        i += 1
    END

    // Unlock the pool.

    MiReleasePool ( pool, ipl )

    // Return the block.

    RETURN block + SIZEOF MiBlock

@FoundBlock

#IF BLD_CHK
    IF block^.Block.Magic != MI_BLOCK_FREE_MAGIC THEN
        KeCrash ( "MiAllocateFromPool: bad %p\n", block )
    END
#END

    // This block is either perfectly sized, or at least big enough to
    // satisfy the allocation request. In either case, we want to
    // unlink it from the bucket's free list now.

    RtlRemoveEntryList ( &block^.SizeEntry )

    RtlRemoveEntryList ( &block^.LogEntry )

    // Increment the reference count on the pool extension to which this
    // free block belongs, since in any case, we're going to be adding
    // a new allocated block to it.

    ext = MiFindPoolExtension ( block )
    ext^.References += 1

    // Set magic to indicate allocated, since in either case we'll be
    // returning this block to the caller.

    block^.Block.Magic = MI_BLOCK_SWIFT_MAGIC

    // Increment pool statistics.

    pool^.BytesUsedInternally += bytes << MI_BLOCK_SIZE_SHIFT

    IF pool^.BytesUsedInternally > pool^.BytesUsedPeak THEN
        pool^.BytesUsedPeak = pool^.BytesUsedInternally
    END

    // Set tag.

    block^.Block.Tag = tag

    // Load the block size and check.

    newblocksize = block^.Block.Size

    IF newblocksize != bytes THEN
        // The block is too big and must be split.

#IF BLD_CHK
        IF newblocksize < bytes THEN
            KeCrash ( "MiAllocateFromPool: smaller block\n" )
        END
#END

        // Set new bucketindex and size in old block header.

        block^.Block.BucketIndex = insertindex
        block^.Block.Size = bytes

        // Calculate the size of the new block.

        newblocksize -= bytes

        // Calculate the index of the bucket to place the new block in.

        newbucketindex = MiEightBitLog[newblocksize]

        // Get a pointer to the new block.

        newblock = block + (bytes << MI_BLOCK_SIZE_SHIFT)

        // Create new block header.

        newblock^.Block.Size = newblocksize
        newblock^.Block.LastSize = bytes
        newblock^.Block.BucketIndex = newbucketindex
        newblock^.Block.Magic = MI_BLOCK_FREE_MAGIC

        // Insert the new block into the buckets indexed by floor-log and size.

        RtlInsertAtHeadList (
            &pool^.LogListHeads[newbucketindex], // head
            &newblock^.LogEntry, // entry
        )

        RtlInsertAtHeadList (
            &pool^.SizeListHeads[newblocksize], // head
            &newblock^.SizeEntry,
        )

        // Update next block to point to the new block, unless it is
        // aligned to a maximum block size, in which case there is no next
        // block.

        newblock += newblocksize << MI_BLOCK_SIZE_SHIFT

        IF newblock & MI_BLOCK_MAX_SIZE_MASK THEN
            newblock^.Block.LastSize = newblocksize
        END
    END

    // Unlock the pool.

    MiReleasePool ( pool, ipl )

    // Return the block.

    RETURN block + SIZEOF MiBlock
END

FN MiFreeToPool (
    IN ptr : ^VOID,
    IN tag : ULONG,
)

    // Free the pool block. We're only passed blocks that were small enough to
    // go in POOLSPACE.

    otherblock : ^MiFreeBlock

    // Acquire a pointer to the block.

    block := CAST ptr - SIZEOF MiBlock TO ^MiFreeBlock

    IF tag != block^.Block.Tag THEN
        KeCrash ( "MiFreeToPool: wrong tag %x on %p (expected %x)\n", block^.Block.Tag, ptr, tag )
    END

    // Acquire a pointer to the pool extension.

    ext := MiFindPoolExtension ( block )

    pool := ext^.Pool

    merged := FALSE

    blocksize := block^.Block.Size

    // Lock the pool in which the block resides.

    ipl := MiAcquirePool ( pool )

    pool^.BytesUsedInternally -= blocksize << MI_BLOCK_SIZE_SHIFT

    IF block^.Block.LastSize THEN
        // Check the block to the left for merging.

        otherblock = block - (block^.Block.LastSize << MI_BLOCK_SIZE_SHIFT)

#IF BLD_CHK
        IF otherblock^.Block.Size != block^.Block.LastSize THEN
            KeCrash ( "MiFreeBlock: bad block left %p %p\n", otherblock, block )
        END
#END

        IF otherblock^.Block.Magic == MI_BLOCK_FREE_MAGIC THEN
            // Free! Merge left.

            merged = TRUE

            // Remove it from old free lists.

            RtlRemoveEntryList ( &otherblock^.LogEntry )

            RtlRemoveEntryList ( &otherblock^.SizeEntry )

            // Increment our block size.

            blocksize += otherblock^.Block.Size

#IF BLD_CHK
            // Invalidate magic number of old block, since it's now in the
            // middle of this new block.

            block^.Block.Magic = MI_BLOCK_INVALID_MAGIC
#END

            // Set block pointer to left block.

            block = otherblock
        END
    END

    // Get a pointer to the block to the right.

    otherblock = block + (blocksize << MI_BLOCK_SIZE_SHIFT)

    IF otherblock & MI_BLOCK_MAX_SIZE_MASK THEN
        // A block to the right exists if it's not aligned to the maximum block
        // size.

        IF otherblock^.Block.Magic == MI_BLOCK_FREE_MAGIC THEN
            // Free! Merge right.

            merged = TRUE

            // Remove it from old free lists.

            RtlRemoveEntryList ( &otherblock^.LogEntry )

            RtlRemoveEntryList ( &otherblock^.SizeEntry )

            // Increment our block size.

            blocksize += otherblock^.Block.Size

#IF BLD_CHK
            // Invalidate magic number of old block, since it's now in the
            // middle of the new block.

            otherblock^.Block.Magic = MI_BLOCK_INVALID_MAGIC
#END
        END
    END

    // Decrement the refcount on the extension.

    ext^.References -= 1

    IF NOT ext^.References THEN
        // The extension is totally empty and should be released.
        // This involves removing all of its blocks (except this one!) from the
        // free lists and then returning the extension from whence it came.

        // The form of the extension should be a partial block (with a piece cut
        // out for the extension header) plus a number of maximum sized blocks.
        // First unlink the partial block.

        otherblock = CAST ext + MI_BLOCK_MIN_SIZE TO ^MiFreeBlock

        IF otherblock != block THEN
#IF BLD_CHK
            IF otherblock^.Block.Magic != MI_BLOCK_FREE_MAGIC THEN
                KeCrash ( "MiFreeToPool: not free 1 %p\n", otherblock )
            END
#END

            RtlRemoveEntryList ( &otherblock^.LogEntry )

            RtlRemoveEntryList ( &otherblock^.SizeEntry )
        END

        // Now unlink the full blocks.

        otherblock += MI_BLOCK_MAX_SIZE - MI_BLOCK_MIN_SIZE

        i := 0

        WHILE i < MI_FULL_BLOCKS_PER_EXTENSION DO
            IF otherblock != block THEN
#IF BLD_CHK
                IF otherblock^.Block.Magic != MI_BLOCK_FREE_MAGIC THEN
                    KeCrash ( "MiFreeToPool: not free 2 %p\n", otherblock )
                END
#END

                RtlRemoveEntryList ( &otherblock^.LogEntry )

                RtlRemoveEntryList ( &otherblock^.SizeEntry )
            END

            i += 1
            otherblock += MI_BLOCK_MAX_SIZE
        END

        // Now return the extension.

        pool^.BytesUsedExternally -= RTL_PAGE_SIZE

        pool^.ReturnMemory ( ext )

        // Unlock pool and return.

        MiReleasePool ( pool, ipl )

        LEAVE
    END

    IF merged THEN
        // Re-calculate bucket index and set new fields.

        block^.Block.BucketIndex = MiEightBitLog[blocksize]
        block^.Block.Size = blocksize

        // Set last size of block to our right.

        otherblock = block + (blocksize << MI_BLOCK_SIZE_SHIFT)

        IF otherblock & MI_BLOCK_MAX_SIZE_MASK THEN
            otherblock^.Block.LastSize = blocksize
        END
    END

    // Set free magic.

    block^.Block.Magic = MI_BLOCK_FREE_MAGIC

    // Put on free lists.

    RtlInsertAtHeadList (
        &pool^.LogListHeads[block^.Block.BucketIndex], // head
        &block^.LogEntry, // entry
    )

    RtlInsertAtHeadList (
        &pool^.SizeListHeads[blocksize], // head
        &block^.SizeEntry, // entry
    )

    // Unlock pool and return.

    MiReleasePool ( pool, ipl )
END