//
// Implements support for Partition objects.
//

// Partial NUMA support is implemented throughout the memory manager, mostly to
// make it easier to add full NUMA support later. Some things that would need
// doing in order to make it really great:
//
//  o Splitting the worker thread pool to be per-node.
//  o Splitting the object and thread reaper lists to be per-node.
//  o Splitting the object allocation caches (possibly by remodeling ObuType to
//    be itself a per-node thing).
//  o Splitting the IO packet allocation caches and other caches.

#INCLUDE "Mmp.hjk"

FN MmpInitializeAvailablePageList (
    IN list : ^MmpAvailablePageList,
)

    // Initialize a list of available pages.

    list^.Count = 0

    i := 0

    WHILE i < MMP_COLOR_COUNT DO
        RtlInitializeList ( &list^.Heads[i] )

        i += 1
    END
END

FN MmpInitializePartitionStage1 (
    IN partition : ^MmpPartition,
    IN node : ^MmpNode,
)

    // Perform the first part of initialization for a memory partition.
    // This is split in two so that we can use it while initializing the system
    // partition.

    partition^.Node = node

    // Initialize the locks.

    KeInitializeLock ( &partition^.ListLock )

    KeInitializeLock ( &partition^.CommitLock )

    // Initialize the events.

    KeInitializeEvent (
        &partition^.LowMemoryEvent, // event
        "LowMemory", // name
        FALSE, // notification
        FALSE, // signalstate
    )

    KeInitializeEvent (
        &partition^.PageAvailableEvent, // event
        "PageAvailable", // name
        TRUE, // notification
        TRUE, // signalstate
    )

    KeInitializeEvent (
        &partition^.LowPageAvailableEvent, // event
        "LowPageAvailable", // name
        TRUE, // notification
        TRUE, // signalstate
    )

    KeInitializeEvent (
        &partition^.ModifiedPageEvent, // event
        "ModifiedPages", // name
        FALSE, // notification
        FALSE, // signalstate
    )

    KeInitializeEvent (
        &partition^.ZeroPageEvent, // event
        "ZeroPages", // name
        FALSE, // notification
        FALSE, // signalstate
    )

    // Initialize the list heads.

    RtlInitializeList ( &partition^.ModifiedListHead )
    partition^.ModifiedPageCount = 0

    MmpInitializeAvailablePageList ( &partition^.FreeList )
    MmpInitializeAvailablePageList ( &partition^.ZeroList )
    MmpInitializeAvailablePageList ( &partition^.StandbyList )

    partition^.AvailablePageCount = 0
    partition^.FluidPageCount = 0

    // Initialize commit.

    partition^.CommitUsage = 0
    partition^.CommitLimit = 0
    partition^.TheoreticalCommitLimit = 0

    // Initialize thresholds.

    partition^.LowPageCount = 0
    partition^.SufficientPageCount = 0
    partition^.ModifiedPageMaximum = 0
    partition^.ZeroingThreshold = 0

    partition^.SizeLevel = MM_UNINITIALIZED_SYSTEM
END

FN MmpSetPartitionSize (
    IN partition : ^MmpPartition,
)

    // Calculate the partition size and various threshold values.

    membytes := partition^.TotalPages << RTL_PAGE_SHIFT
    size : UWORD

    IF membytes <= 3 * 1024 * 1024 THEN
        // Tiny, 0-3MB.

        size = MM_TINY_SYSTEM

    ELSEIF membytes <= 5 * 1024 * 1024 THEN
        // Small, 3-5MB.

        size = MM_SMALL_SYSTEM

    ELSEIF membytes <= 9 * 1024 * 1024 THEN
        // Medium, 5-9MB.

        size = MM_MEDIUM_SYSTEM

    ELSEIF membytes <= 33 * 1024 * 1024 THEN
        // Large, 9-33MB.

        size = MM_LARGE_SYSTEM

    ELSE
        // Massive, >33MB.

        size = MM_MASSIVE_SYSTEM
    END

    partition^.SizeLevel = size

    // Set the modified page maximum.

    IF size <= MM_TINY_SYSTEM THEN
        partition^.ModifiedPageMaximum = 50

    ELSEIF size <= MM_LARGE_SYSTEM THEN
        partition^.ModifiedPageMaximum = 100

    ELSE
        partition^.ModifiedPageMaximum = 300
    END

    // Set the page zeroing threshold.

    IF size <= MM_TINY_SYSTEM THEN
        partition^.ZeroingThreshold = 75

    ELSEIF size <= MM_MEDIUM_SYSTEM THEN
        partition^.ZeroingThreshold = 150

    ELSE
        partition^.ZeroingThreshold = 500
    END

    // Set the paging thresholds.

    IF size <= MM_TINY_SYSTEM THEN
        partition^.LowPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 8
        partition^.SufficientPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 50

    ELSEIF size <= MM_LARGE_SYSTEM THEN
        partition^.LowPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 20
        partition^.SufficientPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 100

    ELSE
        partition^.LowPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 100
        partition^.SufficientPageCount = MMP_BLOCK_FOR_PAGES_THRESHOLD + 500
    END
END

FN MmpInsertPageIntoList (
    IN list : ^MmpAvailablePageList,
    IN pfe : ^MmpPfe,
    IN head : UWORD,
)

    // Insert the page into the specified list, into the correct color bucket.

    pfn := MmpPfeToPfn ( pfe )

    list^.Count += 1

    IF head THEN
        RtlInsertAtHeadList (
            &list^.Heads[MmpPfnColor ( pfn )], // head
            &pfe^.Entry, // entry
        )

    ELSE
        RtlInsertAtTailList (
            &list^.Heads[MmpPfnColor ( pfn )], // head
            &pfe^.Entry, // entry
        )
    END
END

FN MmpAllocatePageFromList (
    IN list : ^MmpAvailablePageList,
    IN color : UWORD,
) : ^MmpPfe

    // Allocate a page, preferably with the given color, from the list.
    // The caller already ensured there's a page to remove from the list.

    list^.Count -= 1

#IF ( == MMP_COLOR_COUNT 1 )
    KeAssert ( NOT RtlEmptyList ( &list^.Heads[0] ) )

    entry := list^.Heads[0].Next

    RtlRemoveEntryList ( entry )

    RETURN CONTAINEROF entry TO MmpPfe.Entry

#ELSE
    i := 0

    WHILE i < MMP_COLOR_COUNT DO
        entry := list^.Heads[color].Next

        IF entry != &list^.Heads[color] THEN
            // Found one. Pop it from the head.

            RtlRemoveEntryList ( entry )

            RETURN CONTAINEROF entry TO MmpPfe.Entry
        END

        color = (color + 1) & (MMP_COLOR_COUNT - 1)
        i += 1
    END

    // Shouldn't be reachable - caller saw there were items in this list.

    KeAssert ( FALSE )
#END

END

FN MmpAllocatePageFromStandbyList (
    IN partition : ^MmpPartition,
    IN color : UWORD,
) : ^MmpPfe

    // Allocate a page from the given standby list.

    pfe := MmpAllocatePageFromList (
        &partition^.StandbyList, // list
        color, // color
    )

    // Disassociate it from its object.
    // If this is paged pool, paged executive, or a page table, this is a "dummy
    // object" used only for locking purposes.

    object := pfe^.Object

    // No need to call this as APC-safe since we're already blocking out APCs
    // by holding the list lock.

    KeAcquireLockExclusive ( &object^.StructureLock )

    // Set object pointer to NULLPTR. This is important so that it notices that
    // the owner of the page "changed" if there is a concurrent reference being
    // taken out on this page.

    pfe^.Object = NULLPTR

    IF pfe^.Type == MMP_BACKED_PFE_TYPE THEN
        // Remove from AVL tree of object.

        ob := CONTAINEROF object TO MmuBackedObject.Hdr

        RtlRemoveAvl (
            &ob^.PageTreeRoot, // root
            &pfe^.U.Backed.Entry, // node
        )

    ELSE

        KeAssert ( pfe^.Type == MMP_ANON_PFE_TYPE )

        // Reset the tracking table entry for this anonymous page.

        entry := pfe^.U.Anon.TrackingTableEntry
        entry^ = pfe^.U.Anon.Backing

        // If this wasn't a page of paged pool or the paged executive, the
        // tracking table entry resides in page tracking pool, and we can
        // decrement the refcount on that page of tracking pool, which may
        // allow it to be paged out if it gets trimmed from the system working
        // set.
        //
        // Note that if it WAS paged pool or paged executive, the containing
        // page for the tracking PTE was an actual system space page table -
        // we never page those out!
        //
        // Note that *user* page tables can be reclaimed, but are *not*
        // reclaimed here. Freeing them up when the last PTE has been trimmed
        // out of a page table is the province of architecture-specific pmap
        // code.

        IF pfe^.Flags & MMP_PAGED_POOL_PFE_FLAG == 0 THEN
            poolpfe := MmpPfnToPfe (
                MmpPfnFromPte (
                    (MmpPteAddress ( entry ))^
                )
            )

            // Tracking pool should consist of anonymous pages.

            KeAssert ( poolpfe^.Type == MMP_ANON_PFE_TYPE )

            // This page of tracking pool should have at least 2
            // references: one for being pinned (due to having this tracking
            // entry resident), and another for being in the system working
            // set.

            KeAssert ( poolpfe^.References >= 2 )

            poolpfe^.References -= 1
        END
    END

    KeReleaseLock ( &object^.StructureLock )

    RETURN pfe
END

FN MmpAllocatePage (
    IN partition : ^MmpPartition,
    IN zeroed : UWORD,
    IN low : UWORD,
    IN color : UWORD,
) : ^MmpPfe

    // Allocate a page from the given partition. If none available, return
    // NULLPTR.

    pfe : ^MmpPfe = NULLPTR
    mustzero := FALSE
    listentry : ^RtlListEntry

    // Ensure color within range.

    color &= MMP_COLOR_COUNT - 1

    ipl := MmpAcquireListExclusive ( partition )

    avail := partition^.AvailablePageCount

    IF avail == 0 THEN
        // No pages.

        GOTO Out
    END

    IF NOT low AND avail <= MMP_BLOCK_FOR_PAGES_THRESHOLD THEN
        // Not enough pages.

        GOTO Out
    END

    IF zeroed THEN
        IF partition^.ZeroList.Count THEN
            pfe = MmpAllocatePageFromList (
                &partition^.ZeroList, // list
                color, // color
            )

        ELSE
            // Need to grab a free or standby page. Make sure to zero out the
            // page outside the list lock.

            mustzero = TRUE

            IF partition^.FreeList.Count THEN
                pfe = MmpAllocatePageFromList (
                    &partition^.FreeList, // list
                    color, // color
                )

            ELSE
                pfe = MmpAllocatePageFromStandbyList (
                    partition, // partition
                    color, // color
                )
            END
        END

    ELSEIF partition^.FreeList.Count THEN
        pfe = MmpAllocatePageFromList (
            &partition^.FreeList, // list
            color, // color
        )

    ELSEIF partition^.ZeroList.Count THEN
        pfe = MmpAllocatePageFromList (
            &partition^.ZeroList, // list
            color, // color
        )

    ELSE
        pfe = MmpAllocatePageFromStandbyList (
            partition, // partition
            color, // color
        )
    END

    avail -= 1
    partition^.AvailablePageCount = avail

    IF avail < partition^.LowPageCount THEN
        // Too few pages. Signal the low memory event.

        KeSignalEvent (
            &partition^.LowMemoryEvent, // event
            0, // priorityboost
        )
    END

@Out

    MmpReleaseList ( partition, ipl )

    IF mustzero THEN
        KeAssert ( pfe != NULLPTR )

        MmZeroPage ( MmpPfeToPfn ( pfe ) )
    END

    RETURN pfe
END

FN MmpFreePage (
    IN partition : ^MmpPartition,
    IN pfe : ^MmpPfe,
)

    // Free the page to the specified partition.

    ipl := MmpAcquireListExclusive ( partition )

    avail := partition^.AvailablePageCount
    avail += 1

    partition^.AvailablePageCount = avail

    // Insert at the head so that we reuse it more quickly (hot in cache).

    MmpInsertPageIntoList (
        &partition^.FreeList, // list
        pfe, // pfe
        TRUE, // head
    )

    IF partition^.FreeList.Count > partition^.ZeroingThreshold AND
        partition^.ZeroPageEvent.Header.SignalCount == 0 THEN

        // Wake the zero page worker.

        KeSignalEvent (
            &partition^.ZeroPageEvent, // event
            0, // priorityboost
        )
    END

    MmpReleaseList ( partition, ipl )

    // Wake waiters for available pages.

    MmpNewAvailablePage ( partition, avail )
END

#DEFINE MMP_MIN_LOOPSU_FOR_BACKOFF 2
#DEFINE MMP_INITIAL_BACKOFF_MS 5
#DEFINE MMP_MAX_BACKOFF_MS 1000

FN MmpWaitForPages (
    IN partition : ^MmpPartition,
    IN low : UWORD,
) : UWORD

    // Wait for available pages to exist from the given partition.
    // This function provides no guarantees - caller will have to repeatedly
    // call it until MmpAllocatePage yields a page.

    // Returns TRUE if a timeout occurred, FALSE otherwise.
    // If a timeout occurred, that indicates that the partition did not have
    // enough fluid pages for its workload, or is missing a pagefile, and has
    // deadlocked.

    // Randomized exponential back-off is performed to mitigate thundering herd.
    // Some bits of the current thread pointer are used as a seed for xorshift.

    loops := 0
    threshold : UWORD
    event : ^KeEvent

    timeout : RtlUquad
    RtlSetUquadToUlong ( &timeout, 60000 )

    backoff : RtlUquad
    backoffms := MMP_INITIAL_BACKOFF_MS

    IF low THEN
        threshold = 0
        event = &partition^.LowPageAvailableEvent

    ELSE
        threshold = MMP_BLOCK_FOR_PAGES_THRESHOLD
        event = &partition^.PageAvailableEvent
    END

    ipl := MmpAcquireListExclusive ( partition )

    WHILE partition^.AvailablePageCount <= threshold DO
        // Wait on the event until we catch the available page count at a
        // sufficient level.

        KeResetEvent ( event )

        MmpReleaseList ( partition, ipl )

        IF loops >= MMP_MIN_LOOPSU_FOR_BACKOFF THEN
            // Perform exponential backoff.

            seed : UWORD

            IF loops == MMP_MIN_LOOPSU_FOR_BACKOFF THEN
                // Initialize the xorshift seed which is the low bits of the
                // current thread pointer shifted right by the natural
                // alignment and XORed with the VPN and the current uptime.
                // This tries to improve uniqueness of the seed between each
                // thread and over time.

                thrd := KeCurrentThread ()
                seed = (thrd >> RTL_ALIGN_SHIFT) $ (thrd >> RTL_PAGE_SHIFT)
#IF ( == BLD_BITS 32 )
                seed $= KeSharedUserPage^.Uptime.Low
#ELSE
                seed $= KeSharedUserPage^.Uptime.Quad
#END
            END

            // Jitter the backoff interval by the low 3 bits of the seed.

            backoffms += seed & 7

            IF backoffms >= MMP_MAX_BACKOFF_MS THEN
                backoffms = 1 + (seed & 31)
            END

            RtlSetUquadToUlong ( &backoff, backoffms )

            KeSleep (
                &backoff, // interval
                KE_KERNEL_MODE, // waitmode
                FALSE, // alertable
            )

            // Multiply the backoff interval by two.

            backoffms *= 2

            seed $= seed << 13
            seed $= seed >> 17
            seed $= seed << 5
        END

        status := KeWaitForSingleObject (
            KE_KERNEL_MODE, // waitmode
            KE_UNALERTABLE, // alertable
            &timeout, // timeout
            &event^.Header, // object
        )

        IF status == OS_STATUS_WAIT_TIMEOUT THEN
            IF NOT MmpIsPartitionPhysical ( partition ) THEN
                // If a node partition is deadlocked, this is a fatal
                // condition.

                KeCrash (
                    "Mm: Deadlocked. EVI=%u FRE=%u ZRO=%u MOD=%u AVL=%u\n",
                    partition^.StandbyList.Count,
                    partition^.FreeList.Count,
                    partition^.ZeroList.Count,
                    partition^.ModifiedPageCount,
                    partition^.AvailablePageCount,
                )
            END

            RETURN TRUE
        END

        loops += 1

        ipl = MmpAcquireListExclusive ( partition )
    END

    MmpReleaseList ( partition, ipl )

    RETURN FALSE
END

FN MmpAllocatePageWait (
    IN partition : ^MmpPartition,
    IN zeroed : UWORD,
    IN low : UWORD,
    IN color : UWORD,
) : ^MmpPfe

    // Allocate a page with the given parameters. Allowed to wait. Returns
    // NULLPTR on timeout (indicative of partition deadlock).

    WHILE TRUE DO
        pfe := MmpAllocatePage (
            partition, // partition
            zeroed, // zeroed
            low, // low
            color, // color
        )

        IF pfe THEN
            RETURN pfe
        END

        IF MmpWaitForPages (
            partition, // partition
            low, // low
        ) THEN
            RETURN NULLPTR
        END
    END
END

FN MmuChargeCommit (
    IN partition : ^MmpPartition,
    IN pages : UWORD,
    IN wait : UWORD,
) : OsStatus

    // Attempt to charge the specified commit to the memory partition.
    // It would be unwise to page this routine as it can be called during
    // nonpaged pool allocation.

    status := OS_STATUS_SUCCESS

    // Acquire the commit lock to block out pagefile contraction that
    // might lower the commit limit and cause us to proceed erroneously.

    ipl := KeAcquireApcLockExclusive ( &partition^.CommitLock )

    IF partition^.CommitUsage + pages < pages THEN
        // Overflows the commit usage.

        status = OS_STATUS_COMMIT_EXCEEDED

        GOTO Exit
    END

    IF partition^.CommitUsage + pages > partition^.TheoreticalCommitLimit THEN
        // Don't even bother trying, there's no way to extend the pagefiles to
        // accommodate this because the theoretical commit limit represents what
        // we could theoretically increase the commit limit to if we were to
        // extend all of the pagefiles to their maximum size.

        status = OS_STATUS_COMMIT_EXCEEDED

        GOTO Exit
    END

    // Increase the commit usage.
    // If it goes over the limit, us and anyone else trying to charge commit
    // will spin below until a pagefile expansion succeeds.

    KeIncrementPtr (
        &partition^.CommitUsage, // ptr
        pages, // inc
    )

    WHILE partition^.CommitUsage > partition^.CommitLimit DO
        KeReleaseApcLock ( &partition^.CommitLock, ipl )

        status = MmpExpandPageFiles (
            partition, // partition
            wait, // wait
            FALSE, // full
        )

        IF NOT wait THEN
            // Proceed no matter what.

            RETURN status
        END

        ipl = KeAcquireApcLockExclusive ( &partition^.CommitLock )

        IF OsError ( status ) THEN
            // Failed to increase commit limit.
            // Remove the commit charge.

            KeIncrementPtr (
                &partition^.CommitUsage, // ptr
                -pages, // inc
            )

            GOTO Exit
        END
    END

@Exit

    KeReleaseApcLock ( &partition^.CommitLock, ipl )

    RETURN status
END

FN MmuUnchargeCommit (
    IN partition : ^MmpPartition,
    IN pages : UWORD,
)

    // Remove the specified commit charge from the partition.
    // If pagefiles can now be contracted, that will be noticed at the next tick
    // of the responsible worker thread.

    old := KeIncrementPtr (
        &partition^.CommitUsage, // ptr
        -pages, // inc
    )

    KeAssert ( pages <= old )
END

EXPORT FN MmGetSystemSize () : UWORD

    // Get the size of the current node.

    RETURN PsCurrentPartition ()^.SizeLevel
END

#SECTION "PAGEtext"
FN (ObuTypeDeleteF) MmpDeletePartitionObject (
    IN object : ^VOID,
) : UWORD

    // Delete a partition object.

    KeCrash ( "TODO MmpDeletePartitionObject\n" )
END

#SECTION "PAGEtext"
FN (ObuTypeInitializeF) MmpInitializePartitionObject (
    IN object : ^VOID,
    IN context : ^VOID,
) : OsStatus

    // Initialize a partition object.

    KeCrash ( "TODO MmpInitializePartitionObject\n" )
END

PUBLIC MmuPartitionType : ObuType = {
    [Name] = "Partition",

    [Delete] = &MmpDeletePartitionObject,

    [Initialize] = &MmpInitializePartitionObject,

    [WaitOffset] = OBU_TYPE_NO_WAIT_OFFSET,
    [TypeIdentifier] = OS_PARTITION_TYPE,
    [Tag] = 'MmPr',

    [TypicalBodySize] = SIZEOF MmpPartition,

    [IsPaged] = FALSE,
}