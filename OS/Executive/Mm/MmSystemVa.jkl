//
// Implements system address space allocation for the MINTIA Memory Manager.
//

#INCLUDE "Mi.hjk"
#INCLUDE "../../Loader/Headers/Loader.hjk"

STRUCT MiChunkEntry
    Next : ^MiChunkEntry,
END

PUBLIC MiPoolSpace : MiChunkSpace
PUBLIC MiCacheSpace : MiChunkSpace

PUBLIC MiCacheSpaceChunkPages : UWORD

MiDynamicSpaceRoot : RtlAvlNode
MiDynamicSpacePushlock : KePushlock

MiDynamicSpacePages : UWORD

#SECTION "INITtext"
FN MiInitializeChunkSpace (
    IN chunkspace : ^MiChunkSpace,
    IN base : ^VOID,
    IN entryshift : UWORD,
    IN pages : UWORD,
)

    // Initialize a chunked region of system space.

    entrysize := 1 << entryshift
    entrycount := (pages << RTL_PAGE_SHIFT) / entrysize
    entrypages := entrysize >> RTL_PAGE_SHIFT

    chunkspace^.EntryShift = entryshift
    chunkspace^.EntryCount = entrycount
    chunkspace^.FreeListHead = NULLPTR

    chunkspace^.PendingFlushCount = 0

    KeInitializePushlock ( &chunkspace^.Pushlock )

    // Link the chunks through the PTEs.

    pte := MI_PTE_ADDRESS ( base )

    WHILE entrycount DO
        entry := CAST pte TO ^MiChunkEntry

        entry^.Next = chunkspace^.FreeListHead
        chunkspace^.FreeListHead = entry

        entrycount -= 1
        pte += entrypages * SIZEOF MiPte
    END
END

FN MiFlushChunkSpace (
    IN chunkspace : ^MiChunkSpace,
)

    // Flush TB entries across all processors for the delayed chunks.

    // Insert these entries into the free list.

    i := 0
    max := chunkspace^.PendingFlushCount

    WHILE i < max DO
        chunk := CAST MI_PTE_ADDRESS ( chunkspace^.PendingFlush[i] )
            TO ^MiChunkEntry

        chunk^.Next = chunkspace^.FreeListHead
        chunkspace^.FreeListHead = chunk

        i += 1
    END

    chunkspace^.PendingFlushCount = 0

    // Flush the TB.

    IF chunkspace^.EntryShift == RTL_PAGE_SHIFT AND
        max < 16 THEN

        // Chunks are pages, and there's fewer than 16.
        // Flush them individually.

        KeFlushMultipleTb (
            &chunkspace^.PendingFlush[0], // vaddrtable
            max, // pagecount
        )

    ELSE
        // Chunks are multiple pages, or there's more than 16.
        // Flush everyone's entire TB. Don't keep global pages.

        KeSweepTb ( FALSE )
    END
END

FN MiAllocateChunkSpace (
    IN chunkspace : ^MiChunkSpace,
) : ^VOID

    // Allocate a chunk from the given chunk space.
    // Returns the virtual address of the chunk. Nothing is mapped into the
    // returned virtual address - this is the caller's responsibility.
    // Returns NULLPTR if no chunks remaining.

    ipl := KeAcquireApcSafePushlockExclusive ( &chunkspace^.Pushlock )

    chunk := chunkspace^.FreeListHead

    IF NOT chunk THEN
        IF NOT chunkspace^.PendingFlushCount THEN
            KeReleaseApcSafePushlock ( &chunkspace^.Pushlock, ipl )

            RETURN NULLPTR
        END

        // There are chunks pending flush.
        // We can flush them and grab the first freed one.

        MiFlushChunkSpace ( chunkspace )

        chunk = chunkspace^.FreeListHead
    END

    chunkspace^.FreeListHead = chunk^.Next

    KeReleaseApcSafePushlock ( &chunkspace^.Pushlock, ipl )

    RETURN MI_VIRTUAL_ADDRESS ( chunk )
END

FN MiFreeChunkSpace (
    IN chunkspace : ^MiChunkSpace,
    IN ptr : ^VOID,
    IN flush : UWORD,
)

    // Return a chunk to the given chunk space.

    ipl := KeAcquireApcSafePushlockExclusive ( &chunkspace^.Pushlock )

    IF flush THEN
        // Insert on the delayed flush table.

        count := chunkspace^.PendingFlushCount

        IF count == MI_MAXIMUM_CHUNKS_PENDING_FLUSH THEN
            // Full. Flush it.

            MiFlushChunkSpace ( chunkspace )

            count = 0
        END

        chunkspace^.PendingFlush[count] = ptr
        chunkspace^.PendingFlushCount = count + 1

    ELSE
        // Insert directly into the free chunk list.

        chunk := CAST MI_PTE_ADDRESS ( ptr ) TO ^MiChunkEntry

        chunk^.Next = chunkspace^.FreeListHead
        chunkspace^.FreeListHead = chunk
    END

    KeReleaseApcSafePushlock ( &chunkspace^.Pushlock, ipl )
END

#SECTION "INITtext"
FN MiInitializeSystemVa ()

    // Initialize the system space allocation.

    // There are three regions of dynamically managed system space:
    //
    // MI_POOL_SPACE:     Sized at boot time with enough page tables for a
    //                    quantity of virtual space equivalent to the total
    //                    physical memory in the system.
    //
    //                    The free list for these pages is threaded through the
    //                    page tables.
    //
    //                    Maximum size on 32-bit is capped at 256MB.
    //
    //
    // MI_CACHE_SPACE:    Occupies 4x phys mem of virtual space. Page tables are
    //                    allocated at boot time. Used to map demand-paged views
    //                    of cached files. Allocated in fixed size chunks,
    //                    varying in size depending on the system size:
    //
    //                    Tiny:   32KB
    //                    *:      64KB
    //                    Large+: 256KB
    //
    //                    The free list for these chunks is threaded through the
    //                    page tables.
    //
    //                    Maximum size on 32-bit is capped at 256MB.
    //
    //
    // MI_DYNAMIC_SPACE:  Page tables are allocated at boot time. Allocations
    //                    can be any count of pages. Used to map kernel stacks,
    //                    MDLs, etc.
    //
    //                    An AVL tree is used to allocate this space. The AVL
    //                    nodes (containing parent, left child, right child, and
    //                    an optional MmObject pointer) are allocated in bulk
    //                    from nonpaged pool on-demand and stored in a lookaside
    //                    list.
    //
    //                    Maximum size on 32-bit is capped at 256MB.

    size := MiSystemPartition.SizeLevel

#IF BLD_CHK
    IF SIZEOF MiChunkEntry > SIZEOF MiPte THEN
        KeCrash ( "MiChunkEntry > MiPte\n" )
    END
#END

    // Initialize nonpaged space.

    MiInitializeChunkSpace (
        &MiPoolSpace, // chunkspace
        MI_POOL_SPACE, // base
        RTL_PAGE_SHIFT, // entryshift
        KeLoaderBlock.PoolSpaceSize, // pages
    )

    // Initialize cache space.

    entryshift : UWORD

    IF size <= MI_TINY_SYSTEM THEN
        entryshift = 15 // 1 << 15 = 32KB

    ELSEIF size < MI_LARGE_SYSTEM THEN
        entryshift = 16 // 1 << 16 = 64KB

    ELSE
        entryshift = 18 // 1 << 18 = 256KB
    END

    MiCacheSpaceChunkPages = (1 << entryshift) >> RTL_PAGE_SHIFT

    MiInitializeChunkSpace (
        &MiCacheSpace, // chunkspace
        MI_CACHE_SPACE, // base
        entryshift, // entryshift
        KeLoaderBlock.CacheSpaceSize, // pages
    )

    // Initialize dynamic space.

    RtlInitializeAvl ( &MiDynamicSpaceRoot )

    KeInitializePushlock ( &MiDynamicSpacePushlock )

    // Trim enough pages off the end of dynamic space to allow each CPU to have
    // its own page for 'quick' mappings.

    dsize := KeLoaderBlock.DynamicSpaceSize

    IF dsize < KeLoaderBlock.ProcessorCount THEN
        KeCrash ( "Dynamic space too small\n" )
    END

    dsize -= KeLoaderBlock.ProcessorCount

    MiDynamicSpacePages = dsize

    // Set each processor's quick PTE.

    basepte := MI_PTE_ADDRESS ( MI_DYNAMIC_SPACE + (dsize << RTL_PAGE_SHIFT) )

    KeSetQuickPtes (
        basepte, // basepte
        SIZEOF MiPte, // ptesize
    )
END

FN MiFindDynamicSpaceNode (
    IN ptr : ^VOID,
) : ^MiDynamicSpaceNode

    // Find the dynamic space node in which the pointer resides.
    // Returns NULLPTR if no such node exists.

    node : ^MiDynamicSpaceNode

    ipl := KeAcquireApcSafePushlockShared ( &MiDynamicSpacePushlock )

    avlnode := MiDynamicSpaceRoot.Right

    WHILE TRUE DO
        IF NOT avlnode THEN
            node = NULLPTR

            BREAK
        END

        node = CONTAINEROF avlnode TO MiDynamicSpaceNode.Entry

        IF ptr < node^.StartVa THEN
            avlnode = avlnode^.Left

        ELSEIF ptr >= node^.EndVa THEN
            avlnode = avlnode^.Right

        ELSE
            BREAK
        END
    END

    KeReleaseApcSafePushlock ( &MiDynamicSpacePushlock, ipl )

    RETURN node
END