//
// Implements kernel stack management for the memory manager.
//

#INCLUDE "Mmp.hjk"

#SECTION "PAGEtext"
FN (MmPoolCacheAllocateF) MmpAllocateKernelStack (
    IN context : ^VOID,
    IN wait : UWORD,
) : ^VOID

    // Allocate a kernel stack by request of the cache layer.

    mmnode := CAST context TO ^MmpNode

    // Allocate the required system space.

    kstack := MmpAllocateDynamicPages (
        mmnode, // mmnode
        KEU_STACK_PAGES + 1, // pages
    )

    IF NOT kstack THEN
        // Couldn't acquire them.

        RETURN NULLPTR
    END

    pfes : ^MmpPfe[KEU_STACK_PAGES]

    // TEMP: Naive implementation. Full implementation will initialize these
    //       pages as modified anonymous memory so that kernel stacks can be
    //       swapped. We don't yet know exactly what anonymous PFEs will
    //       look like at time of writing.

    i := 0
    ptr := kstack + RTL_PAGE_SIZE

    WHILE i < KEU_STACK_PAGES DO
        // Allocate a physical page.

        pfes[i] = MmpAllocatePageWait (
            mmnode, // mmnode
            FALSE, // zeroed
            FALSE, // low
            MmpVirtualAddressColor ( ptr ), // color
        )

        IF NOT pfes[i] THEN
            // Failed to allocate this page frame.
            // Deallocate the ones we did allocate and return the appropriate
            // status.

            WHILE i DO
                i -= 1

                MmpFreePage (
                    mmnode, // mmnode
                    pfes[i], // pfe
                )
            END

            MmpReleaseDynamicPages (
                mmnode, // mmnode
                kstack, // ptr
                KEU_STACK_PAGES + 1, // pages
                FALSE, // flush
            )

            RETURN NULLPTR
        END

        i += 1
        ptr += RTL_PAGE_SIZE
    END

    // Acquire a pointer to the first PTE for this region.

    pte := MmpPteAddress ( kstack )

    // Set the guard page invalid.

    pte[0] = MMP_INVALID_KERNEL_PTE

    // Skip to the first real stack page.

    pte = &pte[1]

    // Map the stack pages.

    i = 0

    WHILE i < KEU_STACK_PAGES DO
        pte[i] = MmpBuildPoolPte ( MmpPfeToPfn ( pfes[i]) )

        i += 1
    END

    RETURN kstack + RTL_PAGE_SIZE
END

#SECTION "PAGEtext"
FN (MmPoolCacheFreeF) MmpFreeKernelStack (
    IN context : ^VOID,
    IN ptr : ^VOID,
)

    // Free a kernel stack.

    mmnode := CAST context TO ^MmpNode

    // Acquire a pointer to the first PTE for this region.

    pte := MmpPteAddress ( ptr )

    // Free the kernel stack pages.

    i := 0

    WHILE i < KEU_STACK_PAGES DO
        // Load the PTE for this page.

        ptecontents := pte[i]

        KeAssert ( MmpIsPteValid ( ptecontents ) )

        // Clear the PTE, makes it more likely we'll see it if a bad pointer
        // within this space is used later. Due to the TB it's not 100% though.

        pte[i] = MMP_INVALID_KERNEL_PTE

        // Free the page frame.

        // TEMP: Does not yet handle kernel stacks being private anonymous
        //       memory.

        MmpFreePage (
            mmnode, // mmnode
            MmpPfnToPfe ( MmpPfnFromPte ( ptecontents ) ), // pfe
        )

        i += 1
    END

    // Release the system space containing the stack.

    MmpReleaseDynamicPages (
        mmnode, // mmnode
        ptr - RTL_PAGE_SIZE, // ptr
        KEU_STACK_PAGES + 1, // pages
        TRUE, // flush
    )
END

#SECTION "INITtext"
FN MmpInitializeKernelStackCache (
    IN kenode : ^KeuNode,
)

    // Initialize the zones we use for quickly allocating kernel stacks.

    mmnode := kenode^.Mmp

    mmnode^.KernelStackCache = MmCreatePoolCacheEx (
        mmnode, // mmnode
        "Kstacks", // name
        KEU_STACK_PAGES * RTL_PAGE_SIZE, // size
        TRUE, // pageable
        &MmpAllocateKernelStack, // allocfunc
        &MmpFreeKernelStack, // freefunc
        NULLPTR, // deletefunc
        mmnode, // context
    )

#ENTERSECTION "INITtext"
    IF NOT mmnode^.KernelStackCache THEN
        KeCrash ( "MmpInitializeKernelStackCache: failed to create cache\n" )
    END
#LEAVESECTION

END

#SECTION "PAGEtext"
FN MmuCreateKernelStack (
    IN kenode : ^KeuNode,
    IN process : ^PsuProcess,
    OUT kstack : ^VOID,
) : OsStatus

    // Create a kernel stack.

    mmnode := kenode^.Mmp

    quotablock := PsuQuotaBlock ( process )

    // Charge the process's virtual memory quota for the kernel stack.

    status := MmuChargeVmQuota (
        mmnode, // mmnode
        quotablock, // quotablock
        KEU_STACK_PAGES, // pages
    )

    IF OsError ( status ) THEN
        RETURN status
    END

    // Allocate it.

    kstack = MmAllocateFromPoolCache (
        mmnode^.KernelStackCache, // cache
        TRUE, // wait
    )

    IF NOT kstack THEN
        // Failed to allocate it so uncharge and report an error.

        MmuUnchargeVmQuota (
            mmnode, // mmnode
            quotablock, // quotablock
            KEU_STACK_PAGES, // pages
        )

        status = OS_STATUS_NO_MEMORY
    END

    RETURN status
END

#SECTION "PAGEtext"
FN MmuFreeKernelStack (
    IN kenode : ^KeuNode,
    IN process : ^PsuProcess,
    IN kstack : ^VOID,
)

    // Free a kernel stack. It must be in an inswapped state.

    mmnode := kenode^.Mmp

    MmFreeToPoolCache (
        mmnode^.KernelStackCache, // cache
        kstack, // ptr
    )

    // Uncharge the virtual memory quota consumed by the kernel stack.

    MmuUnchargeVmQuota (
        mmnode, // mmnode
        PsuQuotaBlock ( process ), // quotablock
        KEU_STACK_PAGES, // pages
    )
END