//
// Implements quick-mapping.
//

#INCLUDE "Mi.hjk"
#INCLUDE "../../Loader/Headers/Loader.hjk"

STRUCT MiQuickPteBlock
    Locks : KeLock[MI_QUICK_PER_CPU],
    BasePte : ^MiPte,
    NextIndex : UBYTE,
END

#DEFINE MI_QUICK_PTE_BLOCK_SIZE [((SIZEOF MiQuickPteBlock + KE_CACHE_ALIGN - 1) &
    ~(KE_CACHE_ALIGN - 1))]

PUBLIC MiQuickPteBase : ^MiPte

PUBLIC MiQuickPteBlocks : ^MiQuickPteBlock

#ENTERSECTION "INITtext"

#SECTION "INITtext"
FN MiInitializeQuickPages ()

    // Initialize the quick page mappings.

    procs := KeLoaderBlock.ProcessorCount

    MiQuickPteBlocks = MmAllocatePool (
        MM_NONPAGED_POOL, // poolindex
        MI_QUICK_PTE_BLOCK_SIZE * procs, // bytes
        'Quic', // tag
        FALSE, // wait
    )

    IF NOT MiQuickPteBlocks THEN
        KeCrash ( "Failed to allocate quick PTE blocks\n" )
    END

    i := 0

    WHILE i < procs DO
        block := MiQuickPteBlocks + (i * MI_QUICK_PTE_BLOCK_SIZE)

        block^.NextIndex = 0

        block^.BasePte = MiQuickPteBase +
            ((i * MI_QUICK_PER_CPU) * SIZEOF MiPte)

        j := 0

        WHILE j < MI_QUICK_PER_CPU DO
            KeInitializeLock ( &block^.Locks[j] )

            j += 1
        END

        i += 1

    END
END

#LEAVESECTION

FN MmUseQuickPte (
    IN func : MmUseQuickPteF,
    IN pfn : UWORD,
    IN context : ^VOID,
) : OsStatus

    // Allocate a quick mapping for the given PFN.

    ipl := -1

    // Disable migration of the current thread to another processor.

    old := KeControlMigration ( TRUE )

    id := KeCurrentProcessorId ()

    // Trylock all of this processor's quick PTEs.

    block := MiQuickPteBlocks + (id * MI_QUICK_PTE_BLOCK_SIZE)

    i := 0

    WHILE i < MI_QUICK_PER_CPU DO
        IF KeTryAcquireLockExclusive ( &block^.Locks[i] ) THEN
            GOTO GotOne
        END

        i += 1
    END

    // Failed to trylock a page. Increment a counter and lock whatever
    // it lands on.

    i = block^.NextIndex & (MI_QUICK_PER_CPU - 1)
    block^.NextIndex = i + 1

    // Lock the quick page. Only now do we need to mask off KAPCs, to prevent
    // ourselves from self-contending on this lock, blockingly, which would
    // cause a deadlock.

    ipl = KeMaskApcs ()

    KeAcquireLockExclusive ( &block^.Locks[i] )

@GotOne

    // Calculate the PTE and virtual address.

    pte := block^.BasePte + (i * SIZEOF MiPte)
    vaddr := MiVirtualAddress ( pte )

    // Map the page.

    pte[0] = MiBuildPoolPte ( pfn )

    // Flush TB. We only need to flush the local TB because we disabled
    // migration of the current thread to any other CPU.

    KeFlushMyTbAddress ( vaddr )

    // Call provided function.

    status := func (
        vaddr, // vaddr
        context, // context
    )

    // Release the page lock.

    KeReleaseLock ( &block^.Locks[i] )

    // Restore migration.

    KeControlMigration ( old )

    IF ipl != -1 THEN
        // Restore APCs.

        KeUnmaskApcs ( ipl )
    END

    RETURN status
END

FN (MmUseQuickPteF) MiZeroPageFunc (
    IN vaddr : ^VOID,
    IN context : ^VOID,
) : OsStatus

    // Called with the pointer to a quick mapping to zero the page through.

    RtlFillMemoryWithUlong (
        vaddr, // ptr
        RTL_PAGE_SIZE, // sz
        0, // ulong
    )
END

FN MmZeroPage (
    IN pfn : UWORD,
)

    // Zero out a page frame.

    MmUseQuickPte (
        &MiZeroPageFunc, // func
        pfn, // pfn
        NULLPTR, // context
    )
END