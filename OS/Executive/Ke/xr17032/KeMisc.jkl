//
// Various architecture-specific functions.
//

#INCLUDE "../Ki.hjk"
#INCLUDE "../../Mm/xr17032/Mi.hjk"

#ASM [

// a0 - abortblock
// a1 - func
// a2 - context
// outputs:
// a3 - status
KeExceptionJacket:
.export KeExceptionJacket

    // Set up an abort state for the current thread.

    subi sp, sp, 12
    mov  long [sp + 8], lr
    mov  long [sp + 4], s0
    mov  long [sp], s1

    mov  s0, a0

    // Acquire a pointer to the current thread.

    subi t0, zero, 4096
    mov  s1, long [t0 + KiPrb_CurrentThread]

    // Initialize the abort block.

    mov  long [s0 + (KeAbortBlock_Context + OsContext_Sp)], sp

    // Save all the non-volatile (callee-saved) registers that we didn't already
    // save on our stack frame.

    mov  long [s0 + (KeAbortBlock_Context + OsContext_S2)], s2
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S3)], s3
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S4)], s4
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S5)], s5
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S6)], s6
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S7)], s7
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S8)], s8
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S9)], s9
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S10)], s10
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S11)], s11
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S12)], s12
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S13)], s13
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S14)], s14
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S15)], s15
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S16)], s16
    mov  long [s0 + (KeAbortBlock_Context + OsContext_S17)], s17

    // Link it into the thread. No sync needed because we only access the abort
    // list from the context of this thread.

    mov  t1, long [s1 + KeThread_AbortListHead]
    mov  long [s0 + KeAbortBlock_Next], t1
    mov  long [s1 + KeThread_AbortListHead], s0

    // Call the function.

    mov  a0, a2
    jalr lr, a1, 0

.return:

    // Unlink the abort block.

    mov  t0, long [s0 + KeAbortBlock_Next]
    mov  long [s1 + KeThread_AbortListHead], t0

    // Return normally.

    mov  s1, long [sp]
    mov  s0, long [sp + 4]
    mov  lr, long [sp + 8]
    addi sp, sp, 12

    ret

// s0 - abortblock
// s1 - thread
KiAbortVector:
.global KiAbortVector

    // We get vectored here when an abort occurred. We have to restore state
    // from the abort block.

    mov  sp, long [s0 + (KeAbortBlock_Context + OsContext_Sp)]

    // Load the status the caller should receive.

    mov  a3, long [s0 + KeAbortBlock_Status]

    // Restore non-volatile state that wasn't saved on the stack frame.

    mov  s2, long [s0 + (KeAbortBlock_Context + OsContext_S2)]
    mov  s3, long [s0 + (KeAbortBlock_Context + OsContext_S3)]
    mov  s4, long [s0 + (KeAbortBlock_Context + OsContext_S4)]
    mov  s5, long [s0 + (KeAbortBlock_Context + OsContext_S5)]
    mov  s6, long [s0 + (KeAbortBlock_Context + OsContext_S6)]
    mov  s7, long [s0 + (KeAbortBlock_Context + OsContext_S7)]
    mov  s8, long [s0 + (KeAbortBlock_Context + OsContext_S8)]
    mov  s9, long [s0 + (KeAbortBlock_Context + OsContext_S9)]
    mov  s10, long [s0 + (KeAbortBlock_Context + OsContext_S10)]
    mov  s11, long [s0 + (KeAbortBlock_Context + OsContext_S11)]
    mov  s12, long [s0 + (KeAbortBlock_Context + OsContext_S12)]
    mov  s13, long [s0 + (KeAbortBlock_Context + OsContext_S13)]
    mov  s14, long [s0 + (KeAbortBlock_Context + OsContext_S14)]
    mov  s15, long [s0 + (KeAbortBlock_Context + OsContext_S15)]
    mov  s16, long [s0 + (KeAbortBlock_Context + OsContext_S16)]
    mov  s17, long [s0 + (KeAbortBlock_Context + OsContext_S17)]

    b    KeExceptionJacket.return

// outputs:
// a3 - old interrupt state
KiDisableInterrupts:
.global KiDisableInterrupts

    mfcr a3, rs                     // Load current value of RS.
    subi t0, zero, 3                // t0 = 0xFFFFFFFD
    and  t0, a3, t0                 // Mask out the INT bit.
    mtcr rs, t0                     // Write new RS.

    ret

// a0 - old interrupt state
KiRestoreInterrupts:
.global KiRestoreInterrupts

    mtcr rs, a0                     // Write new RS.

    ret

KiEnableInterrupts:
.global KiEnableInterrupts

    mfcr t0, rs
    ori  t0, t0, 2
    mtcr rs, t0

    ret

// Debugger doorstop
.dl 0

KiWaitForInterrupt:
.global KiWaitForInterrupt

    hlt

    ret

// outputs:
// a3 - processor id
KiCurrentProcessor:
.global KiCurrentProcessor

    mfcr a3, whami                  // Load WHO-AM-I control register.

    ret

// outputs:
// a3 - thread
KeCurrentThread:
.export KeCurrentThread

    subi t0, zero, 4096             // Load PRB pointer.
    mov  a3, long [t0 + KiPrb_CurrentThread]

    ret

// outputs:
// a3 - process
KeCurrentProcess:
.export KeCurrentProcess

    subi t0, zero, 4096             // Load PRB pointer.
    mov  a3, long [t0 + KiPrb_CurrentThread]
    mov  a3, long [a3 + KeThread_Process]

    ret

// outputs:
// a3 - current ipl
KiCurrentIpl:
.global KiCurrentIpl

    subi t0, zero, 4096             // Calculate Prb address.
    mov  a3, byte [t0 + KiPrb_Ipl]  // Load IPL.

    ret

// a0 - ptr
// a1 - inc
// outputs:
// a3 - old value
KeIncrementUlong:
.export KeIncrementUlong

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.retry:
    ll   a3, a0                     // Load-locked the location.
    add  t1, a3, a1                 // Add the increment.
    sc   t1, a0, t1                 // Conditionally store the new value.
    beq  t1, .retry                 // If store failed, retry.

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

    ret

// a0 - ptr
// a1 - newvalue
// a2 - expectedvalue
// outputs:
// a3 - origvalue
KeCompareSwapUlong:
.export KeCompareSwapUlong

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.retry:
    ll   a3, a0                     // Load-locked the location.
    sub  t0, a3, a2                 // Compare equality with expected value.
    bne  t0, .exit                  // Not equal, leave.
    sc   t0, a0, a1                 // Conditionally store the new value.
    beq  t0, .retry                 // If store failed, retry.

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.exit:

    ret

// a0 - ptr
// a1 - mask
// outputs:
// a3 - origvalue
KeMaskUlong:
.export KeMaskUlong

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.retry:
    ll   a3, a0                     // Load-locked the location.
    and  t0, a3, a1                 // Mask the value.
    sc   t0, a0, t0                 // Conditionally store the new value.
    beq  t0, .retry                 // If store failed, retry.

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

    ret

// a0 - ptr
// a1 - bitset
// outputs:
// a3 - origvalue
KeOrUlong:
.export KeOrUlong

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.retry:
    ll   a3, a0                     // Load-locked the location.
    or   t0, a3, a1                 // OR the value.
    sc   t0, a0, t0                 // Conditionally store the new value.
    beq  t0, .retry                 // If store failed, retry.

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

    ret

// a0 - ptr
// a1 - newvalue
// outputs:
// a3 - origvalue
KeFetchAndSetUlong:
.export KeFetchAndSetUlong

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

.retry:
    ll   a3, a0                     // Load-locked the location.
    sc   t0, a0, a1                 // Conditionally set the location.
    beq  t0, .retry                 // If store failed, retry.

#IF BLD_MP
    mb                              // Ensure coherence with other processors.
#END

    ret

// Debugger doorstop
.dl 0

KeBreakpoint:
.export KeBreakpoint
    
    brk

    ret

KiFlushMyIcache:
.global KiFlushMyIcache
    
    li   t0, 3
    mtcr icachectrl, t0

    ret

KiFlushMyDcache:
.global KiFlushMyDcache
    
    li   t0, 3
    mtcr dcachectrl, t0

    ret

// inputs:
// a0 - keepglobal
KeSweepMyTb:
.global KeSweepMyTb

    beq  a0, .flushglobal

    li   t0, 2
    mtcr itbctrl, t0
    mtcr dtbctrl, t0

    ret

.flushglobal:

    li   t0, 1
    mtcr itbctrl, t0
    mtcr dtbctrl, t0

    ret


// inputs:
// a0 - address
KeFlushMyTbAddress:
.global KeFlushMyTbAddress

    // Ensure zeroes in the low 12 bits.

    subi t0, zero, 4096
    and  a0, a0, t0

    mtcr itbctrl, a0                // Flush the ITB page.
    mtcr dtbctrl, a0                // Flush the DTB page.

    ret

// inputs:
// a0 - pfn
KiFlushMyIcacheByPhys:
.global KiFlushMyIcacheByPhys

    // Flush a physical page from the icache.

    lshi a0, a0, 12

    // OR the command bits in.

    ori  a0, a0, 2

    // Flush the page.

    mtcr icachectrl, a0

    ret

// inputs:
// a0 - pfn
KiFlushMyDcacheByPhys:
.global KiFlushMyDcacheByPhys

    // Flush a physical page from the dcache.

    lshi a0, a0, 12

    // OR the command bits in.

    ori  a0, a0, 2

    // Flush the page.

    mtcr dcachectrl, a0

    ret

KeMemoryBarrier:
.export KeMemoryBarrier

    mb

    ret

]

#IF BLD_MP

FN (KiIpiF) KiSweepTb (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of a TB shootdown.

    KeSweepMyTb ( context1 )
END

FN (KiIpiF) KiFlushSingleTb (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of a TB shootdown.

    KeFlushMyTbAddress ( CAST context1 TO ^VOID )
END

FN (KiIpiF) KiFlushMultipleTb (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of a TB shootdown.

    vaddrtable := CAST context1 TO ^^VOID

    WHILE context2 DO
        KeFlushMyTbAddress ( vaddrtable^ )

        vaddrtable += SIZEOF ^VOID
        context2 -= 1
    END
END

FN (KiIpiF) KiSweepDcache (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of a Dcache shootdown.

    KiFlushMyDcache ()
END

FN (KiIpiF) KiFlushMultipleDcache (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of a Dcache shootdown.

    pfntable := CAST context1 TO ^^VOID

    WHILE context2 DO
        KiFlushMyDcacheByPhys ( pfntable^ )

        pfntable += SIZEOF ^VOID
        context2 -= 1
    END
END

FN (KiIpiF) KiSweepIcache (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of an Icache shootdown.

    KiFlushMyIcache ()
END

FN (KiIpiF) KiFlushMultipleIcache (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Executes on the target processor of an Icache shootdown.

    pfntable := CAST context1 TO ^^VOID

    WHILE context2 DO
        KiFlushMyIcacheByPhys ( pfntable^ )

        pfntable += SIZEOF ^VOID
        context2 -= 1
    END
END

#END

FN KeSweepTb (
    IN keepglobal : UWORD,
)

    // Flush the entire TB on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiSweepTb, // function
        keepglobal, // context1
        0, // context2
    )

    KiLowerIpl ( ipl )
#END

    KeSweepMyTb ( keepglobal )
END

FN KeFlushSingleTb (
    IN vaddr : ^VOID,
)

    // Flush a single TB entry on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiFlushSingleTb, // function
        vaddr, // context1
        0, // context2
    )

    KiLowerIpl ( ipl )
#END

    KeFlushMyTbAddress ( vaddr )
END

FN KeFlushMultipleTb (
    IN vaddrtable : ^^VOID,
    IN pagecount : UWORD,
)

    // Flush multiple TB entries on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiFlushMultipleTb, // function
        vaddrtable, // context1
        pagecount, // context2
    )

    KiLowerIpl ( ipl )
#END

    WHILE pagecount DO
        KeFlushMyTbAddress ( vaddrtable^ )

        vaddrtable += SIZEOF ^VOID
        pagecount -= 1
    END
END

FN KeSweepDcache ()

    // Flush the entire Dcache on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiSweepDcache, // function
        0, // context1
        0, // context2
    )

    KiLowerIpl ( ipl )
#END

    KiFlushMyDcache ()
END

FN KeFlushDcachePages (
    IN pfntable : ^^VOID,
    IN pagecount : UWORD,
)

    // Flush pages of the Dcache on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiFlushMultipleDcache, // function
        pfntable, // context1
        pagecount, // context2
    )

    KiLowerIpl ( ipl )
#END

    WHILE pagecount DO
        KiFlushMyDcacheByPhys ( pfntable^ )

        pfntable += SIZEOF ^VOID
        pagecount -= 1
    END
END

FN KeSweepIcache ()

    // Flush the entire Icache on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiSweepIcache, // function
        0, // context1
        0, // context2
    )

    KiLowerIpl ( ipl )
#END

    KiFlushMyIcache ()
END

FN KeFlushIcachePages (
    IN pfntable : ^^VOID,
    IN pagecount : UWORD,
)

    // Flush pages of the Icache on all processors.

#IF BLD_MP
    ipl := KiRaiseIpl ( KI_IPL_DPC )

    KiExecuteOnEveryoneElse (
        &KiFlushMultipleIcache, // function
        pfntable, // context1
        pagecount, // context2
    )

    KiLowerIpl ( ipl )
#END

    WHILE pagecount DO
        KiFlushMyIcacheByPhys ( pfntable^ )

        pfntable += SIZEOF ^VOID
        pagecount -= 1
    END
END

FN KeZeroPage (
    IN pfn : UWORD,
)

    // Zero out the page with the given PFN.

    // We use a per-CPU mapping, so raise to block preemption.

    ipl := KiRaiseIpl ( KI_IPL_DPC )

    pteaddr := CAST KI_CURRENT_PRB^.QuickPte TO ^ULONG
    vaddr := MiVirtualAddress ( pteaddr )

    // Map it with the quick page.

    pte := (pfn << 5) | MI_PTE_V | MI_PTE_W | MI_PTE_K | MI_PTE_G

    pteaddr[0] = pte

    // Flush TB.

    KeFlushMyTbAddress ( vaddr )

    // Zero out the page.

    RtlFillMemoryWithUlong (
        vaddr, // ptr
        RTL_PAGE_SIZE, // sz
        0, // ulong
    )

    KiLowerIpl ( ipl )
END