//
// Implements low-level exception handling for XR/17032.
//

#INCLUDE "../Kep.hjk"

#INCLUDE "<ll>/System/OsSignal.hjk"

#INCLUDE "<inc>/Mmu.hjk"

// The exact interface to the HAL for interrupts is private to the architecture.

EXTERN FN HaluInterrupt (
    IN context : ^OsContext,
)

FNPTR KepHighLevelHandlerF (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

KepCauseNames : ^UBYTE[16] = {
    "EXC0",
    "INTERRUPT",
    "SYSCALL",
    "FWCALL",
    "BUSERROR",
    "EXC5",
    "BREAKPOINT",
    "INVINST",
    "PRIVVIOL",
    "UNALIGNED",
    "EXC10",
    "EXC11",
    "PAGFLT(RD)",
    "PAGFLT(WR)",
    "EXC14",
    "EXC15",
}

FN KepFaultCrash (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // Set the FrozenContext to the faulting context because that will be the
    // most relevant information for the debugger.

    prb := KEP_CURRENT_PRB_LOCAL

    IF prb^.FrozenContext THEN
        RtlPrint ( "CPU%d OLD CONTEXT: 0x%p\n", prb^.FrozenContext )
    END

    prb^.FrozenContext = context

    KeCrash (
        "ERS=%08x BADADDR=%08x EPC=%08x ECAUSE=%s\n", // fmt
        context^.Rs,
        badaddr,
        context^.Epc,
        KepCauseNames[context^.Rs >> OS_XR_RS_ECAUSE_SHIFT],
    )
END

EXTERN KepAbortVector : UBYTE

FN KepAbort (
    IN thread : ^KeuThread,
    IN context : ^OsContext,
    IN status : OsStatus,
    IN badaddr : ^VOID,
)

    // Abort the current operation of the thread.

    IF NOT OsStatusIsAddressError ( status ) THEN
        // Not an address error status, so aborting is nonsense.

        KepFaultCrash ( context, badaddr )
    END

    abortblock := thread^.AbortListHead[thread^.ExecutingKapc]

    IF NOT abortblock OR MmuShouldAccessCrash (
        abortblock, // abortblock
        badaddr, // badaddr
        status, // status
    ) THEN
        // No abortable operation was in progress, or this abort block isn't
        // catching this type of error. This is just a kernel bug.

        KepFaultCrash ( context, badaddr )
    END

    // Save the status corresponding to the error.

    abortblock^.Status = status

    // Redirect the trap frame to return to the abort vector.

    context^.S0 = abortblock
    context^.S1 = thread + (thread^.ExecutingKapc * 4)
    context^.Epc = &KepAbortVector
END

FN (KepHighLevelHandlerF) KepSpuriousException (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // Don't know why we're here.

    KeCrash (
        "Spurious Exception EXC=%u ADDR=%p\n", // fmt
        context^.Rs >> OS_XR_RS_ECAUSE_SHIFT,
        badaddr
    )
END

#IF BLD_MP

FN KepProcessIdleDeferredIpiEvents ()

    // There were idle deferred events we need to process.

    prb := KEP_CURRENT_PRB_LOCAL

    events := KeFetchAndSetUlong (
        &prb^.IdleDeferredIpiEvents, // ptr
        0, // ulong
    )

    IF events & KEP_DEFERRED_IDLE_TB_SHOOTDOWN THEN
        // Dump the entire TB right now.

        KeuSweepMyTb ( FALSE )
    END

    IF events & KEP_DEFERRED_IDLE_ICACHE_SHOOTDOWN THEN
        // Dump the entire Icache.

        KepFlushMyIcache ()
    END

    IF events & KEP_DEFERRED_IDLE_DCACHE_SHOOTDOWN THEN
        // Dump my entire Dcache.

        KepFlushMyDcache ()
    END
END

#END

FN (KepHighLevelHandlerF) KepHandleInterrupt (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    prb := KEP_CURRENT_PRB_LOCAL

#IF BLD_MP
    idle := prb^.InIdleLoop

    IF idle THEN
        prb^.InIdleLoop = FALSE

        KeMemoryBarrier ()

        IF prb^.IdleDeferredIpiEvents THEN
            KepProcessIdleDeferredIpiEvents ()
        END
    END
#END

    HaluInterrupt ( context )

    IF prb^.PendingSoftwareInterrupts >> prb^.Ipl THEN
        KepDispatchSoftwareInterrupts ( prb^.Ipl )
    END

#IF BLD_MP
    prb^.InIdleLoop = idle
#END

END

KepExceptionToSignal : UBYTE[16] = {
    [OS_XR_ECAUSE_BUS] = OS_SIGNAL_BUS,
    [OS_XR_ECAUSE_INV] = OS_SIGNAL_ILL,
    [OS_XR_ECAUSE_PRV] = OS_SIGNAL_ILL,
    [OS_XR_ECAUSE_UNA] = OS_SIGNAL_ACV,
}

KepExceptionToStatus : OsStatus[16] = {
    [OS_XR_ECAUSE_BUS] = OS_STATUS_BUS_ERROR,
    [OS_XR_ECAUSE_INV] = OS_STATUS_ILLEGAL_INSTRUCTION,
    [OS_XR_ECAUSE_PRV] = OS_STATUS_ILLEGAL_INSTRUCTION,
    [OS_XR_ECAUSE_UNA] = OS_STATUS_UNALIGNED_FAULT,
}

FN (KepHighLevelHandlerF) KepHandleError (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // An "error" fault occurred. If this happened in kernel mode, figure out
    // if its handled by a SafeCopy function. If not, crash.
    //
    // If it happened in usermode, generate a signal to the thread.

    KepEnableInterrupts ()

    thread := KeCurrentThread ()

    ecause := context^.Rs >> OS_XR_RS_ECAUSE_SHIFT

    IF context^.Rs & OS_XR_RS_OLD_USER THEN
        // Happened in usermode, send a signal.

        thread^.LastFaultStatus = KepExceptionToStatus[ecause]

        KeSignalThread (
            thread, // thread
            KepExceptionToSignal[ecause], // signal
        )

    ELSE
        // Happened in kernel mode, abort the operation.

        KepAbort (
            thread, // thread
            context, // context
            KepExceptionToStatus[ecause], // status
            badaddr, // badaddr
        )
    END

    KepDisableInterrupts ()
END

FN (KepHighLevelHandlerF) KepHandleBreakpoint (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    ecause := context^.Rs >> OS_XR_RS_ECAUSE_SHIFT

    IF context^.Rs & OS_XR_RS_OLD_USER AND ecause != OS_XR_ECAUSE_NMI THEN
        // Usermode breakpoint. Dispatch to debugger or send an illegal
        // instruction signal to the thread if no debugger attached.

        KeCrash ( "NYI Usermode breakpoint\n" )

    ELSEIF KeuDebuggerEntry THEN
        KeuDebuggerEntry ( context )

        IF ecause == OS_XR_ECAUSE_BRK AND context^.Epc == &KeBreakpoint THEN
            // Skip over the explicit breakpoint.

            context^.Epc += 4
        END

    ELSEIF ecause != OS_XR_ECAUSE_NMI THEN
        KeCrash ( "Unhandled kernel mode breakpoint\n" )
    END
END

EXTERN KepStartAbortCasRegion : UBYTE
EXTERN KepEndAbortCasRegion : UBYTE
EXTERN KepAbortCas : UBYTE

FN (KepHighLevelHandlerF) KepHandlePageFault (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // Enable interrupts and dispatch the page fault to Mm.

    IF context^.Epc >= &KepStartAbortCasRegion AND
        context^.Epc < &KepEndAbortCasRegion THEN

        // We cannot handle this page fault because the current thread's
        // turnstile is in use; it can't usefully take locks. Abort the CAS
        // operation.

        context^.Epc = &KepAbortCas

        LEAVE
    END

    KepEnableInterrupts ()

    status := MmuPageFault (
        badaddr, // address
        (context^.Rs >> OS_XR_RS_ECAUSE_SHIFT) == OS_XR_ECAUSE_PFW, // writing
        context^.Rs & OS_XR_RS_OLD_USER, // usermode
    )

    IF OsError ( status ) THEN
        // Failed to handle the fault.

        thread := KeCurrentThread ()

        IF context^.Rs & OS_XR_RS_OLD_USER THEN
            // Happened in usermode. Send a signal.

            thread^.LastFaultStatus = status

            KeSignalThread (
                thread, // thread
                OS_SIGNAL_ACV, // signal
            )

        ELSE
            // Happened in kernel mode. Abort the current operation.

            KepAbort (
                thread, // thread
                context, // context
                status, // status
                badaddr, // badaddr
            )
        END
    END

    KepDisableInterrupts ()
END

#SECTION "text"
KepHandlerTable : KepHighLevelHandlerF[16] = {
    [0] = &KepSpuriousException,
    [OS_XR_ECAUSE_INT] = &KepHandleInterrupt,
    [2] = &KepSpuriousException,
    [3] = &KepSpuriousException,
    [OS_XR_ECAUSE_BUS] = &KepHandleError,
    [OS_XR_ECAUSE_NMI] = &KepHandleBreakpoint,
    [OS_XR_ECAUSE_BRK] = &KepHandleBreakpoint,
    [OS_XR_ECAUSE_INV] = &KepHandleError,
    [OS_XR_ECAUSE_PRV] = &KepHandleError,
    [OS_XR_ECAUSE_UNA] = &KepHandleError,
    [10] = &KepSpuriousException,
    [11] = &KepSpuriousException,
    [OS_XR_ECAUSE_PGF] = &KepHandlePageFault,
    [OS_XR_ECAUSE_PFW] = &KepHandlePageFault,
    [14] = &KepSpuriousException,
    [15] = &KepSpuriousException,
}

#ASM [

// Put symbols here to allow the debugger to know how to interpret the
// context.

KepExceptionHandler:
.export KepExceptionHandler
    mtcr scratch0, t0               // Save T0 as a scratch register.
    mtcr scratch1, sp               // Save the current stack pointer.

    mfcr t0, rs                     // Read the status register.
    andi t0, t0, OS_XR_RS_OLD_USER  // Isolate the old USER bit.
    beq  t0, .waskernel             // If not set, we were already in kernel
                                    // mode. If clear, we entered from usermode.

    subi t0, zero, KEP_PRB_LESS_ZERO // Calculate Prb address.

    // Switch to the current thread's kernel stack.

    mov  sp, long [t0 + KepPrb_KernelStackTop]

.waskernel:

    subi sp, sp, OsContext__SIZEOF   // Create a context block on the stack.

    // Save the context of the processor in order to create a trapframe.

    mfcr t0, scratch0
    mov  long [sp + OsContext_T1], t1
    mov  long [sp + OsContext_T0], t0
    mov  long [sp + OsContext_T2], t2
    mov  long [sp + OsContext_T3], t3
    mov  long [sp + OsContext_T4], t4
    mov  long [sp + OsContext_T5], t5
    mov  long [sp + OsContext_A0], a0
    mov  long [sp + OsContext_A1], a1
    mov  long [sp + OsContext_A2], a2
    mov  long [sp + OsContext_A3], a3
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17
    mov  long [sp + OsContext_Tp], tp
    mfcr t0, scratch1
    mov  long [sp + OsContext_Lr], lr
    mfcr t1, epc
    mov  long [sp + OsContext_Sp], t0
    mfcr t2, rs
    mov  long [sp + OsContext_Epc], t1
    mov  long [sp + OsContext_Rs], t2

    andi s0, t2, OS_XR_RS_OLD_USER  // Isolate the old USER bit.
    beq  s0, .waskernel2            // If not set, we were already in kernel
                                    // mode. If clear, we entered from usermode.

    subi t0, zero, KEP_PRB_LESS_ZERO // Calculate Prb address.

    // Load the current thread.

    mov  s1, long [t0 + KepPrb_CurrentThread]

    // Store the user trapframe address.

    mov  long [s1 + KeuThread_UserFrame], sp

#IF BLD_MP
    // Set current thread as currently in kernel mode.

    mov  byte [s1 + KeuThread_CurrentMode], KE_KERNEL_MODE
#END

.waskernel2:

    rshi t0, t2, OS_XR_RS_ECAUSE_SHIFT // Isolate the exception code.
    la   t1, KepHandlerTable         // Load the address of the handler table.
    mov  t0, long [t1 + t0 LSH 2]   // Load the handler.

    mfcr a1, ebadaddr               // Set bad address as second argument.
    mov  a0, sp                     // Set trapframe as first argument.
    jalr lr, t0, 0                  // Execute handler.

    beq  s0, .waskernel3            // If not set, we were already in kernel
                                    // mode. If clear, we are returning to user
                                    // mode.

#IF BLD_MP
    // Set current thread as currently in usermode.
    // Do this *before* dispatching usermode interrupts, or there's a risk of
    // missed IPIs. This field is advisory for IPI delivery since there's no
    // point sending an IPI to get the thread into the kernel to check its
    // signals, if we're already there.

    mov  byte [s1 + KeuThread_CurrentMode], KE_USER_MODE

    mb
#END

    // Check for pending usermode interrupt.

    mov  t0, byte [s1 + KeuThread_UserInterrupt]

    beq  t0, .waskernel3            // If clear, no pending usermode interrupt.

    jal  KepDispatchUserInterrupts   // Dispatch pending usermode interrupts.

.waskernel3:

    // Restore the context of the processor from the trapframe.

    mov  t0, long [sp + OsContext_Rs]
    mtcr rs, t0
    mov  t1, long [sp + OsContext_Epc]
    mtcr epc, t1
    mov  t0, long [sp + OsContext_T0]
    mov  t1, long [sp + OsContext_T1]
    mov  t2, long [sp + OsContext_T2]
    mov  t3, long [sp + OsContext_T3]
    mov  t4, long [sp + OsContext_T4]
    mov  t5, long [sp + OsContext_T5]
    mov  a0, long [sp + OsContext_A0]
    mov  a1, long [sp + OsContext_A1]
    mov  a2, long [sp + OsContext_A2]
    mov  a3, long [sp + OsContext_A3]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    mov  tp, long [sp + OsContext_Tp]
    mov  lr, long [sp + OsContext_Lr]
    mov  sp, long [sp + OsContext_Sp]

    // Return from the exception.

    rfe

DbgExcEnd:
.export DbgExcEnd

// outputs:
// a3 - oldipl
KeMaskApcs:
.export KeMaskApcs

    li   a0, KEP_IPL_APC             // Set argument to KepRaiseIpl.

    // Fall through.

// a0 - newipl
// outputs:
// a3 - oldipl
KepRaiseIpl:
.global KepRaiseIpl

    // Note: This routine is inlined at KepAcquireSpinlockRaise.
    
    subi t0, zero, KEP_PRB_LESS_ZERO // Calculate Prb address.
    mov  a3, byte [t0 + KepPrb_Ipl]  // Load the old IPL.
    mov  byte [t0 + KepPrb_Ipl], a0  // Store the new IPL.

#IF BLD_CHK

    slt  t0, a0, a3                 // Test newipl < oldipl.
    bne  t0, .badraise              // If lower, this is a bad request.

#END

    ret

#IF BLD_CHK

.badraise:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KepBadRaiseMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

#END

// a0 - newipl
KeUnmaskApcs:
.export KeUnmaskApcs

    // Fall through.

// a0 - newipl
KepLowerIpl:
.global KepLowerIpl

    // Note: This routine is inlined at KepReleaseSpinlockLower.

    subi t0, zero, KEP_PRB_LESS_ZERO // Calculate Prb address.

#IF BLD_CHK

    mov  t1, byte [t0 + KepPrb_Ipl]  // Load old IPL.
    slt  t1, t1, a0                 // Compare oldipl < newipl
    bne  t1, .badlower              // If lower, this is a bad request.

#END

    mov  byte [t0 + KepPrb_Ipl], a0  // Store the new IPL.
    mov  t1, long [t0 + KepPrb_PendingSoftwareInterrupts]
    rsh  t2, t1, a0                 // Right shift pending by new IPL.
    bne  t2, .dispatch              // If zero, none pending at new IPL.

    ret

.dispatch:
    j    KepDispatchSoftwareInterrupts

#IF BLD_CHK

.badlower:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KepBadLowerMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

KepBadRaiseMessage:
    .ds "KepRaiseIpl: oldipl > newipl\n"
    .db 0

KepBadLowerMessage:
    .ds "KepLowerIpl: newipl > oldipl\n"
    .db 0

.align 4

#END

// a0 - thread
KepJumpIntoThread:
.global KepJumpIntoThread

    // Restore context of new thread.

    mov  sp, long [a0 + KeuThread_Context]

    j    LoadContext

// a0 - newthread
// a1 - oldthread
KepSwitchContext:
.global KepSwitchContext
    
    // Save the current context and restore the new.
    // We only need to save the callee-saved registers as this has the same
    // considerations as a function call that trashes them all.
    // We must also release the old thread's thread lock on our way out, after
    // we have fully left its context.

    subi sp, sp, OsContext__SIZEOF
    mov  long [sp + OsContext_Lr], lr
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17

    mov  long [a1 + KeuThread_Context], sp

    // Restore context of new thread.

    mov  sp, long [a0 + KeuThread_Context]

    // Release thread lock. Inline KepReleaseSpinlock here for speed.

#IF BLD_MP
    // Indicate no longer switching off of our stack.

    mov  byte [a1 + KeuThread_Switching], 0

    // Memory barrier to ensure old writes are committed.

    wmb

    // Set spinlock un-owned.

    mov  long [a1 + KeuThread_Spinlock], zero
#END

LoadContext:

    // Set thread to RUNNING.

    mov  byte [a0 + KeuThread_Status], KE_THREAD_RUNNING

    // If there are any KAPCs pending in the new thread, set int at KEP_IPL_APC
    // pending.

    addi t1, a0, KeuThread_KapcListHead
    mov  t0, long [a0 + (KeuThread_KapcListHead + RtlListEntry_Next)]
    sub  t0, t0, t1
    beq  t0, .none

    // Trigger.

    subi a0, zero, (KEP_PRB_LESS_ZERO - KepPrb_PendingSoftwareInterrupts)
    li   a1, (1 << ((KEP_IPL_APC) - 1))
    jal  KeOrUlong

.none:

    mov  lr, long [sp + OsContext_Lr]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    addi sp, sp, OsContext__SIZEOF

    // Return into the new thread.

    ret

// NOTE: KepSwitchMapCode is copied into the wired exception block so that no TB
//       misses are taken while executing it.

// a0 - pgtb
// a1 - asid
KepSwitchMapCode:

    // Disable interrupts.

    mfcr t2, rs                     // Load current value of RS.
    subi t0, zero, 3                // t0 = 0xFFFFFFFD
    and  t0, t2, t0                 // Mask out the INT bit.
    mtcr rs, t0                     // Write new RS.

    // Set the new page directory in DTB entry 0.

    mfcr t1, dtbindex
    mtcr dtbindex, zero

    la   t0, (0xB02C0000 >> 12)
    mtcr dtbtag, t0

    lshi t0, a0, 5
    ori  t0, t0, 0x17
    mtcr dtbpte, t0

    mtcr dtbindex, t1

    // Set the ASID for both TBs.

    lshi a1, a1, 20
    mtcr itbtag, a1
    mtcr dtbtag, a1

    // Restore interrupts.

    mtcr rs, t2

    ret

KepSwitchMapCodeEnd:

KepThreadTrampoline:

    // This is where a new thread begins execution.
    // s0 contains the start function, s1 and s2 contain context pointers.

    // We're at KEP_IPL_DPC, so lower that now.

    li   a0, KEP_IPL_LOW
    jal  KepLowerIpl

    // Set LR to 0 so that stack traces terminate here.

    mov  lr, zero

    // Jump to the start function.

    mov  a0, s1
    mov  a1, s2
    jalr zero, s0, 0

]

EXTERN FN KepThreadTrampoline ()

EXTERN FN KepExceptionHandler ()

EXTERN KepSwitchMapCode : UBYTE
EXTERN KepSwitchMapCodeEnd : UBYTE

FNPTR KepSwitchMapF (
    IN pgtb : UWORD,
    IN asid : UWORD,
)

KepSwitchMap : KepSwitchMapF

#SECTION "INITtext"
FN KepInitializeArchitecture (
    IN prb : ^KepPrb,
)

    // Our KepCurrentProcessor is implemented by reading the WHAMI control
    // register, so it's already okay to do that.

    procid := KepCurrentProcessor ()

    IF procid == 0 THEN
        // Construct a jump instruction that just jumps to our exception
        // handler, and then copy it to the first instruction of each entry of
        // the exception block, except for the TB miss handlers, which have
        // already been set up by Loader.

        eb := CAST KeuLoaderBlock.U.Xr.ExceptionBlock TO ^ULONG

        jmpinstruction := CAST &KepExceptionHandler TO ULONG

        jmpinstruction >>= 2
        jmpinstruction <<= 3
        jmpinstruction |= 6

        i := 0

        WHILE i < 14 DO
            eb^ = jmpinstruction

            i += 1
            eb += 256
        END

        // Copy KepSwitchMap into the zeroth vector. We do this because
        // exception 0 is permanently reserved by the architecture, making it a
        // convenient place to stash this function which *cannot* cause a TB
        // miss during execution.

        RtlCopyBytes (
            KeuLoaderBlock.U.Xr.ExceptionBlock, // dest
            &KepSwitchMapCode, // src
            &KepSwitchMapCodeEnd - &KepSwitchMapCode, // sz
        )

        KepSwitchMap = CAST KeuLoaderBlock.U.Xr.ExceptionBlock TO KepSwitchMapF

        // Copy the syscall handler into the exception block.
        // This one is special because it doesn't need to save as much as the
        // others do.

        // ... TODO ...

        // We modified the instruction stream, so flush the icache.

        KepFlushMyIcache ()
    END

    // Initialize the ASID sequence counter.

    RtlSetUquadToUlong (
        &prb^.AsidSequenceNumber, // ptr
        0, // ulong
    )

    // Initialize the next ASID.

    prb^.NextAsid = 1
END

FN KepSwitchAddressSpace (
    IN process : ^KeuProcess,
)

    // Switch address space to the given process. Interrupts are enabled, thread
    // lock is held. IPL is KEP_IPL_DPC, so we are pinned to this processor.

    IF process^.PageDirectoryPfn == process^.Node^.SystemPageDirectoryPfn THEN
        // Just switch, don't bother dealing with ASIDs since ASID 0 is reserved
        // for the system address space.

        KepSwitchMap (
            process^.PageDirectoryPfn, // pgtb
            0, // asid
        )

        LEAVE
    END

    prb := KEP_CURRENT_PRB_LOCAL

    asidentry := &process^.AsidTable[prb^.ConsecutiveId]

    cpuseq := &prb^.AsidSequenceNumber

    // Check for ASID roll-over.

    IF RtlUquadNeqUquad ( &asidentry^.AsidSequenceNumber, cpuseq ) THEN
        // The ASIDs rolled over at some point, so we have to give this
        // process a new one.

        KeCrash ( "Test ASID rollover\n" )

        asid := prb^.NextAsid
        prb^.NextAsid = asid + 1

        // NOTE: Per the architecture manual we don't use ASID 0xFFF,
        //       so we roll over when we get that one.

        IF asid == 0xFFF THEN
            // Roll over. Flush TB on this processor and increment the sequence
            // number.

            asid = 1
            prb^.NextAsid = 2

            RtlAddUlongToUquad (
                cpuseq, // quad
                1, // ulong
            )

            // Flush my TB. Keep global pages because we only use ASIDs for
            // private pages, no need to waste system space TB entries.

            KeuSweepMyTb ( TRUE )
        END

        asidentry^.Asid = asid

        RtlMoveUquad (
            &asidentry^.AsidSequenceNumber, // destquad
            cpuseq, // srcquad
        )
    END

    // Perform the low-level address space switch.

    KepSwitchMap (
        process^.PageDirectoryPfn, // pgtb
        asidentry^.Asid, // asid
    )
END

#SECTION "PAGEtext"
FN KepInitializeContext (
    IN thread : ^KeuThread,
    IN kstack : ^VOID,
    IN startfunc : KeStartThreadF,
    IN context1 : UWORD,
    IN context2 : UWORD,
) : ^OsContext

    // Initialize the context for a thread that is about to begin execution.

    context := CAST (kstack - SIZEOF OsContext) TO ^OsContext

    context^.S0 = CAST startfunc TO ULONG
    context^.S1 = CAST context1 TO ULONG
    context^.S2 = CAST context2 TO ULONG

    context^.Lr = CAST &KepThreadTrampoline TO ULONG

    RETURN context
END

#SECTION "PAGEtext"
FN KepInterruptUsermode (
    IN dispatchfunc : ^VOID,
    IN trapframe : ^OsContext,
    IN userfunc : UWORD,
    IN context : UWORD,
    IN thread : ^KeuThread,
)

    // Cause a usermode interrupt of the current thread by saving the context
    // on the user stack and redirecting the trapframe to the usermode
    // interrupt handler. This is used to implement signal and APC dispatch.

    usp := trapframe^.Sp

    usp -= SIZEOF OsContext

    // Save the trapframe to the user stack.
    // If that fails, and the thread has a panic stack, switch to it and copy
    // out to that instead. If THAT fails, terminate the entire process.

    status := MmSafeCopyOut (
        CAST usp TO ^VOID, // dest
        trapframe, // src
        SIZEOF OsContext, // sz
    )

    IF OsError ( status ) THEN
        // Failed to copy out the context frame.
        // This is fatal to the entire process.

        KeSignalProcess (
            thread^.Process, // process
            OS_SIGNAL_KILL, // signal
        )

        LEAVE
    END

    // Redirect the trapframe to the usermode interrupt handler.

    trapframe^.Sp = usp
    trapframe^.Epc = dispatchfunc
    trapframe^.A0 = context
    trapframe^.A1 = usp
    trapframe^.A2 = userfunc
END