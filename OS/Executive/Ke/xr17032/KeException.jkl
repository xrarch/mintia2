//
// Implements low-level exception handling for XR/17032.
//

#INCLUDE "../Ki.hjk"
#INCLUDE "<ll>/System/OsContext.hjk"

#IF BLD_MP

KiAsidLock : KiSpinlock = KI_INITIAL_SPINLOCK
KiUpdateAsidLock : KiSpinlock = KI_INITIAL_SPINLOCK

#END

KiAsidSequenceNumber : RtlUquad
KiNextAsid := 1

// The exact interface to the HAL for interrupts is private to the architecture.

EXTERN FN HalInterrupt (
    IN context : ^OsContext,
)

FNPTR KiHighLevelHandlerF (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

#DEFINE EXC_INT 1
#DEFINE EXC_SYS 2
#DEFINE EXC_BUS 4
#DEFINE EXC_NMI 5
#DEFINE EXC_BRK 6
#DEFINE EXC_INV 7
#DEFINE EXC_PRV 8
#DEFINE EXC_UNA 9
#DEFINE EXC_PGF 12
#DEFINE EXC_PFW 13

FN (KiHighLevelHandlerF) KiSpuriousException (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // Don't know why we're here.

    KeCrash (
        "Spurious Exception EXC=%u ADDR=%p\n", // fmt
        context^.Rs >> 28,
        badaddr
    )
END

FN (KiHighLevelHandlerF) KiHandleInterrupt (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    HalInterrupt ( context )

    prb := KI_CURRENT_PRB

    currentipl := prb^.Ipl

    IF prb^.PendingSoftwareInterrupts >> currentipl THEN
        KiDispatchSoftwareInterrupts ( currentipl )
    END
END

FN (KiHighLevelHandlerF) KiHandleError (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // An "error" fault occurred. If this happened in kernel mode, figure out
    // if its handled by a SafeCopy function. If not, crash.
    //
    // If it happened in usermode, generate a signal to the thread.

    RtlPrint ( "%u %p\n", context^.Rs >> 28, badaddr )
    KeCrash ( "KiHandleError Unimplemented\n" )
END

FN (KiHighLevelHandlerF) KiHandleBreakpoint (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    ecause := context^.Rs >> 28

    IF context^.Rs & 1 AND ecause != EXC_NMI THEN
        // Usermode breakpoint. Dispatch to debugger or send an illegal
        // instruction signal to the thread if no debugger attached.

        KeCrash ( "Usermode breakpoint Unimplemented\n" )

    ELSE
        IF KeDebuggerEntry THEN
#IF BLD_MP
            KiFreezeOtherProcessors ()
#END

            KeDebuggerEntry ( context )

#IF BLD_MP
            KiUnfreezeOtherProcessors ()
#END

            IF ecause == EXC_BRK AND context^.Epc == &KeBreakpoint THEN
                // Skip over the explicit breakpoint.

                context^.Epc += 4
            END

        ELSEIF ecause != EXC_NMI THEN
            KeCrash ( "Unhandled kernel mode breakpoint\n" )
        END
    END
END

FN (KiHighLevelHandlerF) KiHandlePageFault (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    KeCrash ( "KiHandlePageFault Unimplemented\n" )
END

#SECTION "text"
KiHandlerTable : KiHighLevelHandlerF[16] = {
    [0] = &KiSpuriousException,
    [EXC_INT] = &KiHandleInterrupt,
    [2] = &KiSpuriousException,
    [3] = &KiSpuriousException,
    [EXC_BUS] = &KiHandleError,
    [EXC_NMI] = &KiHandleBreakpoint,
    [EXC_BRK] = &KiHandleBreakpoint,
    [EXC_INV] = &KiHandleError,
    [EXC_PRV] = &KiHandleError,
    [EXC_UNA] = &KiHandleError,
    [10] = &KiSpuriousException,
    [11] = &KiSpuriousException,
    [EXC_PGF] = &KiHandlePageFault,
    [EXC_PFW] = &KiHandlePageFault,
    [14] = &KiSpuriousException,
    [15] = &KiSpuriousException,
}

#ASM [

// Put symbols here to allow the debugger to know how to interpret the
// context.

KiExceptionHandler:
.export KiExceptionHandler
    mtcr scratch0, t0               // Save T0 as a scratch register.
    mtcr scratch1, sp               // Save the current stack pointer.

    mfcr t0, rs                     // Read the status register.
    andi t0, t0, 1                  // Isolate the USER bit.
    beq  t0, .waskernel             // If not set, we were already in kernel mode.

    subi t0, zero, 4096             // Load the address of the PRB.
    mov  sp, long [t0 + KiPrb_KernelStackTop]

.waskernel:
    subi sp, sp, OsContext__SIZEOF   // Create a context block on the stack.

    mfcr t0, scratch0
    mov  long [sp + OsContext_T1], t1
    mov  long [sp + OsContext_T0], t0
    mov  long [sp + OsContext_T2], t2
    mov  long [sp + OsContext_T3], t3
    mov  long [sp + OsContext_T4], t4
    mov  long [sp + OsContext_T5], t5
    mov  long [sp + OsContext_A0], a0
    mov  long [sp + OsContext_A1], a1
    mov  long [sp + OsContext_A2], a2
    mov  long [sp + OsContext_A3], a3
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17
    mov  long [sp + OsContext_Tp], tp
    mfcr t0, scratch1
    mov  long [sp + OsContext_Lr], lr
    mfcr t1, epc
    mov  long [sp + OsContext_Sp], t0
    mfcr t2, rs
    mov  long [sp + OsContext_Epc], t1
    mov  long [sp + OsContext_Rs], t2

    rshi t0, t2, 28
    la   t1, KiHandlerTable
    mov  t0, long [t1 + t0 LSH 2]

    mfcr a1, ebadaddr
    mov  a0, sp
    jalr lr, t0, 0
    
    mov  t0, long [sp + OsContext_Rs]
    mtcr rs, t0
    mov  t1, long [sp + OsContext_Epc]
    mtcr epc, t1
    mov  t0, long [sp + OsContext_T0]
    mov  t1, long [sp + OsContext_T1]
    mov  t2, long [sp + OsContext_T2]
    mov  t3, long [sp + OsContext_T3]
    mov  t4, long [sp + OsContext_T4]
    mov  t5, long [sp + OsContext_T5]
    mov  a0, long [sp + OsContext_A0]
    mov  a1, long [sp + OsContext_A1]
    mov  a2, long [sp + OsContext_A2]
    mov  a3, long [sp + OsContext_A3]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    mov  tp, long [sp + OsContext_Tp]
    mov  lr, long [sp + OsContext_Lr]
    mov  sp, long [sp + OsContext_Sp]

    rfe

DbgExcEnd:
.export DbgExcEnd

// a0 - newipl
// outputs:
// a3 - oldipl
KiRaiseIpl:
.global KiRaiseIpl

    // Note: This routine is inlined at KiAcquireSpinlockRaise.
    
    subi t0, zero, 4096             // Acquire a pointer to the Prb.
    mov  a3, byte [t0 + KiPrb_Ipl]  // Load the old IPL.
    mov  byte [t0 + KiPrb_Ipl], a0  // Store the new IPL.

#IF BLD_CHK

    slt  t0, a0, a3                 // Test newipl < oldipl.
    bne  t0, .badraise              // If lower, this is a bad request.

#END

    ret

#IF BLD_CHK

.badraise:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KiBadRaiseMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

#END

// a0 - newipl
KiLowerIpl:
.global KiLowerIpl

    // Note: This routine is inlined at KiReleaseSpinlockLower.

    subi t0, zero, 4096             // Acquire a pointer to the Prb.

#IF BLD_CHK

    mov  t1, byte [t0 + KiPrb_Ipl]  // Load old IPL.
    slt  t1, t1, a0                 // Compare oldipl < newipl
    bne  t1, .badlower              // If lower, this is a bad request.

#END

    mov  byte [t0 + KiPrb_Ipl], a0  // Store the new IPL.
    mov  t1, long [t0 + KiPrb_PendingSoftwareInterrupts]
    rsh  t2, t1, a0                 // Right shift pending by new IPL.
    bne  t2, .dispatch              // If zero, none pending at new IPL.

    ret

.dispatch:
    j    KiDispatchSoftwareInterrupts

#IF BLD_CHK

.badlower:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KiBadLowerMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

KiBadRaiseMessage:
    .ds "KiRaiseIpl: oldipl > newipl\n"
    .db 0

KiBadLowerMessage:
    .ds "KiLowerIpl: newipl > oldipl\n"
    .db 0

.align 4

#END

// a0 - newthread
// a1 - oldthread
KiSwitchContext:
.global KiSwitchContext
    
    // Save the current context and restore the new.
    // We only need to save the callee-saved registers as this has the same
    // considerations as a function call that trashes them all.
    // We must also release the old thread's thread lock on our way out, after
    // we have fully left its context.

    subi sp, sp, OsContext__SIZEOF
    mov  long [sp + OsContext_Lr], lr
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17
    mov  long [sp + OsContext_Tp], tp

    mov  long [a1 + KeThread_Context], sp

    // Release thread lock. Inline KiReleaseSpinlock here for speed.

#IF BLD_MP
    
    // Memory barrier to ensure old writes are committed.

    wmb

    // Set spinlock un-owned.

    mov  long [a1 + KeThread_Spinlock], zero

#END

    // Fall through.

// a0 - thread
KiJumpIntoThread:
.global KiJumpIntoThread

    // Set new thread parameters in Prb.

    subi t0, zero, 4096
    mov  long [t0 + KiPrb_CurrentThread], a0
    mov  t1, long [a0 + KeThread_KernelStackTop]
    mov  long [t0 + KiPrb_KernelStackTop], t1

    // Restore context of new thread.

    mov  sp, long [a0 + KeThread_Context]

    mov  lr, long [sp + OsContext_Lr]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    mov  tp, long [sp + OsContext_Tp]
    addi sp, sp, OsContext__SIZEOF

    // Return into the new thread.

    ret

// a0 - pgtb
// a1 - asid
KiSwitchMapCode:

    // Set the new page directory in DTB entry 0.

    mfcr t1, dtbindex
    mtcr dtbindex, zero

    la   t0, (0xB02C0000 >> 12)
    mtcr dtbtag, t0

    rshi t0, a0, 12
    lshi t0, t0, 5
    ori  t0, t0, 0x17
    mtcr dtbpte, t0

    mtcr dtbindex, t1

    // Set the ASID for both TBs.

    lshi a1, a1, 20
    mtcr itbtag, a1
    mtcr dtbtag, a1

    ret

KiSwitchMapCodeEnd:

]

EXTERN FN KiExceptionHandler ()

EXTERN KiSwitchMapCode : UBYTE
EXTERN KiSwitchMapCodeEnd : UBYTE

FNPTR KiSwitchMapF (
    IN pgtb : UWORD,
    IN asid : UWORD,
)

KiSwitchMap : KiSwitchMapF

#SECTION "INIT$text"
FN KiInitializeArchitecture (
    IN prb : ^KiPrb,
)

    // Our KiCurrentProcessor is implemented by reading the WHAMI control
    // register, so it's already okay to do that.

    procid := KiCurrentProcessor ()

    IF procid == 0 THEN
        // Construct a jump instruction that just jumps to our exception
        // handler, and then copy it to the first instruction of each entry of
        // the exception block, except for the TB miss handlers, which have
        // already been set up by Loader.

        eb := CAST ExLoaderBlock.U.Xr.ExceptionBlock TO ^ULONG

        jmpinstruction := CAST &KiExceptionHandler TO ULONG

        jmpinstruction >>= 2
        jmpinstruction <<= 3
        jmpinstruction |= 6

        i := 0

        WHILE i < 14 DO
            eb^ = jmpinstruction

            i += 1
            eb += 256
        END

        // Copy KiSwitchMap into the zeroth vector. We do this because exception
        // 0 is permanently reserved by the architecture, making it a convenient
        // place to stash this function which *cannot* cause a TB miss during
        // execution.

        RtlCopyBytes (
            ExLoaderBlock.U.Xr.ExceptionBlock, // dest
            &KiSwitchMapCode, // src
            &KiSwitchMapCodeEnd - &KiSwitchMapCode, // sz
        )

        KiSwitchMap = CAST eb TO KiSwitchMapF

        // Copy the syscall handler into the exception block.
        // This one is special because it doesn't need to save as much as the
        // others do.

        // ... TODO ...

        // We modified the instruction stream, so flush the icache.

        KiFlushMyIcache ()
    END

    // Initialize the ID field of the PRB.

    prb^.Id = procid
END

#IF BLD_MP

FN (KiIpiF) KiUpdateAsidTarget (
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Upon entry to this routine, the requesting processor is holding the
    // global KiAsidLock. Because this is a synchronous request, we could act as
    // if we held it too, if it weren't for pesky other processors. So, there's
    // another KiUpdateAsidLock that we take to synchronize against those guys.
    // This other spinlock is needed or we'd get weird deadlocks.

    prb := KI_CURRENT_PRB

    current := prb^.CurrentThread

#IF BLD_CHK
    IF NOT current THEN
        KeCrash ( "KiUpdateAsidTarget: no current thread\n" )
    END
#END

    process := current^.Process

    IF process^.PageDirectoryPfn == ExLoaderBlock.SystemPageDirectoryPfn THEN
        // We're in the system address space, which has a fixed ASID of 0, so
        // don't worry about it.

        LEAVE
    END

    KiAcquireSpinlock ( &KiUpdateAsidLock )

    // We need to update the ASID we're currently running under.

    asid := process^.Asid

    globalseq := &KiAsidSequenceNumber

    IF RtlUquadNeqUquad ( &process^.AsidSequenceNumber, globalseq ) THEN

        // We need to assign a new ASID to the process. We can't tolerate a
        // nested ASID rollover so here we assume that can't happen. Since the
        // KiAsidLock is held by someone, the ASID count cannot currently be
        // incremented except by processors servicing this IPI. Therefore we
        // would need more than 4096 processors to overflow the ASID count here.
        // This is impossible on XR/computer systems which only allow up to 8
        // by design.

        asid = KiNextAsid
        KiNextAsid = asid + 1

#IF BLD_CHK
        IF asid == 0xFFF THEN
            KeCrash ( "KiUpdateAsidTarget: ASID wrap\n" )
        END
#END

        process^.Asid = asid

        RtlMoveUquad (
            &process^.AsidSequenceNumber, // destquad
            globalseq, // srcquad
        )
    END

    // Doesn't actually switch the page table, just the ASID. We're switching
    // into the same page table we were already in.

    KiSwitchMap (
        process^.PageDirectoryPfn, // pgtb
        asid, // asid
    )

    KiReleaseSpinlock ( &KiUpdateAsidLock )

    // Flush my whole TB.

    KiFlushMyTb ()
END

#END

FN KiSwitchAddressSpace (
    IN process : ^KeProcess,
)

    // On entry to this function we are holding the current thread's spinlock
    // and interrupts are totally disabled (to block out ASID rollover IPIs).

    IF process^.PageDirectoryPfn == ExLoaderBlock.SystemPageDirectoryPfn THEN
        // Just switch, don't bother dealing with ASIDs since ASID 0 is reserved
        // for the system address space.

        KiSwitchMap (
            process^.PageDirectoryPfn << 12, // pgtb
            0, // asid
        )

        LEAVE
    END

    globalseq := &KiAsidSequenceNumber

    // Check for roll-over. If we happen to catch it, we have to try to claim
    // the ASID lock and give the process a new ASID. This seems racey but note
    // that if another processor is the one who ends up dealing with this, they
    // will IPI us and we will receive their IPI before we go on with our stale
    // ASID, so this is all good.
    //
    // Note that skew is unimportant when we read the 64-bit sequence number
    // without holding a lock like this, because either part of the sequence
    // number being different is indicative of a rollover.

    IF RtlUquadNeqUquad ( &process^.AsidSequenceNumber, globalseq ) THEN
        // The ASIDs rolled over at some point, so we have to give this
        // process a new one.

        KeCrash ( "Test ASID reassignment\n" )
        
        // Re-enable interrupts before acquiring the ASID lock. Otherwise, the
        // holder of the lock might IPI us, but since we are spinning with
        // interrupts disabled, we can't accept the IPI. He will then spin
        // forever waiting for us to accept his IPI which will never happen,
        // causing deadlock. Note that we're still at KI_IPL_DPC though, so
        // preemption is blocked out.

#IF BLD_MP
        KiEnableInterrupts ()

        KiAcquireSpinlock ( &KiAsidLock )
#END

        // Re-check for roll-over; another thread of this same process might
        // have updated the ASID. Nothing stops that from happening on
        // another processor because the only lock held right now is the
        // current thread's lock.

#IF BLD_MP
        IF RtlUquadNeqUquad ( &process^.AsidSequenceNumber, globalseq ) THEN
#END

            asid := KiNextAsid
            KiNextAsid = asid + 1

#IF BLD_MP
            rolled := FALSE
#END

            // NOTE: Per the architecture manual we don't use ASID 0xFFF,
            //       so we roll over when we get that one.

            IF asid == 0xFFF THEN
                // Roll over. Flush TBs on all processors and increment
                // the sequence number.

                asid = 1
                KiNextAsid = 2

                RtlAddUlongToUquad (
                    globalseq, // quad
                    1, // ulong
                )

#IF BLD_MP
                rolled = TRUE
#END
            END

            process^.Asid = asid

            RtlMoveUquad (
                &process^.AsidSequenceNumber, // destquad
                globalseq, // srcquad
            )

#IF BLD_MP
            IF rolled THEN
                // Flush all TBs. Actually this does an extra thing which is
                // to ensure the ASIDs of the currently running threads are
                // updated on all processors.

                KiExecuteOnEveryoneElse (
                    &KiUpdateAsidTarget, // function
                    0, // context1
                    0, // context2
                )
            END
        END

        KiDisableInterrupts ()

        KiReleaseSpinlock ( &KiAsidLock )
#END
    END

    // Switch address spaces finally.

    KiSwitchMap (
        process^.PageDirectoryPfn << 12, // pgtb
        process^.Asid, // asid
    )
END