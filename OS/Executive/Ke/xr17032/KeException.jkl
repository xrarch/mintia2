//
// Implements low-level exception handling for XR/17032.
//

#INCLUDE "../Ki.hjk"
#INCLUDE "<ll>/System/OsContext.hjk"

// The exact interface to the HAL for interrupts is private to the architecture.

EXTERN FN HalInterrupt (
    IN context : ^OsContext,
)

FNPTR KiHighLevelHandlerF (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

#DEFINE EXC_INT 1
#DEFINE EXC_SYS 2
#DEFINE EXC_BUS 4
#DEFINE EXC_NMI 5
#DEFINE EXC_BRK 6
#DEFINE EXC_INV 7
#DEFINE EXC_PRV 8
#DEFINE EXC_UNA 9
#DEFINE EXC_PGF 12
#DEFINE EXC_PFW 13

KiCauseNames : ^UBYTE[16] = {
    "EXC0",
    "INTERRUPT",
    "SYSCALL",
    "FWCALL",
    "BUSERROR",
    "EXC5",
    "BREAKPOINT",
    "INVALIDINSTRUCTION",
    "PRIVILEGEVIOLATION",
    "UNALIGNEDADDR",
    "EXC10",
    "EXC11",
    "PAGEFAULT(READ)",
    "PAGEFAULT(WRITE)",
    "EXC14",
    "EXC15",
}

FN KiFaultCrash (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    prb := KI_CURRENT_PRB_LOCAL

    KeCrash (
        "FAULT! PROC=%d IPL=%d ERS=%08x BADADDR=%08x EPC=%08x\n       ECAUSE=%s\n", // fmt
        prb^.Id,
        prb^.Ipl,
        context^.Rs,
        badaddr,
        context^.Epc,
        KiCauseNames[context^.Rs >> 28],
    )
END

FN (KiHighLevelHandlerF) KiSpuriousException (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // Don't know why we're here.

    KeCrash (
        "Spurious Exception EXC=%u ADDR=%p\n", // fmt
        context^.Rs >> 28,
        badaddr
    )
END

FN (KiHighLevelHandlerF) KiHandleInterrupt (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    HalInterrupt ( context )

    prb := KI_CURRENT_PRB_LOCAL

    IF prb^.PendingSoftwareInterrupts >> prb^.Ipl THEN
        KiDispatchSoftwareInterrupts ( prb^.Ipl )
    END
END

FN (KiHighLevelHandlerF) KiHandleError (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // An "error" fault occurred. If this happened in kernel mode, figure out
    // if its handled by a SafeCopy function. If not, crash.
    //
    // If it happened in usermode, generate a signal to the thread.

    // NYI KiHandleError
    KiFaultCrash ( context, badaddr )
END

FN (KiHighLevelHandlerF) KiHandleBreakpoint (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    ecause := context^.Rs >> 28

    IF context^.Rs & 1 AND ecause != EXC_NMI THEN
        // Usermode breakpoint. Dispatch to debugger or send an illegal
        // instruction signal to the thread if no debugger attached.

        KeCrash ( "Usermode breakpoint Unimplemented\n" )

    ELSE
        IF KeDebuggerEntry THEN
            KeDebuggerEntry ( context )

            IF ecause == EXC_BRK AND context^.Epc == &KeBreakpoint THEN
                // Skip over the explicit breakpoint.

                context^.Epc += 4
            END

        ELSEIF ecause != EXC_NMI THEN
            KeCrash ( "Unhandled kernel mode breakpoint\n" )
        END
    END
END

FN (KiHighLevelHandlerF) KiHandlePageFault (
    IN context : ^OsContext,
    IN badaddr : ^VOID,
)

    // NYI KiHandlePageFault
    KiFaultCrash ( context, badaddr )
END

#SECTION "text"
KiHandlerTable : KiHighLevelHandlerF[16] = {
    [0] = &KiSpuriousException,
    [EXC_INT] = &KiHandleInterrupt,
    [2] = &KiSpuriousException,
    [3] = &KiSpuriousException,
    [EXC_BUS] = &KiHandleError,
    [EXC_NMI] = &KiHandleBreakpoint,
    [EXC_BRK] = &KiHandleBreakpoint,
    [EXC_INV] = &KiHandleError,
    [EXC_PRV] = &KiHandleError,
    [EXC_UNA] = &KiHandleError,
    [10] = &KiSpuriousException,
    [11] = &KiSpuriousException,
    [EXC_PGF] = &KiHandlePageFault,
    [EXC_PFW] = &KiHandlePageFault,
    [14] = &KiSpuriousException,
    [15] = &KiSpuriousException,
}

#ASM [

// Put symbols here to allow the debugger to know how to interpret the
// context.

KiExceptionHandler:
.export KiExceptionHandler
    mtcr scratch0, t0               // Save T0 as a scratch register.
    mtcr scratch1, sp               // Save the current stack pointer.

    mfcr t0, rs                     // Read the status register.
    andi t0, t0, (1 << 8)           // Isolate the old USER bit.
    beq  t0, .waskernel             // If not set, we were already in kernel
                                    // mode. If clear, we entered from usermode.

    subi t0, zero, 4096             // Load the address of the PRB.

    // Switch to the current thread's kernel stack.

    mov  sp, long [t0 + KiPrb_KernelStackTop]

.waskernel:

    subi sp, sp, OsContext__SIZEOF   // Create a context block on the stack.

    // Save the context of the processor in order to create a trapframe.

    mfcr t0, scratch0
    mov  long [sp + OsContext_T1], t1
    mov  long [sp + OsContext_T0], t0
    mov  long [sp + OsContext_T2], t2
    mov  long [sp + OsContext_T3], t3
    mov  long [sp + OsContext_T4], t4
    mov  long [sp + OsContext_T5], t5
    mov  long [sp + OsContext_A0], a0
    mov  long [sp + OsContext_A1], a1
    mov  long [sp + OsContext_A2], a2
    mov  long [sp + OsContext_A3], a3
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17
    mov  long [sp + OsContext_Tp], tp
    mfcr t0, scratch1
    mov  long [sp + OsContext_Lr], lr
    mfcr t1, epc
    mov  long [sp + OsContext_Sp], t0
    mfcr t2, rs
    mov  long [sp + OsContext_Epc], t1
    mov  long [sp + OsContext_Rs], t2

    andi s0, t2, (1 << 8)           // Isolate the old USER bit.
    beq  s0, .waskernel2            // If not set, we were already in kernel
                                    // mode. If clear, we entered from usermode.

    subi t0, zero, 4096             // Load the address of the PRB.

    // Load the current thread.

    mov  s1, long [t0 + KiPrb_CurrentThread]

    // Store the user trapframe address.

    mov  long [s1 + KeThread_UserFrame], sp

#IF BLD_MP
    // Set current thread as currently in kernel mode.

    mov  byte [s1 + KeThread_CurrentMode], KE_KERNEL_MODE
#END

.waskernel2:

    rshi t0, t2, 28                 // Isolate the exception code.
    la   t1, KiHandlerTable         // Load the address of the handler table.
    mov  t0, long [t1 + t0 LSH 2]   // Load the handler.

    mfcr a1, ebadaddr               // Set bad address as second argument.
    mov  a0, sp                     // Set trapframe as first argument.
    jalr lr, t0, 0                  // Execute handler.

    beq  s0, .waskernel3            // If not set, we were already in kernel
                                    // mode. If clear, we are returning to user
                                    // mode.

#IF BLD_MP
    // Set current thread as currently in usermode.
    // Do this *before* dispatching usermode interrupts, or there's a risk of
    // missed IPIs. This field is purely advisory for IPI delivery so there's
    // no harm to this.

    mov  byte [s1 + KeThread_CurrentMode], KE_USER_MODE
#END

    // Check for pending usermode interrupt.

    mov  t0, byte [s1 + KeThread_UserInterrupt]

    beq  t0, .waskernel3            // If clear, no pending usermode interrupt.

    jal  KiDispatchUserInterrupts   // Dispatch pending usermode interrupts.

.waskernel3:

    // Restore the context of the processor from the trapframe.

    mov  t0, long [sp + OsContext_Rs]
    mtcr rs, t0
    mov  t1, long [sp + OsContext_Epc]
    mtcr epc, t1
    mov  t0, long [sp + OsContext_T0]
    mov  t1, long [sp + OsContext_T1]
    mov  t2, long [sp + OsContext_T2]
    mov  t3, long [sp + OsContext_T3]
    mov  t4, long [sp + OsContext_T4]
    mov  t5, long [sp + OsContext_T5]
    mov  a0, long [sp + OsContext_A0]
    mov  a1, long [sp + OsContext_A1]
    mov  a2, long [sp + OsContext_A2]
    mov  a3, long [sp + OsContext_A3]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    mov  tp, long [sp + OsContext_Tp]
    mov  lr, long [sp + OsContext_Lr]
    mov  sp, long [sp + OsContext_Sp]

    // Return from the exception.

    rfe

DbgExcEnd:
.export DbgExcEnd

// a0 - newipl
// outputs:
// a3 - oldipl
KiRaiseIpl:
.global KiRaiseIpl

    // Note: This routine is inlined at KiAcquireSpinlockRaise.
    
    subi t0, zero, 4096             // Acquire a pointer to the Prb.
    mov  a3, byte [t0 + KiPrb_Ipl]  // Load the old IPL.
    mov  byte [t0 + KiPrb_Ipl], a0  // Store the new IPL.

#IF BLD_CHK

    slt  t0, a0, a3                 // Test newipl < oldipl.
    bne  t0, .badraise              // If lower, this is a bad request.

#END

    ret

#IF BLD_CHK

.badraise:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KiBadRaiseMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

#END

// a0 - newipl
KiLowerIpl:
.global KiLowerIpl

    // Note: This routine is inlined at KiReleaseSpinlockLower.

    subi t0, zero, 4096             // Acquire a pointer to the Prb.

#IF BLD_CHK

    mov  t1, byte [t0 + KiPrb_Ipl]  // Load old IPL.
    slt  t1, t1, a0                 // Compare oldipl < newipl
    bne  t1, .badlower              // If lower, this is a bad request.

#END

    mov  byte [t0 + KiPrb_Ipl], a0  // Store the new IPL.
    mov  t1, long [t0 + KiPrb_PendingSoftwareInterrupts]
    rsh  t2, t1, a0                 // Right shift pending by new IPL.
    bne  t2, .dispatch              // If zero, none pending at new IPL.

    ret

.dispatch:
    j    KiDispatchSoftwareInterrupts

#IF BLD_CHK

.badlower:
    // Create stack frame for debugger traces.

    subi sp, sp, 4
    mov  long [sp], lr

    la   a0, KiBadLowerMessage
    li   a1, 0
    li   a2, 0
    jal  KeCrash

KiBadRaiseMessage:
    .ds "KiRaiseIpl: oldipl > newipl\n"
    .db 0

KiBadLowerMessage:
    .ds "KiLowerIpl: newipl > oldipl\n"
    .db 0

.align 4

#END

// a0 - thread
KiJumpIntoThread:
.global KiJumpIntoThread

    // Restore context of new thread.

    mov  sp, long [a0 + KeThread_Context]

    j    LoadContext

// a0 - newthread
// a1 - oldthread
KiSwitchContext:
.global KiSwitchContext
    
    // Save the current context and restore the new.
    // We only need to save the callee-saved registers as this has the same
    // considerations as a function call that trashes them all.
    // We must also release the old thread's thread lock on our way out, after
    // we have fully left its context.

    subi sp, sp, OsContext__SIZEOF
    mov  long [sp + OsContext_Lr], lr
    mov  long [sp + OsContext_S0], s0
    mov  long [sp + OsContext_S1], s1
    mov  long [sp + OsContext_S2], s2
    mov  long [sp + OsContext_S3], s3
    mov  long [sp + OsContext_S4], s4
    mov  long [sp + OsContext_S5], s5
    mov  long [sp + OsContext_S6], s6
    mov  long [sp + OsContext_S7], s7
    mov  long [sp + OsContext_S8], s8
    mov  long [sp + OsContext_S9], s9
    mov  long [sp + OsContext_S10], s10
    mov  long [sp + OsContext_S11], s11
    mov  long [sp + OsContext_S12], s12
    mov  long [sp + OsContext_S13], s13
    mov  long [sp + OsContext_S14], s14
    mov  long [sp + OsContext_S15], s15
    mov  long [sp + OsContext_S16], s16
    mov  long [sp + OsContext_S17], s17
    mov  long [sp + OsContext_Tp], tp

    mov  long [a1 + KeThread_Context], sp

    // Restore context of new thread.

    mov  sp, long [a0 + KeThread_Context]

    // Release thread lock. Inline KiReleaseSpinlock here for speed.

#IF BLD_MP
    // Indicate no longer switching off of our stack.

    mov  byte [a1 + KeThread_Switching], 0

    // Memory barrier to ensure old writes are committed.

    wmb

    // Set spinlock un-owned.

    mov  long [a1 + KeThread_Spinlock], zero
#END

LoadContext:

    // Set thread to RUNNING.

    mov  byte [a0 + KeThread_Status], KI_THREAD_RUNNING

    // If there are any KAPCs pending in the new thread, set int at KI_IPL_APC
    // pending.

    addi t1, a0, KeThread_KapcListHead
    mov  t0, long [a0 + (KeThread_KapcListHead + RtlListEntry_Next)]
    sub  t0, t0, t1
    beq  t0, .none

    // Trigger.

    subi a0, zero, 4096
    li   a1, (1 << ((KI_IPL_APC) - 1))
    jal  KiSoftInterruptSelfSet

.none:

    mov  lr, long [sp + OsContext_Lr]
    mov  s0, long [sp + OsContext_S0]
    mov  s1, long [sp + OsContext_S1]
    mov  s2, long [sp + OsContext_S2]
    mov  s3, long [sp + OsContext_S3]
    mov  s4, long [sp + OsContext_S4]
    mov  s5, long [sp + OsContext_S5]
    mov  s6, long [sp + OsContext_S6]
    mov  s7, long [sp + OsContext_S7]
    mov  s8, long [sp + OsContext_S8]
    mov  s9, long [sp + OsContext_S9]
    mov  s10, long [sp + OsContext_S10]
    mov  s11, long [sp + OsContext_S11]
    mov  s12, long [sp + OsContext_S12]
    mov  s13, long [sp + OsContext_S13]
    mov  s14, long [sp + OsContext_S14]
    mov  s15, long [sp + OsContext_S15]
    mov  s16, long [sp + OsContext_S16]
    mov  s17, long [sp + OsContext_S17]
    mov  tp, long [sp + OsContext_Tp]
    addi sp, sp, OsContext__SIZEOF

    // Return into the new thread.

    ret

// a0 - pgtb
// a1 - asid
KiSwitchMapCode:

    // Disable interrupts.

    mfcr t2, rs                     // Load current value of RS.
    subi t0, zero, 3                // t0 = 0xFFFFFFFD
    and  t0, t2, t0                 // Mask out the INT bit.
    mtcr rs, t0                     // Write new RS.

    // Set the new page directory in DTB entry 0.

    mfcr t1, dtbindex
    mtcr dtbindex, zero

    la   t0, (0xB02C0000 >> 12)
    mtcr dtbtag, t0

    rshi t0, a0, 12
    lshi t0, t0, 5
    ori  t0, t0, 0x17
    mtcr dtbpte, t0

    mtcr dtbindex, t1

    // Set the ASID for both TBs.

    lshi a1, a1, 20
    mtcr itbtag, a1
    mtcr dtbtag, a1

    // Restore interrupts.

    mtcr rs, t2

    ret

KiSwitchMapCodeEnd:

// a0 - prb
// a1 - set
KiSoftInterruptSelfSet:
.global KiSoftInterruptSelfSet

    // Soft interrupt the current processor.

    // Disable interrupts to block out IPIs and other modifying events.

    mfcr a3, rs                     // Load current value of RS.
    subi t0, zero, 3                // t0 = 0xFFFFFFFD
    and  t0, a3, t0                 // Mask out the INT bit.
    mtcr rs, t0                     // Write new RS.

    // OR the set into the pending ints.

    mov  t0, long [a0 + KiPrb_PendingSoftwareInterrupts]
    or   t0, t0, a1
    mov  long [a0 + KiPrb_PendingSoftwareInterrupts], t0

    // Restore interrupts.

    mtcr rs, a3
    
    // Return.

    ret

KiThreadTrampoline:

    // This is where a new thread begins execution.
    // s0 contains the start function, s1 and s2 contain context pointers.

    // We're at KI_IPL_DPC, so lower that now.

    li   a0, KI_IPL_LOW
    jal  KiLowerIpl

    // Set LR to 0 so that stack traces terminate here.

    mov  lr, zero

    // Jump to the start function.

    mov  a0, s1
    mov  a1, s2
    jalr zero, s0, 0

]

EXTERN FN KiThreadTrampoline ()

EXTERN FN KiExceptionHandler ()

EXTERN KiSwitchMapCode : UBYTE
EXTERN KiSwitchMapCodeEnd : UBYTE

FNPTR KiSwitchMapF (
    IN pgtb : UWORD,
    IN asid : UWORD,
)

KiSwitchMap : KiSwitchMapF

#SECTION "INITtext"
FN KiInitializeArchitecture (
    IN prb : ^KiPrb,
)

    // Our KiCurrentProcessor is implemented by reading the WHAMI control
    // register, so it's already okay to do that.

    procid := KiCurrentProcessor ()

    IF procid == 0 THEN
        // Construct a jump instruction that just jumps to our exception
        // handler, and then copy it to the first instruction of each entry of
        // the exception block, except for the TB miss handlers, which have
        // already been set up by Loader.

        eb := CAST KeLoaderBlock.U.Xr.ExceptionBlock TO ^ULONG

        jmpinstruction := CAST &KiExceptionHandler TO ULONG

        jmpinstruction >>= 2
        jmpinstruction <<= 3
        jmpinstruction |= 6

        i := 0

        WHILE i < 14 DO
            eb^ = jmpinstruction

            i += 1
            eb += 256
        END

        // Copy KiSwitchMap into the zeroth vector. We do this because exception
        // 0 is permanently reserved by the architecture, making it a convenient
        // place to stash this function which *cannot* cause a TB miss during
        // execution.

        RtlCopyBytes (
            KeLoaderBlock.U.Xr.ExceptionBlock, // dest
            &KiSwitchMapCode, // src
            &KiSwitchMapCodeEnd - &KiSwitchMapCode, // sz
        )

        KiSwitchMap = CAST eb TO KiSwitchMapF

        // Copy the syscall handler into the exception block.
        // This one is special because it doesn't need to save as much as the
        // others do.

        // ... TODO ...

        // We modified the instruction stream, so flush the icache.

        KiFlushMyIcache ()
    END

    // Initialize the ASID sequence counter.

    RtlSetUquadToUlong (
        &prb^.AsidSequenceNumber, // ptr
        0, // ulong
    )

    // Initialize the next ASID.

    prb^.NextAsid = 1
END

FN KiSwitchAddressSpace (
    IN process : ^KeProcess,
)

    // Switch address space to the given process. Interrupts are enabled, thread
    // lock is held. IPL is KI_IPL_DPC, so we are pinned to this processor.

    IF process^.PageDirectoryPfn == KeLoaderBlock.SystemPageDirectoryPfn THEN
        // Just switch, don't bother dealing with ASIDs since ASID 0 is reserved
        // for the system address space.

        KiSwitchMap (
            process^.PageDirectoryPfn << 12, // pgtb
            0, // asid
        )

        LEAVE
    END

    prb := KI_CURRENT_PRB_LOCAL

    asidentry := &process^.AsidTable[prb^.Id]

    cpuseq := &prb^.AsidSequenceNumber

    // Check for ASID roll-over.

    IF RtlUquadNeqUquad ( &asidentry^.AsidSequenceNumber, cpuseq ) THEN
        // The ASIDs rolled over at some point, so we have to give this
        // process a new one.

        KeCrash ( "Test ASID rollover\n" )

        asid := prb^.NextAsid
        prb^.NextAsid = asid + 1

        // NOTE: Per the architecture manual we don't use ASID 0xFFF,
        //       so we roll over when we get that one.

        IF asid == 0xFFF THEN
            // Roll over. Flush TB on this processor and increment the sequence
            // number.

            asid = 1
            prb^.NextAsid = 2

            RtlAddUlongToUquad (
                cpuseq, // quad
                1, // ulong
            )

            // Flush my TB. Keep global pages because we only use ASIDs for
            // private pages, no need to waste system space TB entries.

            KeSweepMyTb ( TRUE )
        END

        asidentry^.Asid = asid

        RtlMoveUquad (
            &asidentry^.AsidSequenceNumber, // destquad
            cpuseq, // srcquad
        )
    END

    // Perform the low-level address space switch.

    KiSwitchMap (
        process^.PageDirectoryPfn << 12, // pgtb
        asidentry^.Asid, // asid
    )
END

FN KiInitializeContext (
    IN thread : ^KeThread,
    IN kstack : ^VOID,
    IN startfunc : KeStartThreadF,
    IN context1 : UWORD,
    IN context2 : UWORD,
) : ^OsContext

    // Initialize the context for a thread that is about to begin execution.

    context := CAST (kstack - SIZEOF OsContext) TO ^OsContext

    context^.S0 = CAST startfunc TO ULONG
    context^.S1 = CAST context1 TO ULONG
    context^.S2 = CAST context2 TO ULONG

    context^.Lr = CAST &KiThreadTrampoline TO ULONG

    RETURN context
END

FN KiInterruptUsermode (
    IN dispatchfunc : ^VOID,
    IN trapframe : ^OsContext,
    IN userfunc : UWORD,
    IN context : UWORD,
)

    // Cause a usermode interrupt of the current thread by saving the context
    // on the user stack and redirecting the trapframe to the usermode
    // interrupt handler. This is used to implement signal and APC dispatch.

    usp := trapframe^.Sp

    usp -= SIZEOF OsContext

    // Save the trapframe to the user stack.
    // If that fails, and the thread has a panic stack, switch to it and copy
    // out to that instead.

    // Can't implement this until we get copy-out figured out.
    KeCrash ( "NYI KiInterruptUsermode\n" )

    // Redirect the trapframe to the usermode interrupt handler.

    trapframe^.Sp = usp
    trapframe^.Epc = dispatchfunc
    trapframe^.A0 = context
    trapframe^.A1 = usp
    trapframe^.A2 = userfunc
END