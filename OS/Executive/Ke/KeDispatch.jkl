//
// Implements the processor dispatcher for the MINTIA Kernel.
//

// Lock ordering:
//
//  Object -> Thread -> ReadyQueue

#INCLUDE "Ki.hjk"

#INCLUDE "<ll>/System/OsStatus.hjk"
#INCLUDE "<ll>/System/OsSignal.hjk"

#IF BLD_MP

KiActiveProcessorBitmap : ULONG[(KI_MAXIMUM_PROCESSORS + 31) / 32]
KiIdleProcessorCount : ULONG

#MACRO KiSetProcessorIdle ( prb ) [
    KeMaskUlong (
        &KiActiveProcessorBitmap[(prb)^.Id / 32], // ptr
        ~(1 << ((prb^).Id % 32)), // mask
    )

    KeIncrementUlong (
        &KiIdleProcessorCount, // ptr
        1, // ulong
    )
]

#MACRO KiClearProcessorIdle ( prb ) [
    KeIncrementUlong (
        &KiIdleProcessorCount, // ptr
        0xFFFFFFFF, // ulong
    )

    KeOrUlong (
        &KiActiveProcessorBitmap[(prb)^.Id / 32], // ptr
        1 << ((prb^).Id % 32), // bitset
    )
]

#MACRO KiAcquireReadyQueueElevated ( prb ) [
    KiAcquireSpinlock ( &(prb)^.ReadyQueueLock )
]

#MACRO KiReleaseReadyQueueElevated ( prb ) [
    KiReleaseSpinlock ( &(prb)^.ReadyQueueLock )
]

#MACRO KiAcquireThread ( thread ) [
    KiAcquireSpinlockRaise ( &(thread)^.Spinlock )
]

#MACRO KiReleaseThread ( thread, oldipl ) [
    KiReleaseSpinlockLower (
        &(thread)^.Spinlock, // spinlock
        oldipl, // oldipl
    )
]

#MACRO KiAcquireThreadElevated ( thread ) [
    KiAcquireSpinlock ( &(thread)^.Spinlock )
]

#MACRO KiReleaseThreadElevated ( thread ) [
    KiReleaseSpinlock ( &(thread)^.Spinlock )
]

#MACRO KiSetWaitAttempt ( thread, state ) [
    NOTHING (thread)^.WaitAttempt = (state)
]

#MACRO KiWaitForSwitch ( thread ) [
    // Wait for the next thread to no longer be switching off his stack.

    WHILE (thread)^.Switching DO
        // Language BARRIER to ensure this loop isn't optimized out.

        BARRIER
    END
]

#ELSE

#MACRO KiSetProcessorIdle ( prb ) []

#MACRO KiClearProcessorIdle ( prb ) []

#MACRO KiAcquireReadyQueueElevated ( prb ) []

#MACRO KiReleaseReadyQueueElevated ( prb ) []

#MACRO KiAcquireThread ( thread ) [
    KiRaiseIpl ( KI_IPL_DPC )
]

#MACRO KiReleaseThread ( thread, oldipl ) [
    KiLowerIpl ( oldipl )
]

#MACRO KiAcquireThreadElevated ( thread ) []

#MACRO KiReleaseThreadElevated ( thread ) []

#MACRO KiSetWaitAttempt ( thread, state ) []

#MACRO KiWaitForSwitch ( thread ) []

#END

#DEFINE KI_INTERACT_MAX 100
#DEFINE KI_INTERACT_HALF ( / KI_INTERACT_MAX 2 )
#DEFINE KI_INTERACT_THRESH 15
#DEFINE KI_SLP_RUN_MAX ( << 5000 KI_TICK_SHIFT )

FN KiJumpIntoIdleThread (
    IN prb : ^KiPrb,
)

    // Called by a processor when it first enters the system to initially jump
    // into its idle thread.

    KiSetProcessorIdle ( prb )

    // Switch into our idle thread.

    KiJumpIntoThread ( &prb^.IdleThread )
END

FN KiUpdateInteractivity (
    IN thread : ^KeThread,
) : UWORD

    // Update the sliding history of thread interactivity.
    // Adapted from sched_interact_update in sched_ule.c, the FreeBSD ULE
    // scheduler.
    //
    // Returns TRUE if the thread was changed from interactive to
    // non-interactive, false otherwise.

    IF thread^.Priority == OS_PRIORITY_IDLE THEN
        RETURN FALSE
    END

    sum := thread^.RunMs + thread^.SleepMs

    IF sum < KI_SLP_RUN_MAX THEN
        // Not enough history.

        GOTO SetInteractive
    END

    IF sum > KI_SLP_RUN_MAX * 2 THEN
        // There's an excessive amount of history.
        // Reset the values to evade overflow.

        IF thread^.RunMs > thread^.SleepMs THEN
            thread^.RunMs = KI_SLP_RUN_MAX
            thread^.SleepMs = 1

        ELSE
            thread^.RunMs = 1
            thread^.SleepMs = KI_SLP_RUN_MAX
        END

        GOTO SetInteractive
    END

    // If we have exceeded by more than 1/5 then the algorithm below will not
    // bring us back into range. Dividing by two here forces us into the range
    // of [4/5 * KI_SLP_RUN_MAX, KI_SLP_RUN_MAX].

    IF sum > (KI_SLP_RUN_MAX / 5) * 6 THEN
        thread^.RunMs /= 2
        thread^.SleepMs /= 2

        GOTO SetInteractive
    END

    thread^.RunMs = (thread^.RunMs / 5) * 4
    thread^.SleepMs = (thread^.SleepMs / 5) * 4

@SetInteractive

    // Calculate the interactivity score.

    score : WORD
    div : UWORD

    IF thread^.RunMs > thread^.SleepMs THEN
        div = thread^.RunMs / KI_INTERACT_HALF

        IF NOT div THEN
            div = 1
        END

        score = CAST KI_INTERACT_HALF +
            (KI_INTERACT_HALF - (thread^.SleepMs / div)) TO WORD

    ELSEIF thread^.RunMs < thread^.SleepMs THEN
        div = thread^.SleepMs / KI_INTERACT_HALF

        IF NOT div THEN
            div = 1
        END

        score = CAST thread^.RunMs / div TO WORD

    ELSEIF thread^.RunMs THEN
        score = KI_INTERACT_HALF

    ELSE
        score = 0
    END

    lostinteractivity := FALSE

    IF score < KI_INTERACT_THRESH THEN
        // Interactive.

        thread^.Interactive = TRUE

    ELSE
        // Not interactive.

        IF thread^.Interactive THEN
            lostinteractivity = TRUE
            thread^.Interactive = FALSE
        END
    END

    RETURN lostinteractivity
END

FN KiSwitchThread (
    IN current : ^KeThread,
    IN thread : ^KeThread,
)

    // The current thread is locked, unless it is NULLPTR (in which case this is
    // the first thread switch in the lifetime of the system).
    //
    // The target thread is not locked as it has been removed from the ready
    // queue and is in our custody.

#IF BLD_CHK
    IF KiCurrentIpl () != KI_IPL_DPC THEN
        KeCrash ( "KiSwitchThread: IPL != KI_IPL_DPC\n" )
    END

    IF current == thread THEN
        KeCrash ( "KiSwitchThread: same thread\n" )
    END

    IF NOT current THEN
        KeCrash ( "KiSwitchThread: current == 0\n" )
    END

    IF NOT thread THEN
        KeCrash ( "KiSwitchThread: thread == 0\n" )
    END
#END

    // Set affinity to this processor.

    prb := KI_CURRENT_PRB

#IF BLD_MP
    thread^.AffinityPrb = prb

    IF thread^.Priority == OS_PRIORITY_IDLE THEN
        IF current^.Priority != OS_PRIORITY_IDLE THEN
            // We were non-idle and are switching into an idle thread.

            KiSetProcessorIdle ( prb )
        END

    ELSEIF current^.Priority == OS_PRIORITY_IDLE THEN
        // We were idle and are switching into a non-idle thread.

        KiClearProcessorIdle ( prb )
    END
#END

    // Store tick the new thread started running on.

    thread^.StateMs = KiLowTick ()

    // See if we have to switch address spaces.

    nextproc := thread^.Process

    IF nextproc^.PageDirectoryPfn != current^.Process^.PageDirectoryPfn THEN
        // Switch to the address space of the new process.

        KiSwitchAddressSpace ( nextproc )
    END

    // Note that KiSwitchContext releases the old thread's lock.
    // It is not reacquired before switching back in.

    KiSwitchContext (
        thread, // newthread
        current, // oldthread
    )

    // We're back in the context of the "current" thread. This is always where
    // the hole that the gopher pops back out of is, except in the case of a
    // newly created thread being dispatched for the first time.
    //
    // Check for pending Kernel APCs that need to be dispatched. Note that we
    // don't need to acquire our thread lock for that since the act of checking
    // (RtlEmptyList) does not touch any pointers.

    IF NOT RtlEmptyList ( &current^.KapcListHead ) THEN
        KiSoftInterruptSelf ( prb, KI_IPL_APC )
    END
END

FN KiInsertThread (
    IN prb : ^KiPrb,
    IN thread : ^KeThread,
    IN other : UWORD,
)

    // Insert a thread into the appropriate ready queue of the given processor.
    // We *don't* try to synchronize against this thread being readied by
    // multiple processors at once, so there should be a well defined and
    // exclusive custody of the thread object by the caller at this point. Also
    // the ready queue of the processor should be locked. Also the thread lock
    // is held.

    thread^.Status = KI_THREAD_READY

#IF BLD_MP
    thread^.CurrentPrb = prb

    // Increment count of ready threads on this processor.

    prb^.Load += 1
#END

    current := prb^.CurrentThread
    next := prb^.NextThread

    compare := next

    IF NOT compare THEN
        compare = current
    END

    IF thread^.Priority >= OS_PRIORITY_LOW_REALTIME OR
        thread^.Interactive THEN

        // It's either one of the forced real time priorities or we've deemed it
        // interactive. Either way it goes in the real time queue or preempts
        // the current thread.

        IF (compare^.Priority >= OS_PRIORITY_LOW_REALTIME OR
            compare^.Interactive) AND thread^.Priority <= compare^.Priority THEN

            thread^.CurrentQueue = KI_REAL_TIME_QUEUE

            // Go on the back of the queue.

            RtlInsertAtTailList (
                &prb^.RealTimeListHeads[thread^.Priority], // head
                &thread^.ReadyEntry, // entry
            )

            // Indicate that an item exists in this queue.

            prb^.RealTimeReady |= 1 << thread^.Priority

            LEAVE
        END

    ELSE
        // It's a timeshared or idle thread. There's only one thing these can
        // preempt - the idle thread.

        IF compare != &prb^.IdleThread THEN
            // No preemption. Just place on the appropriate queue.

            IF thread^.Priority == OS_PRIORITY_IDLE THEN
                // Idle queue.

                thread^.CurrentQueue = KI_IDLE_QUEUE

                RtlInsertAtTailList (
                    &prb^.IdleListHead, // head
                    &thread^.ReadyEntry, // entry
                )

                LEAVE
            END

            // Timeshared queue.

            thread^.CurrentQueue = KI_TIMESHARED_QUEUE

            insertat := prb^.CalendarEnqueueIndex

            // Bias the index by the inverse of the priority, so that higher
            // priority timeshared threads are scheduled sooner.

            insertat += KI_TIMESHARED_DISTANCE - thread^.Priority
            insertat %= KI_TIMESHARED_QUEUES

            IF prb^.CalendarRunIndex != prb^.CalendarEnqueueIndex AND
                insertat == prb^.CalendarRunIndex THEN

                insertat -= 1
                insertat %= KI_TIMESHARED_QUEUES
            END

            // Reuse Alertable to stash the timeshared queue index.

            thread^.Alertable = insertat

            // Go on the back of the queue.

            RtlInsertAtTailList (
                &prb^.CalendarListHeads[insertat], // head
                &thread^.ReadyEntry, // entry
            )

            // Indicate that an item exists in this queue.

            prb^.CalendarReady |= 1 << insertat

            LEAVE
        END
    END

#IF BLD_MP
    // Decrement count of ready threads. We don't count standby and running
    // threads in this counter.

    prb^.Load -= 1
#END

    // Cause a preemption.

    thread^.Status = KI_THREAD_STANDBY

    prb^.NextThread = thread

    IF next THEN
        // Recursively re-ready the preempted NextThread. Don't fear - this can
        // only nest one level deep.

        KiInsertThread (
            prb, // prb
            next, // thread
            other, // other
        )

    ELSE
        // Trigger a software interrupt.

#IF BLD_MP
        IF other THEN
            // This was a remote Prb; may have to send an IPI.

            KiSoftInterruptOther (
                prb, // targetprb
                KI_IPL_DPC, // ipl
            )

            LEAVE
        END
#END

        KiSoftInterruptSelf (
            prb, // targetprb
            KI_IPL_DPC, // ipl
        )
    END
END

FN KiWouldPreempt (
    IN thread1 : ^KeThread,
    IN thread2 : ^KeThread,
    IN targetprb : ^KiPrb,
) : UWORD

    // Returns TRUE if thread1 would preempt thread2.

    pri1 := thread1^.Priority
    pri2 := thread2^.Priority

    IF thread1^.Interactive THEN
        IF NOT thread2^.Interactive THEN
            // Interactive threads always preempt non-interactive threads.

            RETURN TRUE
        END

        // Both are interactive. Compare priorities.

        RETURN pri1 > pri2
    END

    IF pri1 >= OS_PRIORITY_LOW_REALTIME AND
        pri1 > pri2 THEN

        // Higher priority real time threads preempt all other threads.

        RETURN TRUE
    END

    IF pri1 > OS_PRIORITY_IDLE AND
        pri2 == OS_PRIORITY_IDLE THEN

        // Non-idle threads always preempt idle threads.

        RETURN TRUE
    END

    IF thread2 == &targetprb^.IdleThread THEN
        // Always preempt the idle thread.

        RETURN TRUE
    END

    RETURN FALSE
END

#IF BLD_MP

FN KiFindIdleProcessor () : ^KiPrb

    // Find an idle processor and return the pointer.

    bytes := CAST &KiActiveProcessorBitmap[0] TO ^UBYTE

    i := 0
    procs := KeLoaderBlock.ProcessorCount
    fbc := &KiIndexFirstBitClear[0]

    WHILE i < procs DO
        index := fbc[bytes[i / 8]]

        IF index != 8 THEN
            // Found one.

            index += i

            IF index < procs THEN
                RETURN KiPrbFromNumber ( index )
            END

            // The index was beyond the actual processor count.

            RETURN NULLPTR
        END

        i += 8
    END

    RETURN NULLPTR
END

FN KiFindProcessor (
    IN thread : ^KeThread,
) : ^KiPrb

    // Scan for the preemptible processor with the lowest load.
    // At the same time, scan for the processor with the lowest load in
    // general.

    procs := KeLoaderBlock.ProcessorCount

    preemptprb : ^KiPrb = NULLPTR
    unloadedprb : ^KiPrb = NULLPTR
    prb : ^KiPrb

    i := 0

    WHILE i < procs DO
        prb = KiPrbFromNumber ( i )

        preempt : UWORD

        KiAcquireReadyQueueElevated ( prb )

        preempt = KiWouldPreempt (
            thread, // thread1
            prb^.CurrentThread, // thread2
            prb, // targetprb
        )

        KiReleaseReadyQueueElevated ( prb )

        IF preempt THEN
            IF NOT preemptprb THEN
                preemptprb = prb

            ELSEIF prb^.Load < preemptprb^.Load THEN
                preemptprb = prb
            END
        END

        IF NOT unloadedprb THEN
            unloadedprb = prb

        ELSEIF prb^.Load < unloadedprb^.Load THEN
            unloadedprb = prb
        END

        i += 1
    END

    IF preemptprb THEN
        // Select the preemptible processor with the least load.

        RETURN preemptprb
    END

    // Select the least loaded processor in general.

    RETURN unloadedprb
END

FN KiFindMostAndLeastLoadedProcessor (
    OUT mostloaded : ^KiPrb,
    OUT leastloaded : ^KiPrb,
)

    // Find and return the most and least loaded processors.

    procs := KeLoaderBlock.ProcessorCount

    mostloaded = KiPrbFromNumber ( 0 )
    leastloaded = mostloaded

    i := 1
    prb := mostloaded + BL_PRB_SIZE

    WHILE i < procs DO
        IF prb^.Load < leastloaded^.Load THEN
            leastloaded = prb
        END

        IF prb^.Load > mostloaded^.Load THEN
            mostloaded = prb
        END

        i += 1
        prb += BL_PRB_SIZE
    END
END

#END

FN KiReadyThread (
    IN thread : ^KeThread,
)

    // Ready the thread by inserting it into an appropriate ready queue.
    // Thread lock is held.

    myprb := KI_CURRENT_PRB

#IF BLD_MP
    // Select a processor to insert the thread into in the following order:
    //
    // 1. Affinity processor if would preempt.
    // 2. Any other idle processor.
    // 3. Any other preemptible processor.
    // 4. Current processor.

    prb := thread^.AffinityPrb

    IF prb THEN
        KiAcquireReadyQueueElevated ( prb )

        IF thread^.Pinned OR KiWouldPreempt (
            thread, // thread1
            prb^.CurrentThread, // thread2
            prb, // targetprb
        ) THEN

            GOTO Found
        END

        KiReleaseReadyQueueElevated ( prb )
    END

    IF KiIdleProcessorCount THEN
        // Search the idle processor bitmap.

        prb = KiFindIdleProcessor ()

        IF prb THEN
            KiAcquireReadyQueueElevated ( prb )

            GOTO Found
        END
    END

    // Scan for the preemptible processor with the lowest load.

    prb = KiFindProcessor ( thread )

#IF BLD_CHK
    IF NOT prb THEN
        KeCrash ( "KiFindProcessor returned NULLPTR\n" )
    END
#END

    KiAcquireReadyQueueElevated ( prb )

@Found

    KiInsertThread (
        prb, // prb
        thread, // thread
        myprb != prb, // other
    )

    KiReleaseReadyQueueElevated ( prb )

#ELSE
    KiInsertThread (
        myprb, // prb
        thread, // thread
        FALSE, // other
    )
#END

END

FN KiSelectRealTimeThread (
    IN prb : ^KiPrb,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's real time ready
    // queues. The processor's ready queue lock is held.

    readybits := prb^.RealTimeReady

    i := OS_PRIORITY_MAX

    WHILE i DO
        i -= 1

        IF (readybits >> i) & 1 THEN
            // There's a thread in this queue. Unlink and return it.

            queue := &prb^.RealTimeListHeads[i]

            thread := CONTAINEROF queue^.Next TO KeThread.ReadyEntry

#IF BLD_MP
            IF NOT thread^.Pinned OR NOT migrate THEN
#END
                RtlRemoveEntryList ( &thread^.ReadyEntry )

                IF RtlEmptyList ( queue ) THEN
                    // The queue is empty now. Clear the bit.

                    prb^.RealTimeReady = readybits & ~(1 << i)
                END

#IF BLD_MP
                // Decrement count of ready threads.

                prb^.Load -= 1
#END

                RETURN thread
#IF BLD_MP
            END
#END
        END
    END

    RETURN NULLPTR
END

FN KiSelectTimesharedThread (
    IN prb : ^KiPrb,
    IN current : ^KeThread,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's calendar ready
    // queues. The processor's ready queue lock is held.

    // If there's a current thread we want to see where it would be placed if it
    // were to be enqueued here now, so that we can go right back to it if we
    // figure out thats appropriate.

    readybits := prb^.CalendarReady

    k := prb^.CalendarRunIndex

    IF NOT current
#IF BLD_MP
        OR migrate
#END
        THEN

        // If we're migrating, or we'd become idle if we fail to get a thread
        // here, seek to a set bit to make sure we get a thread.

        count := KI_TIMESHARED_QUEUES

        WHILE (readybits >> k) & 1 == 0 AND count DO
            k += 1
            count -= 1

            IF k == KI_TIMESHARED_QUEUES THEN
                k = 0
            END
        END
    END

    IF (readybits >> k) & 1 == 0 THEN
        RETURN NULLPTR
    END

    // There's a thread in this queue. Unlink and return it.

    queue := &prb^.CalendarListHeads[k]

    thread := CONTAINEROF queue^.Next TO KeThread.ReadyEntry

#IF BLD_MP
    IF NOT thread^.Pinned OR NOT migrate THEN
#END
        RtlRemoveEntryList ( &thread^.ReadyEntry )

        IF RtlEmptyList ( queue ) THEN
            // The queue is empty now. Clear the bit.

            prb^.CalendarReady = readybits & ~(1 << k)

#IF BLD_MP
            IF NOT migrate THEN
#END
                // Advance the run index.

                IF prb^.CalendarRunIndex != prb^.CalendarEnqueueIndex THEN
                    prb^.CalendarRunIndex = (k + 1) % KI_TIMESHARED_QUEUES
                END
#IF BLD_MP
            END
#END
        END

#IF BLD_MP
        // Decrement count of ready threads.

        prb^.Load -= 1
#END

        RETURN thread
#IF BLD_MP
    END
#END

    RETURN NULLPTR
END

FN KiSelectThread (
    IN prb : ^KiPrb,
    IN current : ^KeThread,
    IN exclusive : UWORD,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's queues.
    // A thread lock is held, or we are otherwise at KI_IPL_DPC. Ready queue
    // lock is held.
    // If a current thread is given, we only return threads that can preempt it.

    next := prb^.NextThread

    IF NOT migrate AND next THEN
        // There's already a next thread selected, return that.

        prb^.NextThread = NULLPTR
        next^.Status = KI_THREAD_INFLIGHT

        RETURN next
    END

    minimumpriority := 0
    interactive := FALSE

    IF current THEN
        minimumpriority = current^.Priority
        interactive = current^.Interactive

        IF exclusive THEN
            // Only pick threads that can preempt the given one.

            minimumpriority += 1

            IF minimumpriority == 32 THEN
                // None can.

                RETURN NULLPTR
            END
        END
    END

    // Check the real time bitmap.

    readybits := prb^.RealTimeReady

    IF readybits >> minimumpriority THEN
        // We're taking a thread off the real time queues.

        next = KiSelectRealTimeThread (
            prb, // prb
            migrate, // migrate
        )

#IF BLD_MP
        IF NOT migrate OR next != NULLPTR THEN
            RETURN next
        END
#ELSE
        RETURN next
#END
    END

    IF interactive OR minimumpriority >= OS_PRIORITY_LOW_REALTIME THEN
        // Can't be preempted by anybody timeshared.

        RETURN NULLPTR
    END

    // Check the calendar queue (timeshared) bitmap.

    readybits = prb^.CalendarReady

    IF readybits THEN
        // We're taking a thread off the timeshared queues.

        next = KiSelectTimesharedThread (
            prb, // prb
            current, // current
            migrate, // migrate
        )

#IF BLD_MP
        IF NOT migrate OR next != NULLPTR THEN
            RETURN next
        END
#ELSE
        RETURN next
#END
    END

    IF minimumpriority > OS_PRIORITY_IDLE THEN
        // Can't be preempted by an idle thread.

        RETURN NULLPTR
    END

    // Check the idle thread queue.

    IF NOT RtlEmptyList ( &prb^.IdleListHead ) THEN
        // We're taking a thread off the idle queue.

        next = CONTAINEROF prb^.IdleListHead.Next TO KeThread.ReadyEntry

        RtlRemoveEntryList ( &next^.ReadyEntry )

#IF BLD_MP
        // Decrement count of ready threads.

        prb^.Load -= 1
#END

        RETURN next
    END

    // Nothing to run.

    RETURN NULLPTR
END

FN KiPreemptThread (
    IN prb : ^KiPrb,
)

    // Called at KI_IPL_DPC when theres a thread we've been preempted by and
    // it's time to switch into it.

    // Grab the next thread with the ready queue lock held.

    KiAcquireReadyQueueElevated ( prb )

    next := prb^.NextThread
    prb^.NextThread = NULLPTR
    next^.Status = KI_THREAD_INFLIGHT

    KiReleaseReadyQueueElevated ( prb )

    // If there's somehow no next thread, just return.

    IF NOT next THEN
        LEAVE
    END

    // Wait for the next thread to no longer be switching off his stack.

    KiWaitForSwitch ( next )

    // Acquire a pointer to the current thread.

    current := prb^.CurrentThread

    // Acquire the current thread's lock.

    KiAcquireThreadElevated ( current )

#IF BLD_MP
    // Indicate context switching so that anyone who grabs us from the ready
    // queue and tries to switch into us, will wait until we are off our
    // stack. This flag is cleared by KiSwitchContext.

    current^.Switching = TRUE
#END

    IF current != &prb^.IdleThread THEN
        // Ready the current thread.

        KiAcquireReadyQueueElevated ( prb )

        KiInsertThread (
            prb, // prb
            current, // thread
            FALSE, // other
        )

        KiReleaseReadyQueueElevated ( prb )
    END

    // Switch into the thread.

    KiSwitchThread (
        current, // current
        next, // thread
    )

    // KiSwitchThread returns with the thread lock released.
END

FN KiSetPriorityThread (
    IN thread : ^KeThread,
    IN priority : UWORD,
)

    // Set the new priority for a thread.

#IF BLD_CHK
    IF KiCurrentIpl () != KI_IPL_DPC THEN
        KeCrash ( "KiSetPriorityThread: IPL != KI_IPL_DPC\n" )
    END
#END

#IF BLD_MP
    // Lock the thread and any processor ready queue that it is enqueued to.

    KiAcquireThreadElevated ( thread )

    prb := thread^.CurrentPrb

    IF prb THEN
        KiAcquireReadyQueueElevated ( prb )
    END

    other := (prb != KI_CURRENT_PRB)

#ELSE
    prb := KI_CURRENT_PRB
    other := FALSE
#END

    curpri := thread^.Priority

    IF curpri == priority THEN
        // Nothing changed.

        GOTO Exit
    END

    thread^.Priority = priority

    IF thread^.Status == KI_THREAD_READY THEN
        // We changed the priority level, so the thread is now on the wrong
        // ready queue. Manually unlink it from the queue, and then re-ready
        // it to place it on the correct one.

        RtlRemoveEntryList ( &thread^.ReadyEntry )

        IF thread^.ReadyEntry.Prev == thread^.ReadyEntry.Next THEN
            // We just emptied the list. We have to clear a bit.

            IF thread^.CurrentQueue == KI_REAL_TIME_QUEUE THEN
                prb^.RealTimeReady &= ~(1 << curpri)

            ELSEIF thread^.CurrentQueue == KI_TIMESHARED_QUEUE THEN
                // The timeshared queue index was stashed in Alertable.

                prb^.CalendarReady &= ~(1 << thread^.Alertable)
            END
        END

        KiInsertThread (
            prb, // prb
            thread, // thread
            other, // other
        )

        GOTO Exit
    END

    IF priority >= curpri THEN
        // We raised priority, so there's nothing left to do.

        GOTO Exit
    END

    // Priority was dropped. It may need to be preempted.

    next : ^KeThread

    IF thread^.Status == KI_THREAD_STANDBY THEN
        // This is the next thread, so check if we have a higher priority
        // thread we should switch to instead, now that we have dropped its
        // priority.

        next = KiSelectThread (
            prb, // prb
            thread, // current
            TRUE, // exclusive
            FALSE, // migrate
        )

        IF NOT next THEN
            GOTO Exit
        END

        next^.Status = KI_THREAD_STANDBY
        prb^.NextThread = next

        // Re-ready our thread to place it on the normal ready queue.

        KiInsertThread (
            prb, // prb
            thread, // thread
            other, // other
        )

        GOTO Exit
    END

    IF thread^.Status == KI_THREAD_RUNNING THEN
        // This is the running thread, so we should see if there's now a
        // higher priority thread that should preempt it.

        IF prb^.NextThread THEN
            // A next thread was already selected.

            GOTO Exit
        END

        next = KiSelectThread (
            prb, // prb
            thread, // current
            TRUE, // exclusive
            FALSE, // migrate
        )

        IF NOT next THEN
            GOTO Exit
        END

        // Cause a preemption.

        next^.Status = KI_THREAD_STANDBY
        prb^.NextThread = next

#IF BLD_MP
        IF other THEN
            // This was a remote Prb; may have to send an IPI.

            KiSoftInterruptOther (
                prb, // targetprb
                KI_IPL_DPC, // ipl
            )

            GOTO Exit
        END
#END

        KiSoftInterruptSelf (
            prb, // targetprb
            KI_IPL_DPC, // ipl
        )
    END

@Exit

#IF BLD_MP
    IF prb THEN
        KiReleaseReadyQueueElevated ( prb )
    END

    KiReleaseThreadElevated ( thread )
#END

END

FN KiCheckInteractivity (
    IN prb : ^KiPrb,
)

    // The current thread has changed from interactive to non-interactive as a
    // result of a timer interrupt. We have to check for preemption.

    current := prb^.CurrentThread

    // Lock the ready queue.

    KiAcquireReadyQueueElevated ( prb )

    IF NOT prb^.NextThread THEN
        // Try to find a thread to preempt this one with.

        next := KiSelectThread (
            prb, // prb
            current, // current
            FALSE, // exclusive
            FALSE, // migrate
        )

        IF next THEN
            // Found one. Set it as the next thread.

            next^.Status = KI_THREAD_STANDBY
            prb^.NextThread = next
        END
    END

    KiReleaseReadyQueueElevated ( prb )
END

FN KiQuantumEnd (
    IN prb : ^KiPrb,
)

    // A quantum end has been detected on the current processor.

    current := prb^.CurrentThread

    IF current == &prb^.IdleThread THEN
        // Idle thread takes no quantum ends. This can happen if there was a
        // thread swap inbetween the quantum end request and service.

        LEAVE
    END

    // Replenish the quantum of the thread.

    current^.RemainingQuantum = KI_DEFAULT_QUANTUM

    // Decay priority by one.

    IF current^.Priority > current^.BasePriority THEN
        // If this thread should be preempted, this function will find by whom.

        KiSetPriorityThread (
            current, // thread
            current^.Priority - 1, // priority
        )

    ELSE
        // Lock the ready queue.

        KiAcquireReadyQueueElevated ( prb )

        IF NOT prb^.NextThread THEN
            // Try to find a thread to preempt this one with.

            next := KiSelectThread (
                prb, // prb
                current, // current
                FALSE, // exclusive
                FALSE, // migrate
            )

            IF next THEN
                // Found one. Set it as the next thread.

                next^.Status = KI_THREAD_STANDBY
                prb^.NextThread = next
            END
        END

        KiReleaseReadyQueueElevated ( prb )
    END
END

FN KiYield (
    IN current : ^KeThread,
    IN prb : ^KiPrb,
)

    // Yield the processor. Thread lock is held on entry, released on exit.

    // Try to find a thread to switch into.

    KiAcquireReadyQueueElevated ( prb )

    next := KiSelectThread (
        prb, // prb
        NULLPTR, // current
        FALSE, // exclusive
        FALSE, // migrate
    )

    KiReleaseReadyQueueElevated ( prb )

    IF next THEN
        // Wait for the next thread to no longer be switching off his stack.

        KiWaitForSwitch ( next )

        // Switch into it. KiSwitchThread returns with the thread lock released.

        KiSwitchThread (
            current, // current
            next, // thread
        )

    ELSE
#IF BLD_MP
        prb^.StealWork = TRUE
#END

        // Switch to the idle thread. KiSwitchThread returns with the thread
        // lock released.

        KiSwitchThread (
            current, // current
            &prb^.IdleThread, // thread
        )
    END
END

#IF BLD_MP

FN KiMoveThread (
    IN destprb : ^KiPrb,
    IN srcprb : ^KiPrb,
) : UWORD

    // Move a thread from the source to the destination.
    // Return TRUE if a thread was moved, FALSE otherwise.

    myprb := KI_CURRENT_PRB

    // Lock the source Prb.

    KiAcquireReadyQueueElevated ( srcprb )

    // Select a thread.

    thread := KiSelectThread (
        srcprb, // prb
        NULLPTR, // current
        FALSE, // exclusive
        TRUE, // migrate
    )

    IF NOT thread THEN
        // Unlikely situation, but we got no thread to move. Give up.

        KiReleaseReadyQueueElevated ( srcprb )

        RETURN FALSE
    END

    // Set INFLIGHT so nobody tries to touch it while we've got it.

    thread^.Status = KI_THREAD_INFLIGHT

    // Release the ready queue.

    KiReleaseReadyQueueElevated ( srcprb )

    // Lock the thread.

    KiAcquireThreadElevated ( thread )

    // Lock the destination Prb.

    KiAcquireReadyQueueElevated ( destprb )

    // Insert the thread.

    KiInsertThread (
        destprb, // prb
        thread, // thread
        myprb != destprb, // other
    )

    // Release the destination Prb.

    KiReleaseReadyQueueElevated ( destprb )

    // Release the thread.

    KiReleaseThreadElevated ( thread )

    RETURN TRUE
END

FN KiStealWork ()

    // This is called by the idle thread of each processor. We want to find the
    // most heavily loaded processor and steal a thread off his queues.

    ipl := KiRaiseIpl ( KI_IPL_DPC )

    myprb := KI_CURRENT_PRB

    loadedprb : ^KiPrb
    garbagecan : ^VOID

    KiFindMostAndLeastLoadedProcessor (
        OUT loadedprb, // mostloaded
        OUT garbagecan, // leastloaded
    )

    IF loadedprb == myprb THEN
        // Most loaded processor was me. Clearly, something changed while I was
        // trying to do this.

        KiLowerIpl ( ipl )

        LEAVE
    END

    IF loadedprb^.Load < KI_STEAL_LOAD THEN
        // Most loaded processor was still below the minimum stealing load.
        // Just leave.

        KiLowerIpl ( ipl )

        LEAVE
    END

    KiMoveThread (
        myprb, // destprb
        loadedprb, // srcprb
    )

    // Lower IPL - we should switch to the stolen thread.

    KiLowerIpl ( ipl )
END

#DEFINE KI_BALANCE_MAX 16

FN (KeDpcF) KiBalanceWork (
    IN dpc : ^KeDpc,
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Called once per second on processor 0. Moves work from the most loaded
    // processor to the least loaded processor until balance is achieved.

    j := 0

    WHILE j < KI_BALANCE_MAX DO
        mostloaded : ^KiPrb
        leastloaded : ^KiPrb

        KiFindMostAndLeastLoadedProcessor (
            OUT mostloaded, // mostloaded
            OUT leastloaded, // leastloaded
        )

        diff := CAST mostloaded^.Load - leastloaded^.Load TO WORD

        IF diff < 0 THEN
            // Something changed. Retry.

            CONTINUE
        END

        IF diff <= 1 THEN
            // Balance is achieved.

            LEAVE
        END

        moved := KiMoveThread (
            leastloaded, // destprb
            mostloaded, // srcprb
        )

        j += 1
    END
END

FN KiPinThread (
    IN prb : ^KiPrb,
)

    // Pin the current thread to the given processor. No locks are held on
    // entry to this function. 

    myprb := KI_CURRENT_PRB

    current := myprb^.CurrentThread

#IF BLD_CHK
    IF KiCurrentIpl () != KI_IPL_DPC THEN
        KeCrash ( "KiPinThread: IPL != KI_IPL_DPC\n" )
    END

    IF current == &myprb^.IdleThread THEN
        KeCrash ( "KiPinThread: can't pin idle thread\n" )
    END
#END

    KiAcquireThreadElevated ( current )

    current^.AffinityPrb = prb
    current^.Pinned = TRUE

    IF myprb == prb THEN
        // Already on the right processor. Nothing to do.

        KiReleaseThreadElevated ( current )

        LEAVE
    END

    // We need to insert ourselves on the target processor's ready queue and
    // then yield execution.

    // Indicate context switching so that anyone who grabs us from the ready
    // queue and tries to switch into us, will wait until we are off our
    // stack. This flag is cleared by KiSwitchContext.

    current^.Switching = TRUE

    // Ready the current thread to the target Prb.

    KiAcquireReadyQueueElevated ( prb )

    KiInsertThread (
        prb, // prb
        current, // thread
        TRUE, // other
    )

    KiReleaseReadyQueueElevated ( prb )

    // Yield the current processor.

    KiYield (
        current, // current
        myprb, // prb
    )

    // We are now pinned to the requested processor. The thread lock has been
    // released.
END

FN KiUnpinThread ()

    // Unpin the current thread. No locks are held on entry to this function.

    myprb := KI_CURRENT_PRB

    current := myprb^.CurrentThread

#IF BLD_CHK
    IF KiCurrentIpl () != KI_IPL_DPC THEN
        KeCrash ( "KiUnpinThread: IPL != KI_IPL_DPC\n" )
    END

    IF current == &myprb^.IdleThread THEN
        KeCrash ( "KiUnpinThread: can't unpin idle thread\n" )
    END
#END

    // Acquire the thread lock so that nobody sees the value of Pinned change
    // partway through an operation.

    KiAcquireThreadElevated ( current )

    current^.Pinned = FALSE

    KiReleaseThreadElevated ( current )
END

#END

#MACRO KiDequeueWaitBlock ( waitblock ) [
    object := (waitblock)^.Object

    // Acquire the object lock.

    KiAcquireObjectElevated ( object )

    IF (waitblock)^.Flags & KI_WB_DEQUEUED == 0 THEN
        // Remove the wait block.

        RtlRemoveEntryList ( &(waitblock)^.Entry )

        // Decrement waiter count, since this wait block wasn't
        // satisfied yet.

        object^.WaiterCount -= 1
    END

    // Release the object lock.

    KiReleaseObjectElevated ( object )
]

#MACRO KiIndicateActive ( thread, queue ) [
    // If we're associated with a balanced queue, we have to indicate that we've
    // awoken.

    IF queue THEN
        // Indicate that we're active again.

        KiAcquireQueueRemovalElevated ( queue )

#IF BLD_MP
        IF (thread)^.BalancedQueue THEN
#END
            KiAcquireObjectElevated ( &queue^.Header )

            queue^.ActiveThreadCount += 1

            KiReleaseObjectElevated ( &queue^.Header )
#IF BLD_MP
        END
#END

        KiReleaseQueueRemovalElevated ( queue )
    END
]

#MACRO KiIndicateDeactivated ( thread, queue ) [
    // If we're associated with a balanced queue, we have to indicate that we're
    // blocking.

    IF queue THEN
        // Indicate that we're active again.

        KiAcquireQueueRemovalElevated ( queue )

#IF BLD_MP
        IF (thread)^.BalancedQueue THEN
#END
            KiAcquireObjectElevated ( &queue^.Header )

            KiWakeBalancedQueue ( queue )

            KiReleaseObjectElevated ( &queue^.Header )
#IF BLD_MP
        END
#END

        KiReleaseQueueRemovalElevated ( queue )
    END
]

FN KiWaitThread (
    IN thread : ^KeThread,
    IN hastimeout : UWORD,
) : OsStatus

    // This function is entered with the thread lock held (IPLDPC).

    prb := KI_CURRENT_PRB

#IF BLD_CHK
    IF thread == &prb^.IdleThread THEN
        KeCrash ( "KiWaitThread: idle wait\n" )
    END
#END

    // Set the thread status to WAITING.

    thread^.Status = KI_THREAD_WAITING

    // Store tick we slept on.

    thread^.StateMs = KiLowTick ()

    // Yield.

    KiYield (
        thread, // current
        prb, // prb
    )

    // We're back! Thread lock is dropped, but we're still at KI_IPL_DPC.

    // All of our wait blocks have been marked UNWAITED, but may not have been
    // dequeued, so we have to do that now.

    waitblock := thread^.WaitBlockTable
    count := thread^.WaitCount

    WHILE count DO
        KiDequeueWaitBlock ( waitblock )

        count -= 1
        waitblock += SIZEOF KiWaitBlock
    END

    IF hastimeout THEN
        waitblock = &thread^.TimeoutWaitBlock

        // Remove the timer wait block.

        KiDequeueWaitBlock ( waitblock )

        // Cancel the timer.

        KeDequeueTimer ( &thread^.Timeout )
    END

    queue := thread^.BalancedQueue

    // If we're associated with a balanced queue, we have to indicate that we're
    // awake now.

    KiIndicateActive ( thread, queue )

    // Return the status.

    RETURN thread^.WaitStatus
END

FN KiUnwaitThread (
    IN thread : ^KeThread,
    IN status : OsStatus,
    IN priorityboost : UWORD,
)

    // Unwait the thread with the given status.
    // An object lock may be held. The thread lock is held.
    // If we're here, the thread was definitely waiting - it was either in
    // KI_THREAD_WAITING state, or KI_THREAD_RUNNING and WAIT_TRY. This means
    // that its wait block table is valid and full of initialized wait blocks.

#IF BLD_CHK
    IF thread^.Status != KI_THREAD_WAITING
#IF BLD_MP
        AND (thread^.Status != KI_THREAD_RUNNING OR
        thread^.WaitAttempt != KI_THREAD_WAIT_TRY)
#END
        THEN

        KeCrash ( "KiUnwaitThread: thread wasn't waiting %x %x\n", thread^.Status )        
    END
#END

#IF BLD_MP
    IF thread^.Status == KI_THREAD_RUNNING THEN
        // Must be in WAIT_TRY. Abort the wait.

        thread^.WaitAttempt = KI_THREAD_WAIT_ABORTED
    END
#END

    // Store the wake status in the thread object.

    thread^.WaitStatus = status

    // Set all the thread's wait blocks to UNWAITED.
    // They'll be dequeued under the lock of each object as they stumble across
    // them, and will be finally removed by the thread when it wakes up.

    waitblock := thread^.WaitBlockTable
    count := thread^.WaitCount

    WHILE count DO
        waitblock^.Flags |= KI_WB_UNWAITED

        count -= 1
        waitblock += SIZEOF KiWaitBlock
    END

    // Set the timeout wait block unwaited too. If the timer was enqueued, it'll
    // be dequeued by the thread when he wakes up or notices he was aborted.

    thread^.TimeoutWaitBlock.Flags |= KI_WB_UNWAITED

    IF thread^.Status == KI_THREAD_WAITING THEN
        // Replenish the quantum of the thread.

        thread^.RemainingQuantum = KI_DEFAULT_QUANTUM

        IF priorityboost AND thread^.Priority < OS_PRIORITY_LOW_REALTIME THEN
            // Apply the priority boost to the thread.

            newpri := thread^.BasePriority + priorityboost

            // Don't cross into the real time priority class.

            IF newpri > OS_PRIORITY_HIGH_USER THEN
                newpri = OS_PRIORITY_HIGH_USER
            END

            // Only apply the boost if it raises the thread's priority.

            IF newpri > thread^.Priority THEN
                thread^.Priority = newpri
            END
        END

        // Update the ticks the thread has spent sleeping.

        waitedms := thread^.StateMs
        currentms := KiLowTick ()

        IF waitedms < currentms THEN
            thread^.SleepMs += (currentms - waitedms) << KI_TICK_SHIFT

            // Update interactivity score.

            KiUpdateInteractivity ( thread )
        END

        // Ready the thread.

        KiReadyThread ( thread )
    END
END

FN KiSatisfyObject (
    IN object : ^KiDispatchHeader,
    IN priorityboost : UWORD,
    IN all : UWORD,
    IN status : OsStatus,
) : ^KeThread

    // Satisfy a wait on the object. The object lock is held.
    // Return a pointer to a satisfied thread object, NULLPTR if none satisfied.

    listhead := &object^.WaitListHead
    listentry := listhead^.Next

    WHILE listentry != listhead DO
        waitblock := CONTAINEROF listentry TO KiWaitBlock.Entry

        thread := waitblock^.Thread

        // Acquire the thread's lock.

        KiAcquireThreadElevated ( thread )

        // Set the wait block dequeued and remove it from our queue.

        waitblock^.Flags |= KI_WB_DEQUEUED

        RtlRemoveEntryList ( &waitblock^.Entry )

        // Decrement our waiter count.

        object^.WaiterCount -= 1

        IF waitblock^.Flags & KI_WB_UNWAITED THEN
            // This wait block was already unwaited and left on our queue by
            // someone else. Get the next one and continue.

            KiReleaseThreadElevated ( thread )

            listentry = listentry^.Next

            CONTINUE
        END

        // Still active. Unwait the thread.

        IF NOT status THEN
            // Unwait with the status stored in the wait block.

            KiUnwaitThread (
                waitblock^.Thread, // thread
                waitblock^.WakeStatus, // status
                priorityboost, // priorityboost
            )

        ELSE
            // Unwait with the specified status.

            KiUnwaitThread (
                waitblock^.Thread, // thread
                status, // status
                priorityboost, // priorityboost
            )
        END

        IF NOT all THEN
            // We got one, so exit.

            KiReleaseThreadElevated ( thread )

            RETURN thread
        END

        KiReleaseThreadElevated ( thread )

        listentry = listentry^.Next
    END

    RETURN NULLPTR
END

#MACRO KiCheckWaitInterruptingEvents ( thread, ipl, alertable, waitmode ) [
    // IPL >= KI_IPL_APC masks out all events. We also don't check unless
    // KernelInterrupt has been set, as this is pretty time consuming to do on
    // every wait operation.

    IF thread^.KernelInterrupt AND ipl == KI_IPL_LOW THEN
        thread^.KernelInterrupt = FALSE

        IF NOT alertable THEN
            IF waitmode == KE_USER_MODE AND
                thread^.SignalMask & (1 << OS_SIGNAL_KILL) THEN

                // Unalertable usermode waits are only interrupted by
                // termination.

                KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

                KiReleaseThread ( thread, ipl )

                RETURN OS_STATUS_KILLED
            END

        ELSEIF waitmode == KE_KERNEL_MODE THEN
            IF NOT thread^.IgnoreEventCount AND
                thread^.SignalMask & (1 << OS_SIGNAL_KILL) THEN

                // Alertable kernel mode waits are only interrupted by
                // termination.

                KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

                KiReleaseThread ( thread, ipl )

                RETURN OS_STATUS_KILLED
            END

        ELSEIF NOT RtlEmptyList ( &thread^.LapcListHead ) THEN
            // There are pending lazy APCs and this is a usermode wait,
            // so dispatch them and retry.

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            KiReleaseThread ( thread, ipl )

            KiDispatchLazyApcQueue ( thread )

            GOTO Retry

        ELSEIF NOT RtlEmptyList ( &thread^.UapcListHead ) THEN
            // There are pending usermode APCs and this is a usermode
            // wait, so interrupt the wait and cause them to be
            // dispatched upon return to userspace.

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            thread^.UserApcTriggered = TRUE
            thread^.UserInterrupt = TRUE

            KiReleaseThread ( thread, ipl )

            RETURN OS_STATUS_USER_APC

        ELSEIF thread^.SignalMask &
            thread^.SignalAcceptMask &
            thread^.SignalDeliverOnWaitMask THEN

            // There are pending signals and this is a usermode wait, so
            // interrupt the wait and cause them to be dispatched upon return
            // to usermode.

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            thread^.SignalDeliverOnWaitMask &= ~thread^.SignalMask
            thread^.UserInterrupt = TRUE

            KiReleaseThread ( thread, ipl )

            RETURN OS_STATUS_SIGNALED
        END
    END
]

#MACRO KiWaitHead ( thread, ipl, alertable, waitmode, waitblocktable, waitcount, starttime, timeout ) [

#IF BLD_CHK
    IF KiCurrentIpl () >= KI_IPL_DPC THEN
        KeCrash ( "Attempt to wait at IPL >= KI_IPL_DPC\n" )
    END
#END

    // Raise IPL to stop APCs from corrupting our wait state if they come in
    // and try to wait in our context.

    ipl := KiRaiseIpl ( KI_IPL_DPC )

    // Capture the start time.

    IF timeout THEN
        KiCaptureCurrentTicks ( starttime )
    END

    // Clear timeout wait block flags field.

    thread^.TimeoutWaitBlock.Flags = 0

    // Set the wait values in the thread.

    thread^.Alertable = alertable
    thread^.WaitMode = waitmode
    thread^.WaitIpl = ipl

    // Store the wait block table in the thread.

    thread^.WaitBlockTable = waitblocktable
    thread^.WaitCount = waitcount

    // Acquire the thread lock to check for interrupting events.

    KiAcquireThreadElevated ( thread )

    // Set the thread to wait-try.
    //
    // Note that this wait-try tactic was derived from an explanation given
    // by Arun Kishan in an interview about how the Windows kernel team
    // broke up the dispatcher spinlock.

    KiSetWaitAttempt ( thread, KI_THREAD_WAIT_TRY )

    // Before we start, check for events that would interrupt the wait.
    // This is a macro that can return from the function for us (after
    // dropping the thread lock).

    KiCheckWaitInterruptingEvents (
        thread, // thread
        ipl, // ipl
        alertable, // alertable
        waitmode, // waitmode
    )

    KiReleaseThreadElevated ( thread )
]

#MACRO KiKernelApcReceived ( timeout, starttime ) [
    // A kernel APC interrupted the wait, so decrement the timeout based on how
    // many milliseconds have transpired since the wait began.

    currenttime : RtlUquad

    KiCaptureCurrentTicks ( &currenttime )

    RtlSubUquadFromUquad ( &currenttime, starttime )

    IF RtlUquadLtUquad ( &currenttime, timeout ) THEN
        RtlSubUquadFromUquad ( timeout, &currenttime )

    ELSE
        // Timeout already expired.

        RETURN OS_STATUS_WAIT_TIMEOUT
    END
]

EXPORT FN KeWaitForObjects (
    IN waitmode : UWORD,
    IN alertable : UWORD,
    IN timeout : ^RtlUquad,
    IN objectcount : UWORD,
    IN objecttable : ^^KiDispatchHeader,
    IN waitblocktable : ^KiWaitBlock,
) : OsStatus

    // Wait for any of multiple objects to enter a signaled state. A timeout
    // interval in milliseconds can be supplied. If it is NULLPTR, the timeout
    // is infinite.

#IF BLD_CHK
    // The following parameters should never be given by executive callers and
    // should have been rejected by the object manager.

    IF objectcount == 0 THEN
        KeCrash ( "KeWaitForObjects: objectcount == 0\n" )
    END

#IF ( == BLD_BITS 64 )
    IF objectcount > 0xFFFFFFFF THEN
        KeCrash ( "KeWaitForObjects: objectcount > ULONG size\n" )
    END
#END

#END

    thread := KeCurrentThread ()

    IF NOT waitblocktable THEN
#IF BLD_CHK
        IF objectcount > KI_THREAD_WAIT_BLOCKS THEN
            KeCrash ( "objectcount > KI_THREAD_WAIT_BLOCKS\n" )
        END
#END

        // Use the integral wait blocks of the thread.
        // This mechanism exists to remove dependency on allocation.

        waitblocktable = &thread^.WaitBlocks[0]
    END

    capturedtimeout : RtlUquad

    IF timeout THEN
        RtlMoveUquad (
            &capturedtimeout, // dest
            timeout, // src
        )
    END

    // Initialize all of the wait blocks now.
    // This isn't just to reduce time at KI_IPL_DPC - if we initialize them
    // while enqueuing wait blocks to the objects, clearing the Flags field
    // is racey with other processors satisfying object waits.

    i := 0
    waitblock := &waitblocktable[0]

    WHILE i < objectcount DO
        waitblock^.Thread = thread
        waitblock^.Object = objecttable[i]
        waitblock^.WakeStatus = i
        waitblock^.Flags = 0

        i += 1
        waitblock += SIZEOF KiWaitBlock
    END

@Retry

    // The following function is a macro that can perform an early return.
    // It puts us in a WAIT_TRY state and raises IPL to KI_IPL_DPC.

    starttime : RtlUquad

    KiWaitHead (
        thread, // thread
        ipl, // ipl
        alertable, // alertable
        waitmode, // waitmode
        waitblocktable, // waitblocktable
        objectcount, // waitcount
        &starttime, // starttime
        timeout, // timeout
    )

    timer : ^KeTimer
    status : OsStatus
    object : ^KiDispatchHeader

    waitblock = &waitblocktable[0]
    i = 0

    WHILE i < objectcount DO
        object = objecttable[i]

        KiAcquireObjectElevated ( object )

        // Capture the current signal count.

        signal := object^.SignalCount

        IF signal THEN
            // Already signaled. Our wait has been satisfied before it began.
            // If this isn't a notification event, consume the count.

            IF object^.Type != KI_DISPATCH_EVENT_NOTIF THEN
                object^.SignalCount = signal - 1
            END

            KiReleaseObjectElevated ( object )

            status = i

@Abort

            // Back out of the wait by simply removing our wait blocks from all
            // of the objects that we enqueued them to.
            //
            // Note the label above - on MP we GOTO here if another processor
            // rudely aborted our wait.
            //
            // At this point "i" is equivalent to the maximum object index we
            // reached before we aborted, and "status" is equivalent to whatever
            // we should return when we leave.
            //
            // Remove our wait blocks from every object we enqueued them to.

            j := 0
            waitblock = &waitblocktable[0]

            WHILE j < i DO
                KiDequeueWaitBlock ( waitblock )

                j += 1
                waitblock += SIZEOF KiWaitBlock
            END

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            KiLowerIpl ( ipl )

            IF status != OS_STATUS_KERNEL_APC THEN
                RETURN status
            END

            GOTO KernelApcReceived
        END

        // Enqueue our wait block to the object.

        RtlInsertAtTailList (
            &object^.WaitListHead, // head
            &waitblock^.Entry, // entry
        )

        // Increment waiter count.

        object^.WaiterCount += 1

        // Release the object lock.

        KiReleaseObjectElevated ( object )

        waitblock += SIZEOF KiWaitBlock
        i += 1
    END

    IF timeout THEN
        // Start the timeout.
        // NOTE: The timer object and the timeout wait block have been
        //       initialized by KeInitializeThread already.

        waitblock = &thread^.TimeoutWaitBlock
        timer = &thread^.Timeout

        // Insert the wait block in the timer's list.
        // This is safe to do without a lock because only we ever mess with
        // this timer in the context of this thread.

        RtlInsertAtTailList (
            &timer^.Header.WaitListHead, // head
            &waitblock^.Entry, // entry
        )

        timer^.Header.WaiterCount = 1

        // Enqueue the timer.

        KeEnqueueTimer (
            timer, // timer
            &capturedtimeout, // interval
            0, // context1
            0, // context2
        )
    END

    queue := thread^.BalancedQueue

    // If we're associated with a balanced queue, we have to indicate that we
    // are blocking so that someone else can be awoken.

    KiIndicateDeactivated ( thread, queue )

    // Lock our thread.

    KiAcquireThreadElevated ( thread )

#IF BLD_MP
    // Check if an interrupting event (such as the object being signaled, a user
    // APC, etc) from another processor aborted our wait while we were enqueuing
    // wait blocks.

    IF thread^.WaitAttempt == KI_THREAD_WAIT_ABORTED THEN
        // It was aborted. We have to dequeue all our wait blocks and return.
        //
        // Release the thread lock so we don't violate the object->thread
        // lock ordering.

        KiReleaseThreadElevated ( thread )

        IF timeout THEN
            // We need to get rid of the timer.

            waitblock = &thread^.TimeoutWaitBlock
            timer = &thread^.Timeout

            // Dequeue it.

            KeDequeueTimer ( timer )

            // Remove the wait block.
            // We don't need the timer's object lock because we've been
            // nonpreemptible and blocking out the expiration DPC for this
            // processor since we enqueued it. Therefore it is still in our
            // custody.

            RtlRemoveEntryList ( &waitblock^.Entry )
        END

        // If we're associated with a balanced queue, we indicated that we were
        // deactivated. We have to undo that now.

        KiIndicateActive ( thread, queue )

        // The guy who aborted the wait left our status in our thread struct.

        status = thread^.WaitStatus

        GOTO Abort
    END

    thread^.WaitAttempt = KI_THREAD_WAIT_COMMITTED
#END

    // The wait shall proceed.

    status = KiWaitThread (
        thread, // thread
        timeout, // hastimeout
    )

    KiLowerIpl ( ipl )

    // KiWaitThread returns with the thread lock released.
    // All of our wait blocks have been dequeued, timer dequeued, etc.

    IF status != OS_STATUS_KERNEL_APC THEN
        RETURN status
    END

@KernelApcReceived

    IF timeout THEN
        KiKernelApcReceived ( &capturedtimeout, &starttime )
    END

    GOTO Retry
END

EXPORT FN KeSleep (
    IN interval : ^RtlUquad,
    IN waitmode : UWORD,
    IN alertable : UWORD,
) : OsStatus

    thread := KeCurrentThread ()

    capturedinterval : RtlUquad

    RtlMoveUquad (
        &capturedinterval, // destquad
        interval, // srcquad
    )

@Retry

    // The following function is a macro that can perform an early return.
    // It puts us in a WAIT_TRY state and raises IPL to KI_IPL_DPC.

    starttime : RtlUquad

    KiWaitHead (
        thread, // thread
        ipl, // ipl
        alertable, // alertable
        waitmode, // waitmode
        NULLPTR, // waitblocktable
        0, // waitcount
        &starttime, // starttime
        interval, // timeout
    )

    status : OsStatus

    // Start the timeout.
    // NOTE: The timer object and the timeout wait block have been
    //       initialized by KeInitializeThread already.

    waitblock := &thread^.TimeoutWaitBlock
    timer := &thread^.Timeout

    // Insert the wait block in the timer's list.
    // This is safe to do without a lock because only we ever mess with
    // this timer in the context of this thread.

    RtlInsertAtTailList (
        &timer^.Header.WaitListHead, // head
        &waitblock^.Entry, // entry
    )

    timer^.Header.WaiterCount = 1

    // Enqueue the timer.

    KeEnqueueTimer (
        timer, // timer
        &capturedinterval, // interval
        0, // context1
        0, // context2
    )

    queue := thread^.BalancedQueue

    // If we're associated with a balanced queue, we have to indicate that we
    // are blocking so that someone else can be awoken.

    KiIndicateDeactivated ( thread, queue )

    // Lock our thread.

    KiAcquireThreadElevated ( thread )

#IF BLD_MP
    // Check if an interrupting event (such as the object being signaled, a user
    // APC, etc) from another processor aborted our wait while we were enqueuing
    // wait blocks.

    IF thread^.WaitAttempt == KI_THREAD_WAIT_ABORTED THEN
        // It was aborted. We have to dequeue all our wait blocks and return.
        //
        // Release the thread lock so we don't violate the object->thread
        // lock ordering.

        KiReleaseThreadElevated ( thread )

        // We need to get rid of the timer.

        // Dequeue it.

        KeDequeueTimer ( timer )

        // Remove the wait block.
        // We don't need the timer's object lock because we've been
        // nonpreemptible and blocking out the expiration DPC for this
        // processor since we enqueued it. Therefore it is still in our
        // custody.

        RtlRemoveEntryList ( &waitblock^.Entry )

        // The guy who aborted the wait left our status in our thread struct.

        status = thread^.WaitStatus

        // Set to not waiting.

        KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

        // If we're associated with a balanced queue, we indicated that we were
        // deactivated. We have to undo that now.

        KiIndicateActive ( thread, queue )

        KiLowerIpl ( ipl )

        IF status != OS_STATUS_KERNEL_APC THEN
            RETURN status
        END

        GOTO KernelApcReceived
    END

    thread^.WaitAttempt = KI_THREAD_WAIT_COMMITTED
#END

    // The wait shall proceed.

    status = KiWaitThread (
        thread, // thread
        TRUE, // hastimeout
    )

    KiLowerIpl ( ipl )

    // KiWaitThread returns with the thread lock released.
    // All of our wait blocks have been dequeued, timer dequeued, etc.

    IF status != OS_STATUS_KERNEL_APC THEN
        RETURN status
    END

@KernelApcReceived

    KiKernelApcReceived ( &capturedinterval, &starttime )

    GOTO Retry
END

EXPORT FN KeWaitForSingleObject (
    IN waitmode : UWORD,
    IN alertable : UWORD,
    IN timeout : ^RtlUquad,
    IN object : ^KiDispatchHeader,
) : OsStatus

    // Wait for a single object to enter a signaled state. A timeout
    // interval in milliseconds can be supplied. If it is NULLPTR, the timeout
    // is infinite.

    thread := KeCurrentThread ()

    singlewaitblock : KiWaitBlock

    capturedtimeout : RtlUquad

    IF timeout THEN
        RtlMoveUquad (
            &capturedtimeout, // dest
            timeout, // src
        )
    END

    // Initialize all of the wait blocks now.
    // This isn't just to reduce time at KI_IPL_DPC - if we initialize them
    // while enqueuing wait blocks to the objects, clearing the Flags field
    // is racey with other processors satisfying object waits.

    singlewaitblock.Thread = thread
    singlewaitblock.Object = object
    singlewaitblock.WakeStatus = 0
    singlewaitblock.Flags = 0

@Retry

    // The following function is a macro that can perform an early return.
    // It puts us in a WAIT_TRY state and raises IPL to KI_IPL_DPC.

    starttime : RtlUquad

    KiWaitHead (
        thread, // thread
        ipl, // ipl
        alertable, // alertable
        waitmode, // waitmode
        &singlewaitblock, // waitblocktable
        1, // waitcount
        &starttime, // starttime
        timeout, // timeout
    )

    timer : ^KeTimer
    status : OsStatus

    KiAcquireObjectElevated ( object )

    IF object^.Type != KI_DISPATCH_BALANCED_QUEUE THEN
        IF object^.SignalCount THEN
            // Already signaled. Our wait has been satisfied before it began.
            // If this isn't a notification event, consume the count.

            IF object^.Type != KI_DISPATCH_EVENT_NOTIF THEN
                object^.SignalCount -= 1
            END

            KiReleaseObjectElevated ( object )

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            KiLowerIpl ( ipl )

            RETURN 0
        END

    ELSE
        // This is a balanced queue. If there's a pending item, grab it.

        queue := CONTAINEROF object TO KeBalancedQueue.Header

        IF NOT RtlEmptyList ( &queue^.ItemListHead ) AND
            queue^.ActiveThreadCount <= queue^.MaximumThreadCount THEN

            // Grab the item.

            item := queue^.ItemListHead.Next

            // Stash it in the thread object.

            thread^.QueueItem = item

            // Remove it from the list.

            RtlRemoveEntryList ( item )

            // Back out and return.

            KiReleaseObjectElevated ( object )

            KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

            KiLowerIpl ( ipl )

            RETURN 0
        END
    END

    // Enqueue our wait block to the object.

    RtlInsertAtTailList (
        &object^.WaitListHead, // head
        &singlewaitblock.Entry, // entry
    )

    // Increment waiter count.

    object^.WaiterCount += 1

    // Release the object lock.

    KiReleaseObjectElevated ( object )

    waitblock : ^KiWaitBlock

    IF timeout THEN
        // Start the timeout.
        // NOTE: The timer object and the timeout wait block have been
        //       initialized by KeInitializeThread already.

        waitblock = &thread^.TimeoutWaitBlock
        timer = &thread^.Timeout

        // Insert the wait block in the timer's list.
        // This is safe to do without a lock because only we ever mess with
        // this timer in the context of this thread.

        RtlInsertAtTailList (
            &timer^.Header.WaitListHead, // head
            &waitblock^.Entry, // entry
        )

        timer^.Header.WaiterCount = 1

        // Enqueue the timer.

        KeEnqueueTimer (
            timer, // timer
            &capturedtimeout, // interval
            0, // context1
            0, // context2
        )
    END

    queue := thread^.BalancedQueue

    // If we're associated with a balanced queue, we have to indicate that we
    // are blocking so that someone else can be awoken.

    KiIndicateDeactivated ( thread, queue )

    // Lock our thread.

    KiAcquireThreadElevated ( thread )

#IF BLD_MP
    // Check if an interrupting event (such as the object being signaled, a user
    // APC, etc) from another processor aborted our wait while we were enqueuing
    // wait blocks.

    IF thread^.WaitAttempt == KI_THREAD_WAIT_ABORTED THEN
        // It was aborted. We have to dequeue all our wait blocks and return.
        //
        // Release the thread lock so we don't violate the object->thread
        // lock ordering.

        KiReleaseThreadElevated ( thread )

        IF timeout THEN
            // We need to get rid of the timer.

            waitblock = &thread^.TimeoutWaitBlock
            timer = &thread^.Timeout

            // Dequeue it.

            KeDequeueTimer ( timer )

            // Remove the wait block.
            // We don't need the timer's object lock because we've been
            // nonpreemptible and blocking out the expiration DPC for this
            // processor since we enqueued it. Therefore it is still in our
            // custody.

            RtlRemoveEntryList ( &waitblock^.Entry )
        END

        // The guy who aborted the wait left our status in our thread struct.

        status = thread^.WaitStatus

        // Dequeue the single wait block.

        KiDequeueWaitBlock ( &singlewaitblock )

        // Set to not waiting.

        KiSetWaitAttempt ( thread, KI_THREAD_WAIT_NONE )

        // If we're associated with a balanced queue, we indicated that we were
        // deactivated. We have to undo that now.

        KiIndicateActive ( thread, queue )

        KiLowerIpl ( ipl )

        IF status != OS_STATUS_KERNEL_APC THEN
            RETURN status
        END

        GOTO KernelApcReceived
    END

    thread^.WaitAttempt = KI_THREAD_WAIT_COMMITTED
#END

    // The wait shall proceed.

    status = KiWaitThread (
        thread, // thread
        timeout, // hastimeout
    )

    KiLowerIpl ( ipl )

    // KiWaitThread returns with the thread lock released.
    // All of our wait blocks have been dequeued, timer dequeued, etc.

    IF status != OS_STATUS_KERNEL_APC THEN
        RETURN status
    END

@KernelApcReceived

    IF timeout THEN
        KiKernelApcReceived ( &capturedtimeout, &starttime )
    END

    GOTO Retry
END