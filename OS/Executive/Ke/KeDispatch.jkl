//
// Implements the processor dispatcher for the MINTIA Kernel.
//

// Lock ordering:
//
//  Object -> Thread -> ReadyQueue

#INCLUDE "Ki.hjk"

#IF BLD_MP

#MACRO KiAcquireReadyQueueElevated ( prb ) [
    KiAcquireSpinlock ( &(prb)^.ReadyQueueLock )
]

#MACRO KiReleaseReadyQueueElevated ( prb ) [
    KiReleaseSpinlock ( &(prb)^.ReadyQueueLock )
]

#MACRO KiReleaseReadyQueueAndThreadElevated ( prb, thread ) [
    KiReleaseTwoSpinlocks ( &(prb)^.ReadyQueueLock, &(thread)^.Spinlock )
]

#MACRO KiReleaseTwoReadyQueuesElevated ( prb1, prb2 ) [
    KiReleaseTwoSpinlocks ( &(prb1)^.ReadyQueueLock, &(prb2)^.ReadyQueueLock )
]

#MACRO KiWaitForSwitch ( thread ) [
    // Wait for the next thread to no longer be switching off his stack.

    WHILE (thread)^.Switching DO
        // Language BARRIER to ensure this loop isn't optimized out.

        BARRIER

        KeSpinPause ()
    END
]

#MACRO KiDecrementLoad ( prb ) [
    NOTHING (prb)^.Load -= 1
]

#MACRO KiIncrementLoad ( prb ) [
    NOTHING (prb)^.Load += 1
]

#ELSE

#MACRO KiAcquireReadyQueueElevated ( prb ) []

#MACRO KiReleaseReadyQueueElevated ( prb ) []

#MACRO KiReleaseReadyQueueAndThreadElevated ( prb, thread ) []

#MACRO KiWaitForSwitch ( thread ) []

#MACRO KiDecrementLoad ( prb ) []

#MACRO KiIncrementLoad ( prb ) []

#END

#MACRO KiSetNextThread ( prb, next ) [
    prb^.NextThread = next
    next^.Status = KI_THREAD_STANDBY

#IF BLD_MP
    // Stash these in the Prb so that they can be examined locklessly by
    // remote processors.

    prb^.StashedCurrentThreadInfo =
        (next^.Priority << KI_STASHED_PRIORITY_SHIFT) |
        (next^.InteractiveBits << KI_STASHED_INTERACTIVE_SHIFT)

    // Clear StealWork in case the processor is planning on doing that, since
    // that has become unnecessary now it isn't gonna become idle.

    prb^.StealWork = FALSE
#END
]

#SECTION "text"
PUBLIC KiIndexFirstBitSet : UBYTE[256] = {
    8, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    5, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    6, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    5, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    7, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    5, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    6, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    5, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
    4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,
}

#SECTION "text"
PUBLIC KiIndexLastBitSet : UBYTE[256] = {
    8, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
}

#DEFINE KI_INTERACT_MAX 100
#DEFINE KI_INTERACT_HALF ( / KI_INTERACT_MAX 2 )
#DEFINE KI_INTERACT_THRESH 15
#DEFINE KI_SLP_RUN_MAX ( << 5000 KI_TICK_SHIFT )

FN KiJumpIntoIdleThread (
    IN prb : ^KiPrb,
)

    // Called by a processor when it first enters the system to initially jump
    // into its idle thread.

    // Set parameters for new thread.

    prb^.CurrentThread = &prb^.IdleThread
    prb^.KernelStackTop = prb^.IdleThread.KernelStackTop

    KiSetCurrentThreadForProcessor ( &prb^.IdleThread )

    // Switch into our idle thread.

    KiJumpIntoThread ( &prb^.IdleThread )
END

FN KiUpdateInteractivity (
    IN thread : ^KeThread,
    IN deferupdate : UWORD,
)

    // Update the sliding history of thread interactivity.
    // Adapted from sched_interact_update in sched_ule.c, the FreeBSD ULE
    // scheduler.

    IF thread^.Priority == OS_PRIORITY_IDLE THEN
        LEAVE
    END

    sum := thread^.RunMs + thread^.SleepMs

    IF sum < KI_SLP_RUN_MAX THEN
        // Not enough history.

        GOTO SetInteractive
    END

    IF sum > KI_SLP_RUN_MAX * 2 THEN
        // There's an excessive amount of history.
        // Reset the values to evade overflow.

        IF thread^.RunMs > thread^.SleepMs THEN
            thread^.RunMs = KI_SLP_RUN_MAX
            thread^.SleepMs = 1

        ELSE
            thread^.RunMs = 1
            thread^.SleepMs = KI_SLP_RUN_MAX
        END

        GOTO SetInteractive
    END

    // If we have exceeded by more than 1/5 then the algorithm below will not
    // bring us back into range. Dividing by two here forces us into the range
    // of [4/5 * KI_SLP_RUN_MAX, KI_SLP_RUN_MAX].

    IF sum > (KI_SLP_RUN_MAX / 5) * 6 THEN
        thread^.RunMs /= 2
        thread^.SleepMs /= 2

        GOTO SetInteractive
    END

    thread^.RunMs = (thread^.RunMs / 5) * 4
    thread^.SleepMs = (thread^.SleepMs / 5) * 4

@SetInteractive

    // Calculate the interactivity score.

    score : WORD
    div : UWORD

    IF thread^.RunMs > thread^.SleepMs THEN
        div = thread^.RunMs / KI_INTERACT_HALF

        IF NOT div THEN
            div = 1
        END

        score = CAST KI_INTERACT_HALF +
            (KI_INTERACT_HALF - (thread^.SleepMs / div)) TO WORD

    ELSEIF thread^.RunMs < thread^.SleepMs THEN
        div = thread^.SleepMs / KI_INTERACT_HALF

        IF NOT div THEN
            div = 1
        END

        score = CAST thread^.RunMs / div TO WORD

    ELSEIF thread^.RunMs THEN
        score = KI_INTERACT_HALF

    ELSE
        score = 0
    END

    IF score < KI_INTERACT_THRESH AND
        NOT KiIsInteractiveForBehavior ( thread ) THEN

        // Changing from non-interactive to interactive.

        IF deferupdate THEN
            GOTO DeferUpdate
        END

        KiSetInteractiveForBehavior ( thread )

    ELSEIF KiIsInteractiveForBehavior ( thread ) THEN
        // Changing from interactive to non-interactive.

        IF deferupdate THEN
            GOTO DeferUpdate
        END

        KiClearInteractiveForBehavior ( thread )
    END

    LEAVE

@DeferUpdate

    // Our caller was the timer interrupt or something.
    // We have to defer the actual update to the Interactive field
    // to a lower IPL holding the thread spinlock.

    prb := KI_CURRENT_PRB_LOCAL

    prb^.CheckInteractivity = TRUE

    KiSoftInterruptSelf ( prb, KI_IPL_DPC )
END

FN KiSwitchThread (
    IN current : ^KeThread,
    IN thread : ^KeThread,
)

    // The current thread is locked, unless it is NULLPTR (in which case this is
    // the first thread switch in the lifetime of the system).
    //
    // The target thread is not locked as it has been removed from the ready
    // queue and is in our custody.

    KeAssert ( KiCurrentIpl () == KI_IPL_DPC )
    KeAssert ( current != thread )
    KeAssert ( current != NULLPTR )
    KeAssert ( thread != NULLPTR )

    // Set affinity to this processor.

    prb := KI_CURRENT_PRB

#IF BLD_MP
    thread^.AffinityPrb = prb
#END

    // Store tick the new thread started running on.

    thread^.StateMs = KiLowTick ()

    // See if we have to switch address spaces.

    nextproc := thread^.Process

    IF nextproc^.PageDirectoryPfn != current^.Process^.PageDirectoryPfn THEN
        // Switch to the address space of the new process.

        KiSwitchAddressSpace ( nextproc )
    END

    // Set parameters for new thread. We have to do this *before* we call
    // KiSwitchContext since we've lost custody of the thread immediately
    // after it releases the spinlock, so it would be incorrect for the interval
    // timer interrupt or anyone else to think its safe to reference it through
    // the CurrentThread field of the Prb after that moment. We want that to
    // always be safe so here we do this.

    prb^.CurrentThread = thread
    prb^.KernelStackTop = thread^.KernelStackTop

    KiSetCurrentThreadForProcessor ( thread )

    // Note that KiSwitchContext releases the old thread's lock.
    // It is not reacquired before switching back in.

    KiSwitchContext (
        thread, // newthread
        current, // oldthread
    )

    KeAssert ( current == KeCurrentThread () )

    // We're back in the context of the "current" thread. This is always where
    // the hole that the gopher pops back out of is, except in the case of a
    // newly created thread being dispatched for the first time.
END

FN KiInsertThread (
    IN prb : ^KiPrb,
    IN thread : ^KeThread,
    IN other : UWORD,
    IN preempted : UWORD,
)

    // Insert a thread into the appropriate ready queue of the given processor.
    // We *don't* try to synchronize against this thread being readied by
    // multiple processors at once, so there should be a well defined and
    // exclusive custody of the thread object by the caller at this point. Also
    // the ready queue of the processor should be locked. Also the thread lock
    // is held.

    thread^.Status = KI_THREAD_READY

#IF BLD_MP
    thread^.CurrentPrb = prb

    // Increment count of ready threads on this processor.

    KiIncrementLoad ( prb )
#END

    current := prb^.CurrentThread
    next := prb^.NextThread

    compare := next

    IF NOT compare THEN
        compare = current
    END

    IF thread^.Priority >= OS_PRIORITY_LOW_REALTIME OR
        thread^.InteractiveBits THEN

        // It's either one of the forced real time priorities or we've deemed it
        // interactive. Either way it goes in the real time queue or preempts
        // the current thread.

        IF (compare^.Priority >= OS_PRIORITY_LOW_REALTIME OR
            compare^.InteractiveBits) AND
            thread^.Priority <= compare^.Priority THEN

            thread^.CurrentQueue = KI_REAL_TIME_QUEUE

            IF preempted THEN
                // Go on the front of the queue.

                RtlInsertAtHeadList (
                    &prb^.RealTimeListHeads[thread^.Priority], // head
                    &thread^.ReadyEntry, // entry
                )
            ELSE
                // Go on the back of the queue.

                RtlInsertAtTailList (
                    &prb^.RealTimeListHeads[thread^.Priority], // head
                    &thread^.ReadyEntry, // entry
                )
            END

            // Indicate that an item exists in this queue.

            prb^.RealTimeReady |= 1 << thread^.Priority

            LEAVE
        END

    ELSE
        // It's a timeshared or idle thread. There's only one thing these can
        // preempt - the idle thread.

        IF compare != &prb^.IdleThread THEN
            // No preemption. Just place on the appropriate queue.

            IF thread^.Priority == OS_PRIORITY_IDLE THEN
                // Idle queue.

                thread^.CurrentQueue = KI_IDLE_QUEUE

                IF preempted THEN
                    RtlInsertAtHeadList (
                        &prb^.IdleListHead, // head
                        &thread^.ReadyEntry, // entry
                    )
                ELSE
                    RtlInsertAtTailList (
                        &prb^.IdleListHead, // head
                        &thread^.ReadyEntry, // entry
                    )
                END

                LEAVE
            END

            // Timeshared queue.

            thread^.CurrentQueue = KI_TIMESHARED_QUEUE

            insertat := prb^.CalendarEnqueueIndex

            IF NOT preempted THEN
                // Bias the index by the inverse of the priority, so that higher
                // priority timeshared threads are scheduled sooner.

                insertat = (insertat + KI_TIMESHARED_DISTANCE - thread^.Priority)
                    % KI_TIMESHARED_QUEUES

                IF prb^.CalendarRunIndex != prb^.CalendarEnqueueIndex AND
                    insertat == prb^.CalendarRunIndex THEN

                    insertat -= 1
                    insertat %= KI_TIMESHARED_QUEUES
                END
            END

            // Reuse Alertable to stash the timeshared queue index.

            thread^.Alertable = insertat

            // Go on the back of the queue.

            RtlInsertAtTailList (
                &prb^.CalendarListHeads[insertat], // head
                &thread^.ReadyEntry, // entry
            )

            // Indicate that an item exists in this queue.

            prb^.CalendarReady |= 1 << insertat

            LEAVE
        END
    END

    // Decrement count of ready threads. We don't count standby and running
    // threads in this counter.

    KiDecrementLoad ( prb )

    // Cause a preemption.

    KiSetNextThread (
        prb, // prb
        thread, // thread
    )

    IF next THEN
        // Recursively re-ready the preempted NextThread. Don't fear - this can
        // only nest one level deep.

        KiInsertThread (
            prb, // prb
            next, // thread
            other, // other
            TRUE, // preempted
        )

    ELSE
        // Trigger a software interrupt.

#IF BLD_MP
        IF other THEN
            // This was a remote Prb; may have to send an IPI.

            KiSoftInterruptOther (
                prb, // targetprb
                KI_IPL_DPC, // ipl
            )

            LEAVE
        END
#END

        KiSoftInterruptSelf (
            prb, // targetprb
            KI_IPL_DPC, // ipl
        )
    END
END

#IF BLD_MP

FN KiWouldPreempt (
    IN thread1 : ^KeThread,
    IN targetprb : ^KiPrb,
) : UWORD

    // Returns TRUE if thread1 would preempt the current thread on the target
    // processor. We do this locklessly.

    // Language-level BARRIER is to ensure that the value of the stash is only
    // loaded once by the compiler.

    stash := targetprb^.StashedCurrentThreadInfo
    BARRIER

    pri1 := thread1^.Priority

    pri2 := KiCurrentThreadPriority ( stash )

    IF thread1^.InteractiveBits THEN
        IF NOT KiCurrentThreadInteractivity ( stash ) THEN
            // Interactive threads always preempt non-interactive threads.

            RETURN TRUE
        END

        // Both are interactive. Compare priorities.

        RETURN pri1 > pri2
    END

    IF pri1 >= OS_PRIORITY_LOW_REALTIME AND
        pri1 > pri2 THEN

        // Higher priority real time threads preempt all other threads.

        RETURN TRUE
    END

    IF pri1 > OS_PRIORITY_IDLE AND
        pri2 == OS_PRIORITY_IDLE THEN

        // Non-idle threads always preempt idle threads.

        RETURN TRUE
    END

    IF KiCurrentThreadIdle ( stash ) THEN
        // Always preempt the idle thread.

        RETURN TRUE
    END

    RETURN FALSE
END

FN KiFindProcessor (
    IN prb : ^KiPrb,
    IN thread : ^KeThread,
) : ^KiPrb

    // Scan for the preemptible processor with the lowest load.
    // Start from the current processor to minimize IPIs by preferentially
    // enqueuing to it.
    //
    // At the same time, scan for the processor with the lowest load in
    // general.

    procs := KeLoaderBlock.ProcessorCount

    preemptprb : ^KiPrb = NULLPTR
    unloadedprb : ^KiPrb = NULLPTR

    i := 0
    id := prb^.Id

    WHILE TRUE DO
        preempt := KiWouldPreempt (
            thread, // thread
            prb, // targetprb
        )

        IF preempt THEN
            IF NOT preemptprb THEN
                preemptprb = prb

            ELSEIF prb^.Load < preemptprb^.Load THEN
                preemptprb = prb
            END
        END

        IF NOT unloadedprb THEN
            unloadedprb = prb

        ELSEIF prb^.Load < unloadedprb^.Load THEN
            unloadedprb = prb
        END

        i += 1

        IF i >= procs THEN
            BREAK
        END

        id += 1

        IF id >= procs THEN
            id = 0
        END

        prb = KiPrbFromNumber ( id )
    END

    IF preemptprb THEN
        // Select the preemptible processor with the least load.

        RETURN preemptprb
    END

    // Select the least loaded processor in general.

    RETURN unloadedprb
END

FN KiFindMostAndLeastLoadedProcessor (
    OUT mostloaded : ^KiPrb,
    OUT leastloaded : ^KiPrb,
)

    // Find and return the most and least loaded processors.

    procs := KeLoaderBlock.ProcessorCount

    mostloaded = KiPrbFromNumber ( 0 )
    leastloaded = mostloaded

    i := 1
    prb := mostloaded + BL_PRB_SIZE

    WHILE i < procs DO
        IF prb^.Load < leastloaded^.Load THEN
            leastloaded = prb
        END

        IF prb^.Load > mostloaded^.Load THEN
            mostloaded = prb
        END

        i += 1
        prb += BL_PRB_SIZE
    END
END

#END

FN KiReadyThread (
    IN thread : ^KeThread,
)

    // Ready the thread by inserting it into an appropriate ready queue.
    // Thread lock is held.

@Retry

    IF thread^.Process^.MemoryState != KI_PROCESS_RESIDENT THEN
        // The thread's process is outswapped.

        IF KiReadyThreadOutswappedProcess ( thread ) THEN
            GOTO Retry
        END

        LEAVE

    ELSEIF NOT thread^.KernelStackResident THEN
        // The thread's kernel stack is outswapped.

        IF KiReadyOutswappedThread ( thread ) THEN
            GOTO Retry
        END

        LEAVE
    END

    thread^.InSwapList = FALSE

    myprb := KI_CURRENT_PRB

#IF BLD_MP
    // Select a processor to insert the thread into in the following order:
    //
    // 1. Affinity processor if would preempt.
    // 2. Any other idle processor.
    // 3. Any other preemptible processor.
    // 4. Current processor.

    prb := thread^.AffinityPrb

    IF prb THEN
        IF thread^.Pinned OR KiWouldPreempt (
            thread, // thread1
            prb, // targetprb
        ) THEN

            GOTO Found
        END
    END

    // Scan for the preemptible processor with the lowest load.

    prb = KiFindProcessor (
        myprb, // preferential
        thread, // thread
    )

    KeAssert ( prb != NULLPTR )

@Found

    KiAcquireReadyQueueElevated ( prb )

    KiInsertThread (
        prb, // prb
        thread, // thread
        myprb != prb, // other
        FALSE, // preempted
    )

    KiReleaseReadyQueueElevated ( prb )

#ELSE
    KiInsertThread (
        myprb, // prb
        thread, // thread
        FALSE, // other
        FALSE, // preempted
    )
#END

END

FN KeReadyThread (
    IN thread : ^KeThread,
)

    // External interface for readying a thread.

    ipl := KiAcquireThread ( thread )

    KiReadyThread ( thread )

    KiReleaseThread ( thread, ipl )
END

#IF BLD_MP

#MACRO KiSkipPinnedThreads ( migrate, thread, readybits, queue, i ) [
    IF migrate AND thread^.Pinned THEN
        // We can't migrate pinned threads, so try to find one that isn't
        // pinned.
        //
        // Note that this causes a degradation of the scheduler to O(n) in
        // number of pinned threads on a ready queue before the first non-pinned
        // thread. It's expected that this won't be an issue because thread
        // pinning is rare.

        WHILE TRUE DO
            IF thread^.ReadyEntry.Next == queue THEN
                // Only pinned threads in this queue, check the next one by
                // masking this one out of the ready bit set.

                readybits &= ~(1 << i)

                IF readybits != 0 THEN
                    GOTO SeekNextQueue
                END

                // No queues have threads we're allowed to take.

                RETURN NULLPTR
            END

            thread = CONTAINEROF thread^.ReadyEntry.Next TO KeThread.ReadyEntry

            IF NOT thread^.Pinned THEN
                BREAK
            END
        END
    END
]

#ELSE

#MACRO KiSkipPinnedThreads ( migrate, thread, readybits, queue, i ) []

#END

FN KiSelectRealTimeThread (
    IN prb : ^KiPrb,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's real time ready
    // queues. The processor's ready queue lock is held.

    readybits := prb^.RealTimeReady

    KeAssert ( readybits != 0 )

@SeekNextQueue

    // Binary search within the 32 bit ready bit set to find the highest byte
    // that has a set bit.

    i : UWORD

    IF readybits & 0xFFFF0000 THEN
        IF readybits & 0xFF000000 THEN
            // 0xFF000000 is the highest byte.
            i = 24

        ELSE
            // 0x00FF0000 is the highest byte.
            i = 16
        END

    ELSEIF readybits & 0x0000FF00 THEN
        // 0x0000FF00 is the highest byte.
        i = 8

    ELSE
        // 0x000000FF is the highest byte.
        i = 0
    END

    // Use a lookup table to find the highest bit set within this byte.

    i = KiIndexLastBitSet[(readybits >> i) & 0xFF] + i

    queue := &prb^.RealTimeListHeads[i]

    thread := CONTAINEROF queue^.Next TO KeThread.ReadyEntry

    // If we're migrating threads, we can't take pinned threads off of this
    // ready queue, so skip any pinned threads in that case.
    //
    // NOTE: This macro can GOTO SeekNextQueue and modify readybits.

    KiSkipPinnedThreads ( migrate, thread, readybits, queue, i )

    // Remove from the ready queue.

    RtlRemoveEntryList ( &thread^.ReadyEntry )

    IF RtlEmptyList ( queue ) THEN
        // The queue is empty now. Clear the bit.

        prb^.RealTimeReady &= ~(1 << i)
    END

    // Decrement count of ready threads.

    KiDecrementLoad ( prb )

    // No longer on a queue, so set INFLIGHT.

    thread^.Status = KI_THREAD_INFLIGHT

    RETURN thread
END

FN KiSelectTimesharedThread (
    IN prb : ^KiPrb,
    IN current : ^KeThread,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's calendar ready
    // queues. The processor's ready queue lock is held.

    // If there's a current thread we want to see where it would be placed if it
    // were to be enqueued here now, so that we can go right back to it if we
    // figure out thats appropriate.

    readybits := prb^.CalendarReady

    KeAssert ( readybits != 0 )

    k := prb^.CalendarRunIndex

    IF NOT current
#IF BLD_MP
        OR migrate
#END
        THEN

        // If we're migrating, or we'd become idle if we fail to get a thread
        // here, seek to a set bit to make sure we get a thread.

@SeekNextQueue

        fbsarray := &KiIndexFirstBitSet[0]

        // Start from bit k. Assume the ready bits are 32 bit.
        // We seek circularly (i.e. with wraparound) from index k to k-1 for the
        // first encountered set bit.
        //
        // Portability hazard: We assume the architecture we run on, masks the
        // rotation amount. This is true on all current and planned
        // architectures (fox32, xr17032, Aphelion, AMD64).
        //
        // Optimization note: This was tried in both an unrolled form and an
        // explicit loop form. They both generated code that executed the same
        // absolute number of instructions. The loop is better on Icache. The
        // unrolled form branch predicts better. Due to the small Icache on
        // xr17032, the loop form was selected with the idea the Icache impact
        // will be more important and the branch mispredicts will come out in
        // the wash, however this needs benchmarking to tell for sure.
        // Also this is probably not that important anyway.

        fbs := fbsarray[(readybits ROR k) & 0xFF]

        WHILE fbs == 8 DO
            k += 8
            fbs = fbsarray[(readybits ROR k) & 0xFF]
        END

        k = (k + fbs) & 31

    ELSEIF (readybits >> k) & 1 == 0 THEN
        RETURN NULLPTR
    END

    // There's a thread in this queue.

    queue := &prb^.CalendarListHeads[k]

    thread := CONTAINEROF queue^.Next TO KeThread.ReadyEntry

    // If we're migrating threads, we can't take pinned threads off of this
    // ready queue, so skip any pinned threads in that case.
    //
    // NOTE: This macro can GOTO SeekNextQueue and modify readybits.

    KiSkipPinnedThreads ( migrate, thread, readybits, queue, k )

    // Remove the thread from the queue.

    RtlRemoveEntryList ( &thread^.ReadyEntry )

    IF RtlEmptyList ( queue ) THEN
        // The queue is empty now. Clear the bit.

        prb^.CalendarReady &= ~(1 << k)

#IF BLD_MP
        IF NOT migrate THEN
#END
            // Advance the run index.

            IF prb^.CalendarRunIndex != prb^.CalendarEnqueueIndex THEN
                prb^.CalendarRunIndex = (k + 1) % KI_TIMESHARED_QUEUES
            END
#IF BLD_MP
        END
#END
    END

    // Decrement count of ready threads.

    KiDecrementLoad ( prb )

    // No longer on a queue, so set INFLIGHT.

    thread^.Status = KI_THREAD_INFLIGHT

    RETURN thread
END

FN KiSelectThread (
    IN prb : ^KiPrb,
    IN current : ^KeThread,
    IN exclusive : UWORD,
    IN migrate : UWORD,
) : ^KeThread

    // Return a thread to switch into from the given processor's queues.
    // A thread lock is held, or we are otherwise at KI_IPL_DPC. Ready queue
    // lock is held.
    //
    // If a current thread is given, we only return threads that can preempt it.

    next : ^KeThread = NULLPTR

    minimumpriority := 0
    interactive := FALSE

    IF current THEN
        // We're selecting a thread whose priority is >= the 'current' thread.

        minimumpriority = current^.Priority
        interactive = current^.InteractiveBits

        IF exclusive THEN
            // Only pick a thread whose priority is strictly > the 'current'
            // thread.

            minimumpriority += 1

            IF minimumpriority == OS_PRIORITY_MAX THEN
                // The thread is already at the highest priority, it can't be
                // preempted.

                // Portability hazard: This check currently stops a right shift
                // below from ever having a shift amount >= the register bit
                // width, which causes unpredictable results on some chips.
                // That should be kept in mind before changing this code.

                RETURN NULLPTR
            END
        END
    END

    // Check the real time bitmap.

    readybits := prb^.RealTimeReady

    IF readybits >> minimumpriority THEN
        // We're taking a thread off the real time queues.

        next = KiSelectRealTimeThread (
            prb, // prb
            migrate, // migrate
        )

#IF BLD_MP
        IF NOT migrate OR next THEN
            RETURN next
        END
#ELSE
        RETURN next
#END
    END

    IF interactive OR minimumpriority >= OS_PRIORITY_LOW_REALTIME THEN
        // Can't be preempted by anybody timeshared.

        RETURN NULLPTR
    END

    // Check the calendar queue (timeshared) bitmap.

    IF prb^.CalendarReady THEN
        // We're taking a thread off the timeshared queues.

        next = KiSelectTimesharedThread (
            prb, // prb
            current, // current
            migrate, // migrate
        )

#IF BLD_MP
        IF NOT migrate OR next THEN
            RETURN next
        END
#ELSE
        RETURN next
#END
    END

    IF minimumpriority > OS_PRIORITY_IDLE THEN
        // Can't be preempted by an idle thread.

        RETURN NULLPTR
    END

    // Check the idle thread queue.

    IF NOT RtlEmptyList ( &prb^.IdleListHead ) THEN
        // We're taking a thread off the idle queue.

        next = CONTAINEROF prb^.IdleListHead.Next TO KeThread.ReadyEntry

        RtlRemoveEntryList ( &next^.ReadyEntry )

        // Decrement count of ready threads.

        KiDecrementLoad ( prb )

        // No longer on a queue, so set INFLIGHT.

        next^.Status = KI_THREAD_INFLIGHT

        RETURN next
    END

    // Nothing to run.

    RETURN NULLPTR
END

FN KiPreemptThread (
    IN prb : ^KiPrb,
)

    // Called at KI_IPL_DPC when theres a thread we've been preempted by and
    // it's time to switch into it.

    // Grab the next thread with the ready queue lock held.

    KiAcquireReadyQueueElevated ( prb )

    next := prb^.NextThread
    prb^.NextThread = NULLPTR

#IF BLD_MP
    IF NOT next THEN
        // If there's somehow no next thread, just return.

        KiReleaseReadyQueueElevated ( prb )
        
        LEAVE
    END
#END

    next^.Status = KI_THREAD_INFLIGHT

    KiReleaseReadyQueueElevated ( prb )

    // Wait for the next thread to no longer be switching off his stack.

    KiWaitForSwitch ( next )

    // Acquire a pointer to the current thread.

    current := prb^.CurrentThread

    // Acquire the current thread's lock.

    KiAcquireThreadElevated ( current )

#IF BLD_MP
    // Indicate context switching so that anyone who grabs us from the ready
    // queue and tries to switch into us, will wait until we are off our
    // stack. This flag is cleared by KiSwitchContext.

    current^.Switching = TRUE
#END

    IF current != &prb^.IdleThread THEN
        // Ready the current thread.

        KiAcquireReadyQueueElevated ( prb )

        KiInsertThread (
            prb, // prb
            current, // thread
            FALSE, // other
            TRUE, // preempted
        )

        KiReleaseReadyQueueElevated ( prb )

    ELSE
        // Make sure to set the idle thread ready, though it's not in a queue.

        current^.Status = KI_THREAD_READY

#IF BLD_MP
        // No longer in the idle loop.

        prb^.InIdleLoop = FALSE

        KeWriteMemoryBarrier ()
#END
    END

    // Switch into the thread.

    KiSwitchThread (
        current, // current
        next, // thread
    )

    // KiSwitchThread returns with the thread lock released.
END

FN KiReinsertThread (
    IN thread : ^KeThread,
    IN prb : ^KiPrb,
    IN other : UWORD,
    IN curpri : UWORD,
)

    // Remove and re-insert the thread into a ready queue.
    // Thread and ready queue lock are held.

    KeAssert ( thread^.Status == KI_THREAD_READY )

    IF thread^.InSwapList THEN
        // It's in a stack swapper list, no need to do anything here.

        LEAVE
    END

    // We changed the priority level, so the thread is now on the wrong
    // ready queue. Manually unlink it from the queue, and then re-ready
    // it to place it on the correct one.

    KiDecrementLoad ( prb )

    RtlRemoveEntryList ( &thread^.ReadyEntry )

    IF thread^.ReadyEntry.Prev == thread^.ReadyEntry.Next THEN
        // We just emptied the list. We have to clear a bit.

        IF thread^.CurrentQueue == KI_REAL_TIME_QUEUE THEN
            prb^.RealTimeReady &= ~(1 << curpri)

        ELSEIF thread^.CurrentQueue == KI_TIMESHARED_QUEUE THEN
            // The timeshared queue index was stashed in Alertable.

            prb^.CalendarReady &= ~(1 << thread^.Alertable)
        END
    END

    KiInsertThread (
        prb, // prb
        thread, // thread
        other, // other
        FALSE, // preempted
    )
END

FN KiSetPriorityThread (
    IN thread : ^KeThread,
    IN priority : UWORD,
)

    // Set the new priority for a thread. The thread lock is held.

    KeAssert ( KiCurrentIpl () == KI_IPL_DPC )

    IF priority < thread^.PriorityFloor THEN
        // This thread is a subject of priority inheritance. Ensure its priority
        // never falls below the current inheritance floor.

        priority = thread^.PriorityFloor
    END

    curpri := thread^.Priority

    IF curpri == priority THEN
        // Nothing changed.

        LEAVE
    END

#IF BLD_MP
    // Lock any processor ready queue that it is enqueued to.

    prb := thread^.CurrentPrb

    IF prb THEN
        KiAcquireReadyQueueElevated ( prb )
    END

    other := (prb != KI_CURRENT_PRB)

#ELSE
    prb := KI_CURRENT_PRB
    other := FALSE
#END

    // The idle thread is often READY without being in a queue.
    // Rather than special casing this, we just forbid setting its priority.
    // This operation cannot be initiated by a user anyway since there's no
    // way to get a handle to an idle thread.

    KeAssert ( thread != &prb^.IdleThread )

    thread^.Priority = priority

    IF priority == OS_PRIORITY_IDLE THEN
        // Make sure idle priority threads are never marked interactive.

        KiClearInteractiveForBehavior ( thread )
    END

    IF thread^.Status == KI_THREAD_READY THEN
        // Remove and re-insert the thread into the ready queues.

        KiReinsertThread (
            thread, // thread
            prb, // prb
            other, // other
            curpri, // curpri
        )

        GOTO Exit
    END

#IF BLD_MP
    IF thread^.Status == KI_THREAD_RUNNING AND
        NOT prb^.NextThread THEN

        // Update the stashed priority.

        prb^.StashedCurrentThreadInfo =
            KiSetPriorityInStash ( prb^.StashedCurrentThreadInfo, priority )
    END
#END

    IF priority >= curpri THEN
        // We raised priority, so there's nothing left to do.

        GOTO Exit
    END

    // Priority was dropped. It may need to be preempted.

    next : ^KeThread

    IF thread^.Status == KI_THREAD_STANDBY THEN
        // This is the next thread, so check if we have a higher priority
        // thread we should switch to instead, now that we have dropped its
        // priority.

        next = KiSelectThread (
            prb, // prb
            thread, // current
            TRUE, // exclusive
            FALSE, // migrate
        )

        IF NOT next THEN
            GOTO Exit
        END

        KiSetNextThread (
            prb, // prb
            next, // thread
        )

        // Re-ready our thread to place it on the normal ready queue.

        KiInsertThread (
            prb, // prb
            thread, // thread
            other, // other
            TRUE, // preempted
        )

        GOTO Exit
    END

    IF thread^.Status == KI_THREAD_RUNNING THEN
        // This is the running thread, so we should see if there's now a
        // higher priority thread that should preempt it.

        IF prb^.NextThread THEN
            // A next thread was already selected.

            GOTO Exit
        END

        next = KiSelectThread (
            prb, // prb
            thread, // current
            TRUE, // exclusive
            FALSE, // migrate
        )

        IF NOT next THEN
            GOTO Exit
        END

        // Cause a preemption.

        KiSetNextThread (
            prb, // prb
            next, // thread
        )

#IF BLD_MP
        IF other THEN
            // This was a remote Prb; may have to send an IPI.

            KiSoftInterruptOther (
                prb, // targetprb
                KI_IPL_DPC, // ipl
            )

            GOTO Exit
        END
#END

        KiSoftInterruptSelf (
            prb, // targetprb
            KI_IPL_DPC, // ipl
        )
    END

@Exit

#IF BLD_MP
    IF prb THEN
        KiReleaseReadyQueueElevated ( prb )
    END
#END

END

EXPORT FN KeSetBasePriorityThread (
    IN thread : ^KeThread,
    IN priority : UWORD,
    IN setcurrentpriority : UWORD,
)

    // Set a new base priority for the given thread. If the new base is higher
    // than the current priority, raise it.

    ipl := KiAcquireThread ( thread )

    thread^.BasePriority = priority

    IF setcurrentpriority OR thread^.Priority < priority THEN
        KiSetPriorityThread (
            thread, // thread
            priority, // priority
        )
    END

    KiReleaseThread ( thread, ipl )
END

EXPORT FN KeSetPriorityThread (
    IN thread : ^KeThread,
    IN priority : UWORD,
)

    // Set a new priority for the thread.

    ipl := KiAcquireThread ( thread )

    KiSetPriorityThread (
        thread, // thread
        priority, // priority
    )

    KiReleaseThread ( thread, ipl )
END

FN KiCheckInteractivityInternal (
    IN prb : ^KiPrb,
    IN current : ^KeThread,
    IN oldinteractivity : UWORD,
    IN newinteractivity : UWORD,
)

    // Check for, and cause, preemption by the thread dropping to
    // non-interactive.

    // Lock the ready queue.

    KiAcquireReadyQueueElevated ( prb )

    IF NOT prb^.NextThread THEN
#IF BLD_MP
        // Update the current interactivity stashed in the prb.

        prb^.StashedCurrentThreadInfo =
            KiSetInteractivityInStash ( prb^.StashedCurrentThreadInfo,
            newinteractivity )
#END

        IF newinteractivity < oldinteractivity THEN
            // Try to find a thread to preempt this one with.

            next := KiSelectThread (
                prb, // prb
                current, // current
                TRUE, // exclusive
                FALSE, // migrate
            )

            IF next THEN
                // Found one. Set it as the next thread.

                KiSetNextThread (
                    prb, // prb
                    next, // thread
                )
            END
        END
    END

    KiReleaseReadyQueueElevated ( prb )
END

FN KiCheckInteractivity (
    IN prb : ^KiPrb,
)

    // The current thread has changed from interactive to non-interactive as a
    // result of a timer interrupt. We have to check for preemption.

    current := prb^.CurrentThread

    // Lock the thread.

    KiAcquireThreadElevated ( current )

    oldinteractivity := current^.InteractiveBits

    // Perform the deferred interactivity update.

    KiUpdateInteractivity (
        current, // thread
        FALSE, // deferupdate
    )

    newinteractivity := current^.InteractiveBits

    IF oldinteractivity == newinteractivity THEN
        // Nothing to do.

        GOTO Exit
    END

    KiCheckInteractivityInternal (
        prb, // prb
        current, // current
        oldinteractivity, // oldinteractivity
        newinteractivity, // newinteractivity
    )

@Exit

    KiReleaseThreadElevated ( current )
END

FN KiMoveToInteractiveQueueThread (
    IN thread : ^KeThread,
)

    // The given thread is ready and was not interactive. It's now interactive
    // so we want to move it to the right queue. Thread lock is held.

#IF BLD_MP
    prb := thread^.CurrentPrb
    other := prb != KI_CURRENT_PRB

    IF NOT prb THEN
        LEAVE
    END

#ELSE
    prb := KI_CURRENT_PRB
    other := FALSE
#END

    KiAcquireReadyQueueElevated ( prb )

    IF thread^.Status != KI_THREAD_READY THEN
#IF BLD_MP
        IF thread^.Status == KI_THREAD_RUNNING AND
            NOT prb^.NextThread THEN

            // Update stashed interactivity.

            prb^.StashedCurrentThreadInfo =
                KiSetInteractivityInStash ( prb^.StashedCurrentThreadInfo,
                thread^.InteractiveBits )
        END
#END

        GOTO Exit
    END

    KiReinsertThread (
        thread, // thread
        prb, // prb
        other, // other
        thread^.Priority, // curpri
    )

@Exit

    KiReleaseReadyQueueElevated ( prb )
END

FN KiQuantumEnd (
    IN prb : ^KiPrb,
)

    // A quantum end has been detected on the current processor.

    current := prb^.CurrentThread

    IF current == &prb^.IdleThread THEN
        // Idle thread takes no quantum ends. This can happen if there was a
        // thread swap inbetween the quantum end request and service.

        LEAVE
    END

    // Replenish the quantum of the thread.

    current^.RemainingQuantum = KI_DEFAULT_QUANTUM

    KiAcquireThreadElevated ( current )

    IF current^.Priority > current^.BasePriority THEN
        // Decay priority by one.

        KiSetPriorityThread (
            current, // thread
            current^.Priority - 1, // priority
        )
    END

    // Lock the ready queue.

    KiAcquireReadyQueueElevated ( prb )

    IF NOT prb^.NextThread THEN
        // Try to find a thread to preempt this one with.

        next := KiSelectThread (
            prb, // prb
            current, // current
            FALSE, // exclusive
            FALSE, // migrate
        )

        IF next THEN
            // Found one. Set it as the next thread.

            KiSetNextThread (
                prb, // prb
                next, // thread
            )
        END
    END

    KiReleaseReadyQueueAndThreadElevated ( prb, current )
END

FN KiYield (
    IN current : ^KeThread,
    IN prb : ^KiPrb,
)

    // Yield the processor. Thread lock is held on entry, released on exit.

    // Try to find a thread to switch into.

    KiAcquireReadyQueueElevated ( prb )

#IF BLD_MP
    // There's a chance that a next thread was selected inbetween raising IPL
    // and taking the Prb lock.

    next := prb^.NextThread

    IF next THEN
        // Yep.

        prb^.NextThread = NULLPTR
        next^.Status = KI_THREAD_INFLIGHT

    ELSE
        next = KiSelectThread (
            prb, // prb
            NULLPTR, // current
            FALSE, // exclusive
            FALSE, // migrate
        )
    END

#ELSE
    KeAssert ( prb^.NextThread == NULLPTR )

    next := KiSelectThread (
        prb, // prb
        NULLPTR, // current
        FALSE, // exclusive
        FALSE, // migrate
    )
#END

    KiReleaseReadyQueueElevated ( prb )

    IF next THEN
        // Wait for the next thread to no longer be switching off his stack.

        KiWaitForSwitch ( next )

        // Switch into it. KiSwitchThread returns with the thread lock released.

        KiSwitchThread (
            current, // current
            next, // thread
        )

    ELSE
#IF BLD_MP
        prb^.StealWork = TRUE
        prb^.StashedCurrentThreadInfo = KiSetIdleInStash ( 0, TRUE )

        prb^.InIdleLoop = TRUE

        KeWriteMemoryBarrier ()
#END

        // Switch to the idle thread. KiSwitchThread returns with the thread
        // lock released.

        KiSwitchThread (
            current, // current
            &prb^.IdleThread, // thread
        )
    END
END

#IF BLD_MP

#DEFINE KI_MAX_THREAD_MOVES 16

FN KiMoveThreads (
    IN destprb : ^KiPrb,
    IN srcprb : ^KiPrb,
    IN other : UWORD,
    IN idlestealing : UWORD,
)

    // Move threads from the source to the destination, so long as it would not
    // worsen an imbalance.

    threads : ^KeThread[KI_MAX_THREAD_MOVES]
    skippedthreads : ^KeThread[KI_MAX_THREAD_MOVES]
    thread : ^KeThread

    i := 0

    // Lock the queues. We need to define a consistent ordering, so we use the
    // order of their addresses.
    //
    // Previously we would lock the source, take a thread, unlock the source,
    // lock the thread, lock the destination, then enqueue to the destination.
    // This created too many opportunities for imbalances to be worsened.
    //
    // Now we lock both queues, make sure there's still an imbalance with the
    // locks held, take threads from the source, unlock it, enqueue threads
    // (which, because we still hold the destination, is out of order, so we
    // need to trylock the thread), then unlock the destination.

    IF destprb < srcprb THEN
        KiAcquireReadyQueueElevated ( destprb )
        KiAcquireReadyQueueElevated ( srcprb )
    ELSE
        KiAcquireReadyQueueElevated ( srcprb )
        KiAcquireReadyQueueElevated ( destprb )
    END

    IF destprb^.Load >= srcprb^.Load OR
        (idlestealing AND destprb^.NextThread) THEN

        // There is no imbalance, bail out.

        // Alternatively, we were here to steal work upon becoming idle, but in
        // the time since we decided to do that, this processor became busy.
        // So it's no longer necessary.

        KiReleaseTwoReadyQueuesElevated ( destprb, srcprb )

        LEAVE
    END

    // Only move half as many threads as the difference in load. This will
    // create a balance between the two processors. If we moved the full
    // difference then we'd just shuffle the imbalance around.

    count := (srcprb^.Load - destprb^.Load + 1) / 2

    IF count > KI_MAX_THREAD_MOVES THEN
        count = KI_MAX_THREAD_MOVES
    END

    WHILE i < count DO
        // Select a thread.

        thread = KiSelectThread (
            srcprb, // prb
            NULLPTR, // current
            FALSE, // exclusive
            TRUE, // migrate
        )

        IF NOT thread THEN
            // Unlikely situation, but we got no thread to move. Give up.
            // This can happen if the source processor had only pinned threads
            // enqueued to it.

            BREAK
        END

        // Set INFLIGHT so nobody tries to touch the thread while we've got it.

        thread^.Status = KI_THREAD_INFLIGHT

        threads[i] = thread

        i += 1
    END

    KiReleaseReadyQueueElevated ( srcprb )

    skipped := 0
    j := 0

    WHILE j < i DO
        thread = threads[j]

        // Lock the thread.
        // This is out of order with respect to the ready queue locks, so we
        // just make a best effort with a trylock.

        IF KiTryAcquireThreadElevated ( thread ) THEN
            // Insert the thread.

            KiInsertThread (
                destprb, // prb
                thread, // thread
                other, // other
                FALSE, // preempted
            )

            // Release the thread.

            KiReleaseThreadElevated ( thread )
        
        ELSE
            // Failed to acquire the thread spinlock. Record this thread for the
            // second pass.

            skippedthreads[skipped] = thread
            skipped += 1
        END

        j += 1
    END

    // Release the destination ready queue.

    KiReleaseReadyQueueElevated ( destprb )

    IF NOT skipped THEN
        LEAVE
    END

    // Some threads were skipped due to a failure to acquire their spinlock.
    // Enqueue them now.

    j = 0

    WHILE j < skipped DO
        thread = skippedthreads[j]

        KiAcquireThreadElevated ( thread )

        KiAcquireReadyQueueElevated ( destprb )

        KiInsertThread (
            destprb, // prb
            thread, // thread
            other, // other
            FALSE, // preempted
        )

        KiReleaseReadyQueueAndThreadElevated ( destprb, thread )

        j += 1
    END
END

FN KiStealWork ()

    // This is called by the idle thread of each processor. We want to find the
    // most heavily loaded processor and steal a thread off his queues.

    ipl := KiRaiseIpl ( KI_IPL_DPC )

    myprb := KI_CURRENT_PRB

    loadedprb : ^KiPrb
    garbagecan : ^VOID

    KiFindMostAndLeastLoadedProcessor (
        OUT loadedprb, // mostloaded
        OUT garbagecan, // leastloaded
    )

    IF loadedprb == myprb THEN
        // Most loaded processor was me. Clearly, something changed while I was
        // trying to do this.

        KiLowerIpl ( ipl )

        LEAVE
    END

    IF loadedprb^.Load < KI_STEAL_LOAD THEN
        // Most loaded processor was still below the minimum stealing load.
        // Just leave.

        KiLowerIpl ( ipl )

        LEAVE
    END

    KiMoveThreads (
        myprb, // destprb
        loadedprb, // srcprb
        FALSE, // other
        TRUE, // idlestealing
    )

    // Lower IPL - we should switch to the stolen thread.

    KiLowerIpl ( ipl )
END

FN (KeDpcF) KiBalanceWork (
    IN dpc : ^KeDpc,
    IN context1 : UWORD,
    IN context2 : UWORD,
)

    // Called once per second on processor 0. Moves work from the most loaded
    // processor to the least loaded processor until balance is achieved.

    max := KiMaximumBalanceIterations
    myprb := KI_CURRENT_PRB
    j := 0

    WHILE j < max DO
        mostloaded : ^KiPrb
        leastloaded : ^KiPrb

        KiFindMostAndLeastLoadedProcessor (
            OUT mostloaded, // mostloaded
            OUT leastloaded, // leastloaded
        )

        IF mostloaded == leastloaded THEN
            BREAK
        END

        diff := CAST mostloaded^.Load - leastloaded^.Load TO WORD

        IF diff < 0 THEN
            // Something changed. Retry.

            CONTINUE
        END

        IF diff < 1 THEN
            // Balance is achieved.

            BREAK
        END

        KiMoveThreads (
            leastloaded, // destprb
            mostloaded, // srcprb
            leastloaded != myprb, // other
            FALSE, // idlestealing
        )

        IF diff == 1 THEN
            // We just moved a thread around. Don't do that again.

            BREAK
        END

        j += 1
    END
END

FN KiPinThread (
    IN prb : ^KiPrb,
)

    // Pin the current thread to the given processor. No locks are held on
    // entry to this function. 

    myprb := KI_CURRENT_PRB

    current := myprb^.CurrentThread

    KeAssert ( KiCurrentIpl () == KI_IPL_DPC )
    KeAssert ( current != &myprb^.IdleThread )

    KiAcquireThreadElevated ( current )

    current^.AffinityPrb = prb
    current^.Pinned = TRUE

    IF myprb == prb THEN
        // Already on the right processor. Nothing to do.

        KiReleaseThreadElevated ( current )

        LEAVE
    END

    // We need to insert ourselves on the target processor's ready queue and
    // then yield execution.

    // Indicate context switching so that anyone who grabs us from the ready
    // queue and tries to switch into us, will wait until we are off our
    // stack. This flag is cleared by KiSwitchContext.

    current^.Switching = TRUE

    // Ready the current thread to the target Prb.

    KiAcquireReadyQueueElevated ( prb )

    KiInsertThread (
        prb, // prb
        current, // thread
        TRUE, // other
        TRUE, // preempted
    )

    KiReleaseReadyQueueElevated ( prb )

    // Yield the current processor.

    KiYield (
        current, // current
        myprb, // prb
    )

    // We are now pinned to the requested processor. The thread lock has been
    // released.
END

FN KiUnpinThread ()

    // Unpin the current thread. No locks are held on entry to this function.

    myprb := KI_CURRENT_PRB

    current := myprb^.CurrentThread

    KeAssert ( KiCurrentIpl () == KI_IPL_DPC )
    KeAssert ( current != &myprb^.IdleThread )

    // Acquire the thread lock so that nobody sees the value of Pinned change
    // partway through an operation.

    KiAcquireThreadElevated ( current )

    current^.Pinned = FALSE

    KiReleaseThreadElevated ( current )
END

#END