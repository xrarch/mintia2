//
// Implements support for software Interrupt Priority Levels (IPLs).
//

#INCLUDE "Kep.hjk"

EXTERN FN PsuReallocateRemoteTurnstile ()

#MACRO KepAcknowledgeSoftwareInterrupt ( prb, ipl ) [
    KeAssert ( ipl != KEP_IPL_LOW )

#IF BLD_MP
    KeMaskUlong (
        &(prb)^.PendingSoftwareInterrupts, // ptr
        ~(KepPendingIpl ( ipl )), // mask
    )
#ELSE
    NOTHING (prb)^.PendingSoftwareInterrupts &= ~(KepPendingIpl ( ipl ))
#END
]

FNPTR KepSoftwareInterruptHandlerF ()

FN (KepSoftwareInterruptHandlerF) KepNoInterrupt ()

    // Called if no software interrupt is pending on entry to
    // KepDispatchSoftwareInterrupts.

    NOTHING
END

FN (KepSoftwareInterruptHandlerF) KepApcInterrupt ()

    // Called if an APC interrupt is pending.
    // Atomically clear the pending APC interrupt.

    prb := KEP_CURRENT_PRB_LOCAL

    KepAcknowledgeSoftwareInterrupt (
        prb, // prb
        KEP_IPL_APC, // ipl
    )

    current := prb^.CurrentThread
    current^.PendingApcLevelInt = FALSE

    prb^.Ipl = KEP_IPL_APC

    KepEnableInterrupts ()

#IF BLD_NUMA
    IF KeNumaNodeFromSpacePointer ( current ) !=
        KeNumaNodeFromSpacePointer ( current^.Turnstile ) THEN

        // Due to turnstile donation, we no longer have a turnstile that is
        // local to our node. At some we point contended on a lock with a thread
        // from a remote node and he left us with this turnstile that is
        // allocated in physical memory on a remote node (basically it has
        // cooties). This situation couldn't be rectified immediately because it
        // is not safe to try to allocate a new turnstile from inside the
        // turnstile code, we needed to just deal with it until a safe moment,
        // which has now come.
        //
        // For locality reasons we shouldn't allow this condition to persist and
        // should upcall into Ps to reallocate the turnstile.

        PsuReallocateRemoteTurnstile ()
    END
#END

    KepDispatchKernelApcQueue ( current )

    KepDisableInterrupts ()
END

FN (KepSoftwareInterruptHandlerF) KepDpcInterrupt ()

    // Called if a DPC interrupt is pending.
    // Atomically clear the pending DPC interrupt.

    prb := KEP_CURRENT_PRB

    KepAcknowledgeSoftwareInterrupt (
        prb, // prb
        KEP_IPL_DPC, // ipl
    )

    prb^.Ipl = KEP_IPL_DPC

    KepEnableInterrupts ()

    IF NOT RtlEmptyList ( &prb^.DpcListHead ) THEN
        KepDispatchDpcQueue ( prb )
    END

    IF prb^.CheckInteractivity THEN
        prb^.CheckInteractivity = FALSE

        KepCheckInteractivity ( prb )
    END

    IF prb^.QuantumEnd THEN
        prb^.QuantumEnd = FALSE

        KepQuantumEnd ( prb )
    END

#IF BLD_MP
    IF prb^.WakeStackSwapper THEN
        // A request was made to wake the stack swapper.
        // On MP we do this here because when we noticed we had to, we were deep
        // in some spinlocks. UP does not have this issue because DPC level is
        // DPC level, so we just signal the event at that time instead of here.

        prb^.WakeStackSwapper = FALSE

        KeSignalEvent (
            &prb^.Node^.StackSwapperEvent, // event
            0, // priorityboost
        )
    END
#END

    IF prb^.NextThread THEN
        // A next thread was selected to preempt the current one.
        // Switch to it immediately.

        KepPreemptThread ( prb )
    END

    KepDisableInterrupts ()
END

#SECTION "text"
KepSoftwareInterruptPriorityTable : KepSoftwareInterruptHandlerF[] = {
    [0] = &KepNoInterrupt,
    [1] = &KepApcInterrupt,
    [2] = &KepDpcInterrupt,
    [3] = &KepDpcInterrupt,
}

FN KepDispatchSoftwareInterrupts (
    IN newipl : UWORD,
)

    // Called when a pending software interrupt is detected either while
    // lowering IPL, or before returning from an interrupt. We need to
    // loop dispatching software interrupts until no more unmasked ones are
    // pending.

    mask := 3 << newipl

    oldstate := KepDisableInterrupts ()

    // Note that there's a race where inbetween the caller noticing unmasked
    // pending soft ints, and disabling interrupts just now, an interrupt may
    // have come in that delivered them, meaning we'll observe a "zero" mask in
    // the pending soft ints mask. We don't check for this and assume it's an
    // uncommon case (although it does happen, observably). The zeroth entry
    // in the dispatch table is a no-op routine in order to catch this
    // harmlessly without wasting branch instructions in the hot path.

    prb := KEP_CURRENT_PRB_LOCAL
    pending := prb^.PendingSoftwareInterrupts & mask

    WHILE TRUE DO
        KepSoftwareInterruptPriorityTable[pending] ()

#IF KEP_VOLATILE_LOCAL_PRB
        // Recapture the Prb since it might have changed due to activity of the
        // scheduler while interrupts were enabled.

        prb = KEP_CURRENT_PRB_LOCAL
#END

        pending = prb^.PendingSoftwareInterrupts & mask

        IF NOT pending THEN
            BREAK
        END
    END

    prb^.Ipl = newipl

    KepRestoreInterrupts ( oldstate )
END